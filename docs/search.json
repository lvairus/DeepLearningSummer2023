[
  {
    "objectID": "posts/2023-06-26-zero-to-hero/index.html",
    "href": "posts/2023-06-26-zero-to-hero/index.html",
    "title": "Zero to Hero",
    "section": "",
    "text": "1. Building Micrograd\nMade a Value class for storing scalars, their operations, and the variables that directly led to them. Using __add__() lets you add them with a+b. using __rmul__() let’s you do 2*a (which normally doesn’t work) by changing it to a*2 computationally\nused a GraphViz api to visualize the flow of data\nBackpropagating is just taking derivatives of every node value/weight using the chain rule\nwe need to add to gradients instead of redefining them because if one Value object is used multiple times, such as when one node connects to multiple others in the next layer, then it’s gradient depends on the sum of all the derivatives of the nodes on the next layer with respect to itself. If we just use a = this gradient will just be overwritten everytime we take the derivative of a new node with respect to it. Therefore we must use a +=\nhe made a topo function that, starting from an input node, makes a list of all the children that came before it in order, so no child is put after it’s parent. He then reversed that list so it starts with the last output node and iterated through it, calling backward() on all of them. This ensures that the gradients using chain rule can have the derivatives available to calculate the new derivative.\nthere is a backward() and _backward(). the _backward() provides information on specifically how to get the derivatives and backward() starts at the output node and propagates backward to calculate all the derivatives.\n\n\n2. Building Makemore\nfirst did bigrams but it was pretty bad\ncounted every time one letter followed another based on a set of 32000 names and stored counts in a dictionary. also used a special character . that signified the beginning and end of the name. made a char to str and str to char dictionary that grouped the letters to their numbers (with . at 0, a at 1,…, and z at 26)."
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html",
    "title": "Import Libraries",
    "section": "",
    "text": "# import packages\nimport tensorflow as tf\n# Make sure the GPU is enabled \nassert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -&gt; Change runtime type -&gt; GPU'\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nimport tensorflow_hub as hub # for interacting with saved models and tensorflow hub\nimport joblib\nimport gzip # for manipulating compressed files\nimport kipoiseq # for manipulating fasta files\nfrom kipoiseq import Interval # same as above, really\nimport pyfaidx # to index our reference genome file\nimport pandas as pd # for manipulating dataframes\nimport numpy as np # for numerical computations\nimport matplotlib.pyplot as plt # for plotting\nimport matplotlib as mpl # for plotting\nimport seaborn as sns # for plotting\nimport pickle # for saving large objects\nimport os, sys # functions for interacting with the operating system\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nNum GPUs Available:  4"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#define-paths",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#define-paths",
    "title": "Import Libraries",
    "section": "Define Paths",
    "text": "Define Paths\n\ntransform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\nmodel_path = 'https://tfhub.dev/deepmind/enformer/1'\nfasta_file = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa'\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#define-functions",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#define-functions",
    "title": "Import Libraries",
    "section": "Define Functions",
    "text": "Define Functions\n\n# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\nSEQUENCE_LENGTH = 393216\n\nclass Enformer:\n\n  def __init__(self, tfhub_url):\n    self._model = hub.load(tfhub_url).model\n\n  def predict_on_batch(self, inputs):\n    predictions = self._model.predict_on_batch(inputs)\n    return {k: v.numpy() for k, v in predictions.items()}\n\n  @tf.function\n  def contribution_input_grad(self, input_sequence,\n                              target_mask, output_head='human'):\n    input_sequence = input_sequence[tf.newaxis]\n\n    target_mask_mass = tf.reduce_sum(target_mask)\n    with tf.GradientTape() as tape:\n      tape.watch(input_sequence)\n      prediction = tf.reduce_sum(\n          target_mask[tf.newaxis] *\n          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n\n    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n    input_grad = tf.squeeze(input_grad, axis=0)\n    return tf.reduce_sum(input_grad, axis=-1)\n\n\nclass EnformerScoreVariantsRaw:\n\n  def __init__(self, tfhub_url, organism='human'):\n    self._model = Enformer(tfhub_url)\n    self._organism = organism\n\n  def predict_on_batch(self, inputs):\n    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n\n    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n\n\nclass EnformerScoreVariantsNormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human'):\n    assert organism == 'human', 'Transforms only compatible with organism=human'\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      transform_pipeline = joblib.load(f)\n    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)\n\n\nclass EnformerScoreVariantsPCANormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human', num_top_features=500):\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      self._transform = joblib.load(f)\n    self._num_top_features = num_top_features\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)[:, :self._num_top_features]\n\n\n# TODO(avsec): Add feature description: Either PCX, or full names.\n\n\n# @title `variant_centered_sequences`\n\nclass FastaStringExtractor:\n\n    def __init__(self, fasta_file):\n        self.fasta = pyfaidx.Fasta(fasta_file)\n        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n    #import pd.Interval as Interval\n    def extract(self, interval: Interval, **kwargs) -&gt; str:\n        # Truncate interval if it extends beyond the chromosome lengths.\n        chromosome_length = self._chromosome_sizes[interval.chrom]\n        trimmed_interval = Interval(interval.chrom,\n                                    max(interval.start, 0),\n                                    min(interval.end, chromosome_length),\n                                    )\n        # pyfaidx wants a 1-based interval\n        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n                                          trimmed_interval.start + 1,\n                                          trimmed_interval.stop).seq).upper()\n        # Fill truncated values with N's.\n        pad_upstream = 'N' * max(-interval.start, 0)\n        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n        return pad_upstream + sequence + pad_downstream\n\n    def close(self):\n        return self.fasta.close()\n\n\ndef one_hot_encode(sequence):\n  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n\n\n\n# @title `plot_tracks`\n\ndef plot_tracks(tracks, interval, height=1.5):\n  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n  for ax, (title, y) in zip(axes, tracks.items()):\n    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n    ax.set_title(title)\n    sns.despine(top=True, right=True, bottom=True)\n  ax.set_xlabel(str(interval))\n  plt.tight_layout()\n\n\nimport Bio\n\nfrom Bio.Seq import Seq\ndef create_rev_complement(dna_string):\n    return(str(Seq(dna_string).reverse_complement()))\n\n\ndef prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n\n  '''\n\n  Parameters:\n          predicitions (A numpy array): All predictions from the track\n          gene (a gene name, character): a gene\n          tss_df: a list of dataframe of genes and their transcription start sites\n  Returns:\n          A dictionary of cage experiment predictions and a list of transcription start sites\n\n  '''\n\n  output = dict()\n  for tdf in tss_df:\n    if gene not in tdf.genes.values:\n      continue\n    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n    gene_tss_list = list(set(gene_tss_list))\n  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n  output['gene_TSS'] = gene_tss_list # a list\n\n\n  return(output) # a dictionary\n\ndef quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n\n  '''\n  Parameters:\n          low_range (int): The lower interval\n          TSS (list of integers): A list of TSS for a gene\n          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n  Returns:\n          A dictionary of gene expression predictions for each TSS for a gene\n    '''\n  tss_predictions = dict()\n  for tss in TSS:\n    bin_start = low_range + ((768 + 320) * 128)\n    count = -1\n    while bin_start &lt; tss:\n      bin_start = bin_start + 128\n      count += 1\n    if count &gt;= len(cage_predictions)-1:\n      continue\n    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n    tss_predictions[tss] = cage_preds\n\n  return(tss_predictions)\n\ndef collect_intervals(chromosomes = [\"22\"], gene_list=None):\n\n  '''\n    Parameters :\n      chromosomes : a list of chromosome numbers; each element should be a string format\n      gene_list : a list of genes; the genes should be located on those chromosomes\n\n    Returns :\n      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n  '''\n\n  gene_intervals = {} # Collect intervals for our genes of interest\n\n  for chrom in chromosomes:\n    with open(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n      for line in chrom_genes:\n        split_line = line.strip().split(\"\\t\")\n        gene_intervals[split_line[2]] = [\n                                          split_line[0],\n                                          int(split_line[3]),\n                                          int(split_line[4])\n                                        ]\n\n  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n    return(use_genes)\n  elif isinstance(gene_list, type(None)):\n    return(gene_intervals)\n\n\ndef run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n  '''\n  Parameters :\n    gene_intervals : the results from calling `collect_intervals`\n    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n\n  Returns :\n    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n  '''\n\n  gene_output = dict()\n  gene_predictions = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2]) # creates an interval to select the right sequences\n    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n    try:\n      cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n    except:\n      continue\n    individual_results = dict()\n    individual_prediction = dict()\n\n    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n      use_individuals = individuals_list\n    elif isinstance(individuals_list, type(None)):\n      use_individuals = cur_gene_vars.columns[4:]\n\n    for individual in use_individuals:\n      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n      # two haplotypes per individual\n      haplo_1 = list(target_fa[:])\n      haplo_2 = list(target_fa[:])\n\n      ref_mismatch_count = 0\n      for i,row in cur_gene_vars.iterrows():\n\n        geno = row[individual].split(\"|\")\n        if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n          continue\n        if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n          continue\n        if geno[0] == \"1\":\n          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n        if geno[1] == \"1\":\n          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n      # predict on the individual's two haplotypes\n      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n\n      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n      individual_prediction[individual] = temp_predictions\n\n      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n      temp_list = list()\n\n      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n\n      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n\n      temp_list.append(tss_predictions_1)\n      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n\n      individual_results[individual] = temp_list # save for the individual\n\n    gene_output[gene] = individual_results\n    gene_predictions[gene] = individual_prediction\n\n  return([gene_output, gene_predictions])\n\n\ndef collect_target_intervals(gene_intervals):\n\n  '''\n  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n  '''\n\n  target_intervals_dict = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\n    target_intervals_dict[gene] = target_interval\n\n  return(target_intervals_dict)\n\ndef prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n\n  '''\n  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n\n  Parameters:\n    - gene\n    - individual\n    - all_predictions\n  '''\n\n  haplo_predictions = all_predictions[gene][individual]\n  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n\n  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n  gene_intervals = collect_target_intervals(gene_intervals)\n\n  output = dict()\n  output['gene_tracks'] = gene_tracks\n  output['gene_intervals'] = gene_intervals[gene]\n\n  return(output)\n\ndef check_individuals(path_to_bed_file, list_of_individuals):\n\n  '''\n  Checks if an individual is missing in bed variation files.\n  These individuals should be removed prior to training\n  '''\n\n  myfile = open(path_to_bed_file, 'r')\n  myline = myfile.readline()\n  bed_names = myline.split('\\t')[4:]\n  myfile.close()\n\n  if set(list_of_individuals).issubset(set(bed_names)) == False:\n    missing = list(set(list_of_individuals).difference(bed_names))\n    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n  else:\n    missing = []\n    print('All individuals are present in the bed file.')\n\n  return(missing)\n\n\ndef geno_to_seq(gene, individual):\n      # two haplotypes per individual\n  haplo_1 = list(target_fa[:])\n  haplo_2 = list(target_fa[:])\n\n  ref_mismatch_count = 0\n  for i,row in cur_gene_vars.iterrows():\n\n    geno = row[individual].split(\"|\")\n    if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n      continue\n    if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n      continue\n    if geno[0] == \"1\":\n      haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n    if geno[1] == \"1\":\n      haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n  return haplo_1, haplo_2\n\n      # predict on the individual's two haplotypes\n    \n\n\ndef run_predictions2(gene, chrom, indiv):\n    '''\n    Parameters :\n       gene: gene to run (string)\n       chrom: chrom gene is on (string)\n       indiv: individual to run (string)\n       chrNtss: variable of tss for chr\n    Returns :\n        A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n    '''\n    \n    gene_intervals = collect_intervals(chromosomes=[chrom], gene_list=[gene])\n    individuals_list = [indiv]\n\n    for gene in gene_intervals.keys():\n        global fasta_extractor\n        gene_interval = gene_intervals[gene]\n        target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                            gene_interval[1],\n                                            gene_interval[2]) # creates an interval to select the right sequences\n        target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n        window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n        try:\n            cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n        except:\n            continue\n        individual_prediction = dict()\n\n        if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n            use_individuals = individuals_list\n        elif isinstance(individuals_list, type(None)):\n            use_individuals = cur_gene_vars.columns[4:]\n\n        for individual in use_individuals:\n            # two haplotypes per individual\n            haplo_1 = list(target_fa[:])\n            haplo_2 = list(target_fa[:])\n\n            ref_mismatch_count = 0\n            for i,row in cur_gene_vars.iterrows():\n\n                geno = row[individual].split(\"|\")\n                if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n                    continue\n                if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n                    continue\n                if geno[0] == \"1\":\n                    haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n                if geno[1] == \"1\":\n                    haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n            # predict on the individual's two haplotypes\n            global model\n\n            ohe_haplo_1 = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\n            ohe_haplo_2 = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\n\n            ohe_haplo_avg = np.add(ohe_haplo_1, ohe_haplo_2) / 2\n                                         \n            prediction_1 = model.predict_on_batch(ohe_haplo_1)['human'][0]\n            prediction_2 = model.predict_on_batch(ohe_haplo_2)['human'][0]\n            prediction_avg = model.predict_on_batch(ohe_haplo_avg)['human'][0]\n            \n            post_avg = (prediction_1 + prediction_2) / 2\n            pre_avg = prediction_avg\n\n    return([pre_avg, post_avg])\n\n\n# rel diff helper functions\n\ndef get_relmax(arr):\n    arr = np.abs(arr)\n    col_max = np.max(arr, axis=0)\n    relmax = arr / col_max\n    return relmax\n\ndef get_rel99(arr):\n    arr = np.abs(arr)\n    col_99 = np.percentile(arr, 99.9, axis=0)\n    rel99 = arr / col_99\n    return rel99\n\ndef get_relmed(arr):\n    arr = np.abs(arr)\n    col_med = np.median(arr, axis=0)\n    relmed = arr / col_med\n    return relmed\n\ndef get_rel_ppavg(pre, post):\n    \n\n\n# Comparison functions\n\ndef get_diffmats(pre_avg, post_avg):\n    pre = pre_avg\n    post = post_avg\n    \n    # make diffmats\n    diffmat = pre_avg - post_avg\n    abs_diffmat = np.abs(diffmat)\n    # rel_diffmat = abs_diffmat / (np.abs(pre_avg) + np.abs(post_avg) + 1**-16)\n    # relmax_diffmat = get_relmax(abs_diffmat) \n    # relmed_diffmat = get_relmed(abs_diffmat) \n    # rel95_diffmat = get_rel99(abs_diffmat)\n\n    # new diff mat\n    pre_colwise_maxes = np.max(pre, axis=0)\n    post_colwise_maxes = np.max(post, axis=0)\n\n    tot_colwise_maxes = np.maximum(pre_colwise_maxes, post_colwise_maxes)\n\n    relmax3_diffmat = diffmat / tot_colwise_maxes\n\n    return relmax3_diffmat\n\n    #return (abs_diffmat, rel_diffmat, relmax_diffmat, relmed_diffmat, rel95_diffmat)\n\n\ndef get_summary(arr):\n    summary = {\n        \"mean\": np.mean(arr),\n        \"median\": np.median(arr),\n        \"std_dev\": np.std(arr),\n        \"minimum\": np.min(arr),\n        \"maximum\": np.max(arr),\n        \"total_sum\": np.sum(arr),\n        \"q1\": np.percentile(arr, 25),\n        \"q3\": np.percentile(arr, 75),\n        \"iqr\": np.percentile(arr, 75) - np.percentile(arr, 25)\n    }\n    return summary\n\n\ndef get_colwise_summary_df(arr):\n    # Initialize empty dictionary\n    col_summaries = {}\n    # Compute summary statistics for each column and store in dictionary\n    for col_index in range(arr.shape[1]):\n        col_name = col_index\n        col_data = arr[:, col_index]\n        col_summary = get_summary(col_data)\n        col_summaries[col_name] = col_summary\n    # Convert dictionary to DataFrame\n    col_summaries_df = pd.DataFrame(col_summaries).transpose()\n\n    return col_summaries_df\n\n\ndef plot_tols_vs_outs(arr, mintol, maxtol, steps):\n    # make x and y values\n    x = np.linspace(maxtol, mintol, steps)\n    y = []\n    for tol in x:\n        num_outs = len(get_outliers(arr, tol))\n        out_perc = num_outs/arr.size\n        print(f'tolerance: {round(tol, 2)}, num outs: {num_outs}, out percent: {out_perc}')\n        y.append(out_perc)\n    # plot x and y\n    plt.scatter(x, y)\n    plt.xlabel('tolerance')\n    plt.ylabel('percentage of outliers')\n    plt.show()\n\n    return None\n\n\ndef get_outliers(arr, tol):\n    outs = arr[arr &gt; tol]\n\n    return outs\n\n\ndef get_outlier_inds(arr, tol):\n    # get list of ind tuples\n    out_inds = np.where(arr &gt; tol)\n    out_inds_arr = np.array(list(zip(out_inds[0], out_inds[1])))\n    # get list of row and col inds\n    row_inds = out_inds[0]\n    col_inds = out_inds[1]\n\n    return [out_inds_arr, row_inds, col_inds]\n\n\ndef plot_hist(arr, bin_num, xlab='Value', ylab='Frequency', title='Histogram'):\n    plt.hist(arr, bins=bin_num)\n    plt.title(title)\n    plt.xlabel(xlab)\n    plt.ylabel(ylab)\n    plt.show()\n\n    return None\n\n\ndef make_outs_df(arr, tol):\n    # get outliers and their inds\n    outs = get_outliers(arr, tol)\n    all_inds, row_inds, col_inds = get_outlier_inds(arr, tol)\n    # make data\n    data = {\n        'name': df_targets['description'].iloc[col_inds],\n        'bin': row_inds,\n        'diff': outs,\n        'system_slims': df_targets['system_slims'].iloc[col_inds],\n        'cell_slims': df_targets['cell_slims'].iloc[col_inds],\n        'organ_slims': df_targets['organ_slims'].iloc[col_inds],\n        'developmental_slims': df_targets['developmental_slims'].iloc[col_inds]\n    }\n    # make df\n    df = pd.DataFrame(data)\n    # sort by ascending difference\n    df_sorted = df.sort_values('diff')\n\n    return df_sorted\n\n\ndef get_system_info(df):\n    # df must be from from make_outs_df\n    # prints a histogram of system counts\n    # outputs a tuple of the full system list and a dictionary of their counts\n\n    # make list of all systems and expand them\n    sys_compressed = df['system_slims'].tolist()\n    sys_expanded = []\n    for sys in sys_compressed:\n        if type(sys) == float:\n            continue\n        sys_list = sys.split(\", \")\n        sys_expanded += sys_list\n\n    # get counts of every system\n    sys_counts = Counter(sys_expanded)\n    sys_counts_sorted = dict(sorted(sys_counts.items(), key=lambda item: item[1], reverse=True))\n    \n    # plot bar graph of systems\n    keys = sys_counts_sorted.keys()\n    values = sys_counts_sorted.values()\n    plt.bar(keys, values)\n    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n    plt.xlabel('System')\n    plt.ylabel('Count')\n    plt.title('System Counts')\n    plt.show()\n\n    return (sys_expanded, sys_counts_sorted)\n\n\ndef get_cell_info(df):\n    # df must be from from make_outs_df\n    # prints a histogram of cell counts\n    # outputs a tuple of the full cell list and a dictionary of their counts\n\n    # make list of all cells and expand them\n    cell_compressed = df['cell_slims'].tolist()\n    cell_expanded = []\n    for cell in cell_compressed:\n        if type(cell) == float:\n            continue\n        cell_list = cell.split(\", \")\n        cell_expanded += cell_list\n\n    # get counts of every cell\n    cell_counts = Counter(cell_expanded)\n    cell_counts_sorted = dict(sorted(cell_counts.items(), key=lambda item: item[1], reverse=True))\n\n    # plot bar graph of cells\n    keys = cell_counts_sorted.keys()\n    values = cell_counts_sorted.values()\n    plt.bar(keys, values)\n    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n    plt.xlabel('Cell')\n    plt.ylabel('Count')\n    plt.title('Cell Counts')\n    plt.show()\n\n    return (cell_expanded, cell_counts_sorted)\n\n\ndef get_organ_info(df):\n    # input df must be from from make_outs_df\n    # prints a histogram of organ counts\n    # outputs a tuple of the full organ list and a dictionary of their counts\n\n    # make list of all organs and expand them\n    organ_compressed = df['organ_slims'].tolist()\n    organ_expanded = []\n    for organ in organ_compressed:\n        if type(organ) == float:\n            continue\n        organ_list = organ.split(\", \")\n        organ_expanded += organ_list\n\n    # get counts of every organ\n    organ_counts = Counter(organ_expanded)\n    organ_counts_sorted = dict(sorted(organ_counts.items(), key=lambda item: item[1], reverse=True))\n\n    # plot bar graph of organs\n    keys = organ_counts_sorted.keys()\n    values = organ_counts_sorted.values()\n    plt.bar(keys, values)\n    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n    plt.xlabel('Organ')\n    plt.ylabel('Count')\n    plt.title('Organ Counts')\n    plt.show()\n\n    return (organ_expanded, organ_counts_sorted)\n\n\ndef get_developmental_info(df):\n    # df must be from from make_outs_df\n    # prints a histogram of developmental stage counts\n    # outputs a tuple of the full developmental stage list and a dictionary of their counts\n\n    # make list of all developmental stages and expand them\n    developmental_compressed = df['developmental_slims'].tolist()\n    developmental_expanded = []\n    for developmental in developmental_compressed:\n        if type(developmental) == float:\n            continue\n        developmental_list = developmental.split(\", \")\n        developmental_expanded += developmental_list\n\n    # get counts of every developmental stage\n    developmental_counts = Counter(developmental_expanded)\n    developmental_counts_sorted = dict(sorted(developmental_counts.items(), key=lambda item: item[1], reverse=True))\n\n    # plot bar graph of developmental stages\n    keys = developmental_counts_sorted.keys()\n    values = developmental_counts_sorted.values()\n    plt.bar(keys, values)\n    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n    plt.xlabel('Developmental Stage')\n    plt.ylabel('Count')\n    plt.title('Developmental Stage Counts')\n    plt.show()\n\n    return (developmental_expanded, developmental_counts_sorted)"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#prepare-input-data",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#prepare-input-data",
    "title": "Import Libraries",
    "section": "Prepare input data",
    "text": "Prepare input data\n\n# targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n# df_targets = pd.read_csv(targets_txt, sep='\\t')\n\n\n# Load df\ndf_targets = pd.read_csv('/grand/TFXcan/imlab/users/lvairus/hackenf/targets_slims.csv')\n\n\ntrack_names = df_targets['description'].tolist()\n# df_targets['slims'].tolist() \n\n\nchrom_bed_downloads = pd.read_csv(\"https://uchicago.box.com/shared/static/du77wf31li38tciv8imivwu57svae03p.csv\")\nchrom_bed_downloads.index = chrom_bed_downloads[\"chroms\"]\n\n# chrom_bed_downloads.head(10)\n\n\nchr17_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr17_tss_by_gene.txt', sep='\\t')\namigo1_variations = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr17/chr17_GSDMB.bed', sep='\\t')\ngeuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\n# geuvadis_gene_expression.head(5)\n\n\n\n\n\n\n\n\ngene_id\ngene_name\nTargetID\nChr\nCoord\nHG00096\nHG00097\nHG00099\nHG00100\nHG00101\n...\nNA20810\nNA20811\nNA20812\nNA20813\nNA20814\nNA20815\nNA20816\nNA20819\nNA20826\nNA20828\n\n\n\n\n0\nENSG00000223972.4\nDDX11L1\nENSG00000223972.4\n1\n11869\n0.320818\n0.344202\n0.354225\n0.478064\n-0.102815\n...\n1.008605\n0.384489\n0.581284\n0.513981\n0.667449\n0.350890\n0.186103\n-0.037976\n0.405439\n0.199143\n\n\n1\nENSG00000227232.3\nWASH7P\nENSG00000227232.3\n1\n29806\n33.714457\n20.185174\n18.095407\n24.100871\n29.018719\n...\n30.980194\n34.086207\n39.678442\n29.643513\n27.120420\n29.121624\n31.117198\n32.047074\n22.798959\n23.563874\n\n\n2\nENSG00000243485.1\nMIR1302-11\nENSG00000243485.1\n1\n29554\n0.240408\n0.157456\n0.218806\n0.320878\n0.067833\n...\n0.065940\n0.228784\n0.140642\n0.283905\n0.273821\n0.286311\n0.324060\n0.049574\n0.255288\n0.157440\n\n\n3\nENSG00000238009.2\nRP11-34P13.7\nENSG00000238009.2\n1\n133566\n0.328272\n0.327932\n0.090064\n0.420443\n0.220269\n...\n0.274071\n0.384179\n0.533693\n0.307221\n0.307367\n0.400278\n0.612321\n0.666633\n0.281138\n1.346129\n\n\n4\nENSG00000239945.1\nRP11-34P13.8\nENSG00000239945.1\n1\n91105\n0.332171\n-0.032164\n0.017323\n0.424677\n0.214025\n...\n0.347323\n0.346744\n0.073580\n0.400396\n0.470517\n0.069749\n0.299353\n0.090019\n0.282554\n-0.157170\n\n\n\n\n5 rows × 467 columns\n\n\n\n\nmodel = Enformer(model_path) # here we load the model architecture.\n\nfasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data\n\n\ngene_intervals = collect_intervals(chromosomes=['17'], gene_list=['GSDMB'])\nprint(gene_intervals)\n\n{'GSDMB': ['17', 38060848, 38077313]}"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#testing-functions",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#testing-functions",
    "title": "Import Libraries",
    "section": "Testing Functions",
    "text": "Testing Functions\n\npre_avg, post_avg = run_predictions2('GSDMB', '17', 'NA12413')\n\n\n# get all diffmats\n#abs, rel, relmax, relmed, rel99 = get_diffmats(pre_avg, post_avg)\nrelmax3 = get_diffmats(pre_avg, post_avg)\n\n\n# get total summary of diffmat\nget_summary(relmax3)\n\n{'mean': -4.0492687e-05,\n 'median': -9.533909e-07,\n 'std_dev': 0.0024903365,\n 'minimum': -0.1878971,\n 'maximum': 0.07923598,\n 'total_sum': -192.76334,\n 'q1': -0.00017962247875402682,\n 'q3': 0.00019269661424914375,\n 'iqr': 0.00037231909300317056}\n\n\n\nlen(relmax[relmax&gt;0.01])\n\n2148076\n\n\n\n5313*896\n\n4760448\n\n\n\n# get column-wise summary for more information\ncolsum = get_colwise_summary_df(relmax3)\ncolsum\n\n\n\n\n\n\n\n\nmean\nmedian\nstd_dev\nminimum\nmaximum\ntotal_sum\nq1\nq3\niqr\n\n\n\n\n0\n-0.000041\n-3.508295e-06\n0.001134\n-0.023800\n0.005413\n-0.037025\n-3.861974e-05\n1.229089e-05\n0.000051\n\n\n1\n-0.000069\n-9.628113e-06\n0.000988\n-0.020328\n0.005106\n-0.061560\n-4.897090e-05\n6.240925e-06\n0.000055\n\n\n2\n-0.000093\n-6.310714e-06\n0.001052\n-0.026924\n0.004012\n-0.083052\n-8.107051e-05\n2.612843e-05\n0.000107\n\n\n3\n-0.000152\n-2.035273e-06\n0.002203\n-0.049426\n0.006036\n-0.135843\n-6.189638e-05\n4.713941e-05\n0.000109\n\n\n4\n-0.000009\n9.401141e-06\n0.001297\n-0.026551\n0.009480\n-0.008235\n-2.701409e-06\n3.257599e-05\n0.000035\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5308\n0.000027\n4.999537e-07\n0.000674\n-0.000311\n0.020153\n0.023799\n-2.199145e-07\n1.619765e-06\n0.000002\n\n\n5309\n0.000032\n-9.232160e-08\n0.000804\n-0.000148\n0.024023\n0.028505\n-8.665713e-07\n4.195065e-07\n0.000001\n\n\n5310\n-0.000005\n-1.788013e-06\n0.000252\n-0.001485\n0.006990\n-0.004523\n-6.904671e-06\n-2.567563e-08\n0.000007\n\n\n5311\n-0.000006\n-5.614372e-07\n0.000182\n-0.004187\n0.002925\n-0.005758\n-2.034222e-06\n-5.564325e-08\n0.000002\n\n\n5312\n0.000007\n-8.557877e-07\n0.000228\n-0.000811\n0.005456\n0.006325\n-3.352361e-06\n9.779096e-08\n0.000003\n\n\n\n\n5313 rows × 9 columns\n\n\n\n\nm_stats_df = colsum[['median', 'maximum', 'minimum', ]]#'maximum']]\n\nm_stats_df_sorted = m_stats_df.sort_values('median').reset_index(drop=True)\n\n\nfor column in m_stats_df_sorted.columns:\n    plt.plot(m_stats_df_sorted[column], label=column)\n\n# Add labels and legend\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Multiple Lines Plot')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\nplot_hist(colsum['mean'].tolist(), 200, title=\"mean\") \n\n\n\n\n\nplot_hist(colsum['maximum'].tolist(), 200, title=\"maximum\")\n\n\n\n\n\nplot_hist(colsum['minimum'].tolist(), 200, title=\"minimum\")\n\n\n\n\n\nsorted_data = np.sort(colsum['median'].tolist())\n\n# Plot the sorted array\nplt.plot(sorted_data)\nplt.xlabel('Index')\nplt.ylabel('Value')\nplt.title('Sorted Array')\nplt.show()\n\n\n\n\n\nplot_hist(colsum['median'].tolist(), 200, title=\"median\")\n\n\n\n\n\nnp.linspace(0.1, 1, 10)\n\narray([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])\n\n\n\n# plot tols to outs to find a good tolerance to use to determine outliers\n# tolerance is the biggest difference that's acceptable\n# if a difference is greater than the tolerance it'll be considered an outlier\nplot_tols_vs_outs(relmax3, 0.001, 0.01, 10)\n\ntolerance: 0.01, num outs: 15837, out percent: 0.0033267877309026378\ntolerance: 0.01, num outs: 20408, out percent: 0.00428699147643247\ntolerance: 0.01, num outs: 26592, out percent: 0.005586028877954344\ntolerance: 0.01, num outs: 35247, out percent: 0.007404135073001533\ntolerance: 0.01, num outs: 48007, out percent: 0.010084555067086123\ntolerance: 0.0, num outs: 67384, out percent: 0.014154970288510661\ntolerance: 0.0, num outs: 98803, out percent: 0.020754979363286817\ntolerance: 0.0, num outs: 154096, out percent: 0.03237006264956575\ntolerance: 0.0, num outs: 263000, out percent: 0.0552469011319943\ntolerance: 0.0, num outs: 517985, out percent: 0.10881013719717136\n\n\n\n\n\n\n1/896\n\n0.0011160714285714285\n\n\n\n# get the indices for each outlier\nall_inds, row_inds, col_inds = test.get_outlier_inds(relmax, 16)\n\n\n# plot histogram distribution of bins and tracks that have outliers\ntest.plot_hist(row_inds, 200), test.plot_hist(col_inds, 200)\n\n\n\n\n\n\n\n(None, None)\n\n\n\n# make df of info of outliers: track, bin#, difference, and slims\n# organized by increasing difference\ndf_relmax_tol16 = test.make_outs_df(relmax, 16)\ndf_relmax_tol16\n\n\n\n\n\n\n\n\nname\nbin\ndiff\nsystem\ncell\norgan\ndevelopmental\n\n\n\n\n4301\nCHIP:PHB2:K562\n158\n16.000057\nimmune system\ncancer cell, leukocyte, hematopoietic cell\nbodily fluid, blood\nmesoderm\n\n\n4380\nCHIP:H3K27ac:trophoblast female embryo (40 weeks)\n772\n16.000072\nnone\nnone\nembryo\nnone\n\n\n844\nCHIP:SIRT6:K562\n806\n16.000170\nimmune system\ncancer cell, leukocyte, hematopoietic cell\nbodily fluid, blood\nmesoderm\n\n\n4055\nCHIP:H2BK20ac:H9\n848\n16.000177\nnone\nembryonic cell, stem cell\nembryo\nnone\n\n\n2255\nCHIP:H2BK120ac:H9\n153\n16.000206\nnone\nembryonic cell, stem cell\nembryo\nnone\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4706\nCAGE:medulla oblongata, adult, pool1\n563\n100.000000\nNaN\nNaN\nNaN\nNaN\n\n\n4705\nCAGE:nucleus accumbens, adult, pool1\n563\n100.000000\nNaN\nNaN\nNaN\nNaN\n\n\n4704\nCAGE:occipital pole, adult, pool1\n563\n100.000000\nNaN\nNaN\nNaN\nNaN\n\n\n3882\nCHIP:H3K36me3:amnion male embryo (16 weeks)\n760\n100.000000\nreproductive system\nnone\nextraembryonic component, placenta\nmesoderm\n\n\n1629\nCHIP:H3K4me1:OCI-LY7\n552\n100.000000\nimmune system\ncancer cell, B cell, leukocyte, hematopoietic ...\nbodily fluid, blood\nmesoderm\n\n\n\n\n229423 rows × 7 columns\n\n\n\n\ndf_relmax_tol16[5:15]\n\n\n\n\n\n\n\n\nname\nbin\ndiff\nsystem\ncell\norgan\ndevelopmental\n\n\n\n\n4068\nCHIP:3xFLAG-PBX2:HepG2 genetically modified us...\n157\n16.000284\nendocrine system, exocrine system, digestive s...\ncancer cell, epithelial cell\nepithelium, endocrine gland, exocrine gland, l...\nendoderm\n\n\n3103\nCHIP:H3F3A:NCI-H929\n3\n16.000452\nimmune system, skeletal system\ncancer cell, B cell, leukocyte, hematopoietic ...\nbone marrow, bone element\nmesoderm\n\n\n1747\nCHIP:EZH2phosphoT487:GM23248\n160\n16.000462\nintegumental system\nfibroblast, connective tissue cell\nskin of body, limb, connective tissue\nectoderm\n\n\n3249\nCHIP:H3K36me3:A673\n358\n16.000467\nmusculature\ncancer cell\nmusculature of body\nmesoderm\n\n\n4643\nCHIP:GR:ChIP-seq, GR_HighDensity_DMI / hMSC / ...\n577\n16.000479\nNaN\nNaN\nNaN\nNaN\n\n\n4523\nCHIP:.:batch1_chrom1_LoVo_CEBPG_Rabbit_PassedQ...\n570\n16.000492\nNaN\nNaN\nNaN\nNaN\n\n\n1823\nCHIP:H3K9me3:CD4-positive, alpha-beta memory T...\n339\n16.000494\nimmune system\nCD4+ T cell, hematopoietic cell, T cell, leuko...\nbodily fluid, blood\nnone\n\n\n2301\nCHIP:H3K27me3:liver male adult (78 years)\n683\n16.000582\nendocrine system, exocrine system, digestive s...\nnone\nexocrine gland, endocrine gland, liver\nendoderm\n\n\n3756\nCHIP:NFXL1:GM12878\n802\n16.000587\nimmune system\nhematopoietic cell, B cell, leukocyte\nbodily fluid, blood\nmesoderm\n\n\n4305\nCHIP:H3K36me3:H1-hESC\n518\n16.000599\nnone\nembryonic cell, stem cell\nembryo\nnone\n\n\n\n\n\n\n\n\nrelmax16sys_packed = df_relmax_tol16['system_slims'].tolist()\nrelmax16sys = []\nfor sys in relmax16sys_packed:\n    if type(sys) == float:\n        continue\n    sys_list = sys.split(\", \")\n    relmax16sys += sys_list\n\nrelmax16sys\n\n['immune system',\n 'none',\n 'immune system',\n 'none',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'skeletal system',\n 'integumental system',\n 'musculature',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'exocrine system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'skeletal system',\n 'digestive system',\n 'reproductive system',\n 'excretory system',\n 'respiratory system',\n 'none',\n 'central nervous system',\n 'musculature',\n 'none',\n 'immune system',\n 'none',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'endocrine system',\n 'immune system',\n 'skeletal system',\n 'reproductive system',\n 'reproductive system',\n 'integumental system',\n 'excretory system',\n 'digestive system',\n 'reproductive system',\n 'central nervous system',\n 'peripheral nervous system',\n 'endocrine system',\n 'immune system',\n 'immune system',\n 'central nervous system',\n 'integumental system',\n 'immune system',\n 'reproductive system',\n 'central nervous system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'immune system',\n 'excretory system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'immune system',\n 'musculature',\n 'central nervous system',\n 'digestive system',\n 'excretory system',\n 'none',\n 'immune system',\n 'skeletal system',\n 'digestive system',\n 'excretory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'central nervous system',\n 'respiratory system',\n 'central nervous system',\n 'none',\n 'digestive system',\n 'excretory system',\n 'reproductive system',\n 'central nervous system',\n 'musculature',\n 'immune system',\n 'immune system',\n 'digestive system',\n 'reproductive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'reproductive system',\n 'integumental system',\n 'reproductive system',\n 'central nervous system',\n 'digestive system',\n 'excretory system',\n 'immune system',\n 'musculature',\n 'digestive system',\n 'none',\n 'circulatory system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'digestive system',\n 'respiratory system',\n 'reproductive system',\n 'integumental system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'endocrine system',\n 'excretory system',\n 'excretory system',\n 'none',\n 'immune system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'digestive system',\n 'integumental system',\n 'circulatory system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'excretory system',\n 'none',\n 'reproductive system',\n 'endocrine system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'integumental system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'respiratory system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'none',\n 'circulatory system',\n 'immune system',\n 'none',\n 'integumental system',\n 'excretory system',\n 'excretory system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'circulatory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'immune system',\n 'respiratory system',\n 'immune system',\n 'endocrine system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'exocrine system',\n 'integumental system',\n 'digestive system',\n 'central nervous system',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'skeletal system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'digestive system',\n 'reproductive system',\n 'skeletal system',\n 'immune system',\n 'immune system',\n 'digestive system',\n 'none',\n 'reproductive system',\n 'integumental system',\n 'integumental system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'immune system',\n 'none',\n 'central nervous system',\n 'immune system',\n 'respiratory system',\n 'circulatory system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'integumental system',\n 'none',\n 'circulatory system',\n 'immune system',\n 'circulatory system',\n 'central nervous system',\n 'digestive system',\n 'none',\n 'reproductive system',\n 'none',\n 'none',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'immune system',\n 'reproductive system',\n 'immune system',\n 'none',\n 'digestive system',\n 'digestive system',\n 'endocrine system',\n 'immune system',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'endocrine system',\n 'central nervous system',\n 'respiratory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'endocrine system',\n 'immune system',\n 'central nervous system',\n 'reproductive system',\n 'digestive system',\n 'integumental system',\n 'immune system',\n 'exocrine system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'immune system',\n 'musculature',\n 'excretory system',\n 'reproductive system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'digestive system',\n 'immune system',\n 'digestive system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'immune system',\n 'excretory system',\n 'none',\n 'digestive system',\n 'reproductive system',\n 'central nervous system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'none',\n 'none',\n 'integumental system',\n 'exocrine system',\n 'integumental system',\n 'central nervous system',\n 'integumental system',\n 'none',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'immune system',\n 'none',\n 'none',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'respiratory system',\n 'excretory system',\n 'immune system',\n 'central nervous system',\n 'exocrine system',\n 'integumental system',\n 'exocrine system',\n 'integumental system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'none',\n 'none',\n 'immune system',\n 'endocrine system',\n 'excretory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'musculature',\n 'circulatory system',\n 'excretory system',\n 'central nervous system',\n 'immune system',\n 'reproductive system',\n 'musculature',\n 'immune system',\n 'immune system',\n 'none',\n 'immune system',\n 'central nervous system',\n 'none',\n 'immune system',\n 'integumental system',\n 'none',\n 'immune system',\n 'none',\n 'excretory system',\n 'musculature',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'skeletal system',\n 'reproductive system',\n 'none',\n 'integumental system',\n 'none',\n 'immune system',\n 'endocrine system',\n 'endocrine system',\n 'exocrine system',\n 'integumental system',\n 'exocrine system',\n 'integumental system',\n 'reproductive system',\n 'respiratory system',\n 'none',\n 'excretory system',\n 'musculature',\n 'reproductive system',\n 'immune system',\n 'exocrine system',\n 'integumental system',\n 'musculature',\n 'immune system',\n 'none',\n 'digestive system',\n 'central nervous system',\n 'immune system',\n 'immune system',\n 'central nervous system',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'musculature',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'digestive system',\n 'circulatory system',\n 'exocrine system',\n 'integumental system',\n 'central nervous system',\n 'immune system',\n 'skeletal system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'none',\n 'integumental system',\n 'excretory system',\n 'reproductive system',\n 'immune system',\n 'none',\n 'none',\n 'immune system',\n 'musculature',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'musculature',\n 'excretory system',\n 'immune system',\n 'reproductive system',\n 'reproductive system',\n 'immune system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'musculature',\n 'exocrine system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'musculature',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'skeletal system',\n 'immune system',\n 'immune system',\n 'integumental system',\n 'reproductive system',\n 'endocrine system',\n 'digestive system',\n 'peripheral nervous system',\n 'circulatory system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'reproductive system',\n 'integumental system',\n 'reproductive system',\n 'circulatory system',\n 'excretory system',\n 'excretory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'musculature',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'central nervous system',\n 'none',\n 'immune system',\n 'central nervous system',\n 'endocrine system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'musculature',\n 'circulatory system',\n 'none',\n 'immune system',\n 'skeletal system',\n 'reproductive system',\n 'musculature',\n 'immune system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'respiratory system',\n 'central nervous system',\n 'skeletal system',\n 'integumental system',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'excretory system',\n 'immune system',\n 'respiratory system',\n 'excretory system',\n 'immune system',\n 'musculature',\n 'none',\n 'reproductive system',\n 'circulatory system',\n 'excretory system',\n 'musculature',\n 'digestive system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'integumental system',\n 'circulatory system',\n 'immune system',\n 'respiratory system',\n 'central nervous system',\n 'reproductive system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'none',\n 'endocrine system',\n 'reproductive system',\n 'immune system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'skeletal system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'immune system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'none',\n 'none',\n 'respiratory system',\n 'none',\n 'none',\n 'excretory system',\n 'excretory system',\n 'reproductive system',\n 'immune system',\n 'excretory system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'none',\n 'integumental system',\n 'immune system',\n 'immune system',\n 'digestive system',\n 'skeletal system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'respiratory system',\n 'central nervous system',\n 'musculature',\n 'circulatory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'exocrine system',\n 'integumental system',\n 'digestive system',\n 'reproductive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'integumental system',\n 'musculature',\n 'circulatory system',\n 'reproductive system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'central nervous system',\n 'central nervous system',\n 'skeletal system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'central nervous system',\n 'endocrine system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'immune system',\n 'digestive system',\n 'immune system',\n 'respiratory system',\n 'integumental system',\n 'immune system',\n 'immune system',\n 'none',\n 'digestive system',\n 'digestive system',\n 'reproductive system',\n 'integumental system',\n 'immune system',\n 'integumental system',\n 'immune system',\n 'immune system',\n 'reproductive system',\n 'none',\n 'central nervous system',\n 'respiratory system',\n 'immune system',\n 'skeletal system',\n 'excretory system',\n 'exocrine system',\n 'integumental system',\n 'central nervous system',\n 'skeletal system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'excretory system',\n 'central nervous system',\n 'central nervous system',\n 'central nervous system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'excretory system',\n 'excretory system',\n 'endocrine system',\n 'none',\n 'immune system',\n 'none',\n 'respiratory system',\n 'immune system',\n 'immune system',\n 'reproductive system',\n 'none',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'respiratory system',\n 'immune system',\n 'reproductive system',\n 'none',\n 'immune system',\n 'central nervous system',\n 'digestive system',\n 'immune system',\n 'digestive system',\n 'integumental system',\n 'immune system',\n 'central nervous system',\n 'reproductive system',\n 'peripheral nervous system',\n 'musculature',\n 'circulatory system',\n 'immune system',\n 'none',\n 'none',\n 'immune system',\n 'immune system',\n 'circulatory system',\n 'integumental system',\n 'immune system',\n 'central nervous system',\n 'exocrine system',\n 'integumental system',\n 'exocrine system',\n 'integumental system',\n 'none',\n 'exocrine system',\n 'integumental system',\n 'digestive system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'immune system',\n 'immune system',\n 'none',\n 'exocrine system',\n 'integumental system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'musculature',\n 'central nervous system',\n 'digestive system',\n 'immune system',\n 'exocrine system',\n 'integumental system',\n 'reproductive system',\n 'integumental system',\n 'integumental system',\n 'immune system',\n 'reproductive system',\n 'immune system',\n 'digestive system',\n 'excretory system',\n 'immune system',\n 'endocrine system',\n 'digestive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'none',\n 'circulatory system',\n 'central nervous system',\n 'peripheral nervous system',\n 'exocrine system',\n 'integumental system',\n 'digestive system',\n 'immune system',\n 'circulatory system',\n 'excretory system',\n 'immune system',\n 'musculature',\n 'immune system',\n 'respiratory system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'integumental system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'central nervous system',\n 'respiratory system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'none',\n 'none',\n 'endocrine system',\n 'integumental system',\n 'none',\n 'exocrine system',\n 'integumental system',\n 'digestive system',\n 'immune system',\n 'reproductive system',\n 'circulatory system',\n 'none',\n 'skeletal system',\n 'excretory system',\n 'immune system',\n 'none',\n 'musculature',\n 'excretory system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'digestive system',\n 'endocrine system',\n 'reproductive system',\n 'none',\n 'none',\n 'excretory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'central nervous system',\n 'central nervous system',\n 'none',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'musculature',\n 'digestive system',\n 'none',\n 'none',\n 'excretory system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'excretory system',\n 'excretory system',\n 'central nervous system',\n 'musculature',\n 'digestive system',\n 'musculature',\n 'peripheral nervous system',\n 'immune system',\n 'skeletal system',\n 'immune system',\n 'immune system',\n 'central nervous system',\n 'immune system',\n 'none',\n 'central nervous system',\n 'none',\n 'reproductive system',\n 'central nervous system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'musculature',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'reproductive system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'circulatory system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'reproductive system',\n 'endocrine system',\n 'immune system',\n 'skeletal system',\n 'excretory system',\n 'excretory system',\n 'central nervous system',\n 'immune system',\n 'central nervous system',\n 'digestive system',\n 'immune system',\n 'reproductive system',\n 'exocrine system',\n 'integumental system',\n 'musculature',\n 'digestive system',\n 'central nervous system',\n 'immune system',\n 'digestive system',\n 'central nervous system',\n 'immune system',\n 'central nervous system',\n 'integumental system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'central nervous system',\n 'none',\n 'immune system',\n 'skeletal system',\n 'circulatory system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'immune system',\n 'skeletal system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'digestive system',\n 'reproductive system',\n 'none',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'excretory system',\n 'none',\n 'none',\n 'immune system',\n 'digestive system',\n 'integumental system',\n 'respiratory system',\n 'none',\n 'reproductive system',\n 'immune system',\n 'central nervous system',\n 'peripheral nervous system',\n 'immune system',\n 'immune system',\n 'excretory system',\n 'none',\n 'none',\n 'central nervous system',\n 'digestive system',\n 'immune system',\n 'central nervous system',\n 'central nervous system',\n 'digestive system',\n 'central nervous system',\n 'none',\n 'reproductive system',\n 'excretory system',\n 'respiratory system',\n 'exocrine system',\n 'integumental system',\n 'none',\n 'immune system',\n 'central nervous system',\n 'respiratory system',\n 'digestive system',\n 'immune system',\n 'digestive system',\n 'exocrine system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'immune system',\n 'immune system',\n 'excretory system',\n 'circulatory system',\n 'exocrine system',\n 'integumental system',\n 'reproductive system',\n 'excretory system',\n 'digestive system',\n 'musculature',\n 'digestive system',\n 'immune system',\n 'none',\n 'immune system',\n 'excretory system',\n 'integumental system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'respiratory system',\n 'reproductive system',\n 'endocrine system',\n 'exocrine system',\n 'digestive system',\n 'endocrine system',\n ...]\n\n\n\nsys_counts = Counter(relmax16sys)\nsorted_sys_counts = dict(sorted(sys_counts.items(), key=lambda item: item[1], reverse=True))\n\nsorted_sys_counts\n\n{'immune system': 70041,\n 'digestive system': 32201,\n 'none': 26820,\n 'exocrine system': 19766,\n 'central nervous system': 18958,\n 'integumental system': 18874,\n 'endocrine system': 18808,\n 'reproductive system': 17530,\n 'musculature': 11953,\n 'excretory system': 10607,\n 'respiratory system': 8971,\n 'circulatory system': 8123,\n 'skeletal system': 7019,\n 'peripheral nervous system': 1823,\n 'sensory system': 95}\n\n\n\nkeys = sorted_sys_counts.keys()\nvalues = sorted_sys_counts.values()\n\n# Create a bar plot\nplt.bar(keys, values)\nplt.xticks(rotation=90)  # Rotate x-axis labels for better readability\nplt.xlabel('System')\nplt.ylabel('Count')\nplt.title('System Counts')\n\nplt.show()\n\n\n\n\n\nlen(test.get_outliers(relmax, 16)) / 5313 / 896\n\n0.04819357337796779\n\n\n\ntest.plot_tol_vs_outs(relmax, 1, 100, 10)\n\ntolerance: 100, num outs: 0, out percent: 0.0\ntolerance: 89, num outs: 7912, out percent: 0.0016620284477427334\ntolerance: 78, num outs: 11997, out percent: 0.002520140961522949\ntolerance: 67, num outs: 18194, out percent: 0.0038219091984619934\ntolerance: 56, num outs: 27914, out percent: 0.00586373383345433\ntolerance: 45, num outs: 44080, out percent: 0.009259632706837675\ntolerance: 34, num outs: 73402, out percent: 0.015419137022397892\ntolerance: 23, num outs: 137315, out percent: 0.028844974254523943\ntolerance: 12, num outs: 332400, out percent: 0.0698253609744293\ntolerance: 1, num outs: 2148076, out percent: 0.4512340015057406\n\n\n\n\n\n\n# get_summary(self, arr):\n# def get_outliers(self, arr, tol):\n# def get_outlier_inds(self, arr, tol):\n# def plot_hist(self, arr, bin_num):\n# def plot_tol_vs_outs(self, arr, mintol, maxtol, steps):\n# def make_df(self, arr, tol):"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#finding-out-if-the-same-columns",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#finding-out-if-the-same-columns",
    "title": "Import Libraries",
    "section": "finding out if the same columns",
    "text": "finding out if the same columns"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#run-predictions",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#run-predictions",
    "title": "Import Libraries",
    "section": "Run Predictions",
    "text": "Run Predictions\nWe’ll pick one individual at random.\n\n# rand_individual = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], replace=False) # individuals we are interested in\nrand_individual = 'NA12413'\n\n'NA12413'\n\n\n\ngene = 'GSDMB'\ngene_interval = gene_intervals[gene]\ntarget_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\ntarget_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))\nwindow_coords = target_interval.resize(SEQUENCE_LENGTH)\ncur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n\n\nhaplo_1, haplo_2 = geno_to_seq(gene, rand_individual)\n\nhaplo_1_enc = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\nhaplo_2_enc = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\naverage_enc = np.add(haplo_1_enc, haplo_2_enc) / 2\n\n\nprediction_1 = model.predict_on_batch(haplo_1_enc)['human'][0]\nprediction_2 = model.predict_on_batch(haplo_2_enc)['human'][0]\n\npost_average = (prediction_1 + prediction_2) / 2\npre_average = model.predict_on_batch(average_enc)['human'][0]"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#comparing-predictions",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#comparing-predictions",
    "title": "Import Libraries",
    "section": "Comparing Predictions",
    "text": "Comparing Predictions\n\npre_average2, post_average2 = run_predictions2(gene, '17', rand_individual)\n\nCurrently on gene GSDMB, and predicting on individual NA12413...\n\n\n\ndiff = pre_average - post_average\n\nabs_diff = np.sqrt(np.square(diff))\n\nrel_diff = (abs_diff) / ((pre_average + post_average) + 10**-16)\n\n\n# Summary Statistics of Absolute Differece\narr = abs_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.011741725\nMedian: 0.0024814606\nStandard Deviation: 0.06555718\nMinimum: 0.0\nMaximum: 10.2612915\nSum: 55895.87\n\n\n\n# Summary Statistics of Relative Difference\narr = rel_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.00026652514\nMedian: 8.4674466e-05\nStandard Deviation: 0.0011749842\nMinimum: 0.0\nMaximum: 0.24099354\nSum: 1268.779\n\n\n\nbigDiff = abs_diff[abs_diff&gt;1]\nlen(bigDiff)\n\n72\n\n\n\n# Plot the histogram\nplt.hist(bigDiff, bins=20)\n\n# Add labels and title\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Histogram')\n\n# Display the plot\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "title": "Import Libraries",
    "section": "In which tracks is it not precise?",
    "text": "In which tracks is it not precise?\n\n# max diff tolerance is 1. If a diff is greater than 1 we will count it as too big\ntolerance = 1\n\nindices = np.where(abs_diff &gt; tolerance)\nindices[0][0], indices[1][0]\n\nind_of_big_diffs = np.array(list(zip(indices[0], indices[1])))\nlen(ind_of_big_diffs), ind_of_big_diffs\n\n(72,\n array([[ 773, 4740],\n        [ 773, 4746],\n        [ 773, 4747],\n        [ 773, 4748],\n        [ 773, 4754],\n        [ 773, 4759],\n        [ 773, 4760],\n        [ 773, 4764],\n        [ 773, 4766],\n        [ 773, 4770],\n        [ 773, 4777],\n        [ 773, 4782],\n        [ 773, 4797],\n        [ 773, 4808],\n        [ 773, 4810],\n        [ 773, 4815],\n        [ 773, 4816],\n        [ 773, 4817],\n        [ 773, 4818],\n        [ 773, 4819],\n        [ 773, 4868],\n        [ 773, 4869],\n        [ 773, 4870],\n        [ 773, 4874],\n        [ 773, 4877],\n        [ 773, 4879],\n        [ 773, 4881],\n        [ 773, 4884],\n        [ 773, 4885],\n        [ 773, 4886],\n        [ 773, 4887],\n        [ 773, 4890],\n        [ 773, 4892],\n        [ 773, 4893],\n        [ 773, 4897],\n        [ 773, 4898],\n        [ 773, 4900],\n        [ 773, 4902],\n        [ 773, 4905],\n        [ 773, 4906],\n        [ 773, 4909],\n        [ 773, 4920],\n        [ 773, 5056],\n        [ 773, 5057],\n        [ 773, 5072],\n        [ 773, 5073],\n        [ 773, 5078],\n        [ 773, 5079],\n        [ 773, 5080],\n        [ 773, 5106],\n        [ 773, 5110],\n        [ 773, 5115],\n        [ 773, 5127],\n        [ 773, 5144],\n        [ 773, 5150],\n        [ 773, 5196],\n        [ 773, 5198],\n        [ 773, 5212],\n        [ 773, 5213],\n        [ 773, 5236],\n        [ 773, 5238],\n        [ 773, 5300],\n        [ 829, 2652],\n        [ 830,  733],\n        [ 830,  746],\n        [ 830,  801],\n        [ 830,  810],\n        [ 830,  812],\n        [ 830,  814],\n        [ 830,  815],\n        [ 830,  822],\n        [ 830, 3647]]))\n\n\n\ncols\n\n# all the indices of the columns where the diff exceeds tolerance\ncol_inds = indices[1]\n\n\ncounts = Counter(col_inds)\n[(key,value) for key,value in counts.items() if value &gt; 8]\n\n[]\n\n\n\nprint(f\"Number of unique col ind: {len(set(col_inds))} \\nTotal col ind: {len(col_inds)}\")\n\nNumber of unique col ind: 72 \nTotal col ind: 72\n\n\n\nplt.hist(col_inds, bins=200)  # Specify the number of bins\nplt.title('Histogram of col indexes')\nplt.show()\n\n\n\n\nAnalysis: the difference exceeds the tolerance in 227 unique columns that are pretty evenly distributed, so enformer doesn’t necessarily do better or worse with averaging before/after in any particular cell line\ni want to get the amount of times it affects each col 227 uniqe cols\n\n\nrows\n\nlen(set(indices[0])), len(indices[0])\n\n(3, 72)\n\n\n\n# Summary Statistics of rows\narr1 = indices[0]\n\nprint(\"Mean:\", np.mean(arr1))\nprint(\"Median:\", np.median(arr1))\nprint(\"Standard Deviation:\", np.std(arr1))\nprint(\"Minimum:\", np.min(arr1))\nprint(\"Maximum:\", np.max(arr1))\nprint(\"Sum:\", np.sum(arr1))\n\nq1 = np.percentile(arr, 25)\nq3 = np.percentile(arr, 75)\niqr = q3 - q1\n\nprint(\"Q1:\", q1)\nprint(\"Q3:\", q3)\nprint(\"Interquartile Range:\", iqr)\n\nMean: 780.9027777777778\nMedian: 773.0\nStandard Deviation: 19.678075590631757\nMinimum: 773\nMaximum: 830\nSum: 56225\n\n\n\nplt.hist(indices[0], bins=30)  # Specify the number of bins\nplt.title('Histogram of row indexes')\nplt.show()\n\n\n\n\nAnalysis: There are only a few specific locations where enformer does worse"
  },
  {
    "objectID": "posts/2023-07-19-compare-avg3/Compare_averages.html#comparing-across-tracks",
    "href": "posts/2023-07-19-compare-avg3/Compare_averages.html#comparing-across-tracks",
    "title": "Import Libraries",
    "section": "Comparing across tracks",
    "text": "Comparing across tracks\n\nres = []\nfor i in range(5313):\n    pre_track = pre_average[:, i]\n    post_track = post_average[:, i]\n    corr = np.corrcoef(pre_track, post_track)[0][1]\n    res.append(corr)\n\nThe results from both methods are nearly identical.\n\nprint(min(res), max(res))\n\n0.9989958894392978 0.9999999912865261"
  },
  {
    "objectID": "posts/2023-07-07-parsl/index.html",
    "href": "posts/2023-07-07-parsl/index.html",
    "title": "Intro to Parsl",
    "section": "",
    "text": "Parsl is a python package that lets you run multiple functions at once (in parallel).\nParsl automatically finds all the processors available for use and passes in your function calls to them so that they can be run asyncronously (at the same time without interrupting your main workflow).\nSo say you have a normal python function you want to run but it takes 10 seconds to finish. If you want to call that function normally you’ll have to wait until it’s finished running before you can do anything else.\nNow say you want to run that function 100 times. That’ll take 17 minutes to finish running before you can do anything else.\nParsl can help shorten the time it takes for all 100 runs to finish AND let you work on other code while you wait for that.\nVocab: - app: parsl instance of your function - run in parallel: run multiple functions at the same time - run asyncronously: run a function at the same time as others without interrupting main workflow - submitting a job: calling a function that has a parsl decorator\n\nUsing Parcel\nThe following function takes some text and prints it out after one second\ndef function1(text):\n  import time\n  time.sleep(1)\n  print(text)\n  return\n\nThe following takes 10 seconds to finish running\nfor i in range(10):\n  function1(i)\n  \nTo use parsl to run this in parallel, all we have to do is import it and add a decorator to our function\nimport parsl\nfrom parsl.app.app import python_app\n\n@python_app\ndef function2(text):\n  import time\n  time.sleep(1)\n  print(text)\n  return\n\nUsing this new function, the following takes less time to finish (the specific time depends on how many processors(?) you have available to use in parallel)\nfor i in range(10):\n  function2(i)\n  \n\n\nAppFutures"
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html",
    "title": "blog hackenf",
    "section": "",
    "text": "Authors: Saideep Gona, Temidayo Adeluwa\nAcknowledgement: - Boxiang Liu - Festus Nyasimi (for providing us with Predixcan predictions)\nDate: Saturday April 2, 2022\nCopyright 2021 DeepMind Technologies Limited\nLicensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n https://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#genetic-medicine-deep-learning-hackathon-2022",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#genetic-medicine-deep-learning-hackathon-2022",
    "title": "blog hackenf",
    "section": "",
    "text": "Authors: Saideep Gona, Temidayo Adeluwa\nAcknowledgement: - Boxiang Liu - Festus Nyasimi (for providing us with Predixcan predictions)\nDate: Saturday April 2, 2022\nCopyright 2021 DeepMind Technologies Limited\nLicensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n https://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#introduction",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#introduction",
    "title": "blog hackenf",
    "section": "Introduction",
    "text": "Introduction\nIn this notebook, we explore how Enformer can be used to predict the expression of protein-coding genes. We utilized some code from the original Enformer usage colab notebook. Here, we showcase how the Enformer model can be used to predict gene expression on a GEUVADIS/1000 genomes dataset, and compare the predictions with true expression.\n“Effective gene expression prediction from sequence by integrating long-range interactions”\nŽiga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, David R. Kelley\n\nSteps\nThis notebook demonstrates how to - Prepare inputs for Enformer to make predictions - Make predictions with Enformer and produce figures - Compare predictions with true expression"
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#setup",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#setup",
    "title": "blog hackenf",
    "section": "Setup",
    "text": "Setup\nGoogle Colab gives us some GPU access. This limited GPU is available to anyone with a Google account, who has signed up to use Colaboratory. We will begin by changing the runtime type to GPU. Follow the instruction below by clicking on “Runtime -&gt; Change runtime type -&gt; GPU” in the menu bar below the title of this notebook.\nStart the colab kernel with GPU: Runtime -&gt; Change runtime type -&gt; GPU\nBelow, we import tensorflow as tf, and check that the runtime has been changed to GPU.\n\n!which pip\n\n/home/lvairus/venvs/polaris/2023-01-10/bin/pip\n\n\n\nimport tensorflow as tf\n# Make sure the GPU is enabled\nassert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -&gt; Change runtime type -&gt; GPU'\n\nkipoiseq is a package that helps us to extract sequences from fasta files given some intervals. We will install the package.\n\n#%pip install kipoiseq==0.5.2 --quiet &gt; /dev/null\n# You can ignore the pyYAML error\n\nBiopython is a python package that helps us do many bioinfomatic analysis in python\n\n#%pip install Biopython\n\n\nSetting up our environments\nWe need to have some packages imported to help us do cool stuff.\n\n!which python\nimport tensorflow_hub as hub # for interacting with saved models and tensorflow hub\nimport joblib\nimport gzip # for manipulating compressed files\nimport kipoiseq # for manipulating fasta files\nfrom kipoiseq import Interval # same as above, really\nimport pyfaidx # to index our reference genome file\nimport pandas as pd # for manipulating dataframes\nimport numpy as np # for numerical computations\nimport matplotlib.pyplot as plt # for plotting\nimport matplotlib as mpl # for plotting\nimport seaborn as sns # for plotting\nimport pickle # for saving large objects\nimport os, sys # functions for interacting with the operating system\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n/home/lvairus/venvs/polaris/2023-01-10/bin/python\n\n\nNext,\nWe want to define some paths to save downloaded files for the duration of this notebook. These will be wiped off by Google as soon as we are done.\n\ntransform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\nmodel_path = 'https://tfhub.dev/deepmind/enformer/1'\nfasta_file = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa'\n\nWe may inspect the tracks used to train the model. The CAGE prediction corresponding to B lymphoblastoid cell line is index 5110. We use B lymphoblastoid cell line predictions here because that is the cell line used to generate GEUVADIS gene expression data. You can copy the https link, paste in another tab in your browser and look through the large txt file for other tracks.\n\n# Download targets from Basenji2 dataset\n# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')\ndf_targets[df_targets.index==5110]\n\n\n\n\n\n\n\n\nindex\ngenome\nidentifier\nfile\nclip\nscale\nsum_stat\ndescription\n\n\n\n\n5110\n5110\n0\nCNhs12333\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:B lymphoblastoid cell line: GM12878 ENCOD...\n\n\n\n\n\n\n\n\n\nDownload files\nWe need to download some files. Give it a moment. We will download the following files: - The reference genome fasta file (we will also index this file in the process) - A text file for the transcription start sites for each chromosome - Per chromosome files that has annotation for the genes - A compressed file that contains the variant bed files for the genes and their locations.\nCredit to Genome Reference Consortium: https://www.ncbi.nlm.nih.gov/grc\nSchneider et al 2017 http://dx.doi.org/10.1101/gr.213611.116: Evaluation of GRCh38 and de novo haploid genome assemblies demonstrates the enduring quality of the reference assembly\nMake a data directory, and download the necessary bed files and chromosome annotation files\nNB: You may decide to download these files into your “/content/drive/MyDrive/Enformer_Hackathon_2022/” directory. You don’t need to do this. But if you want permanent access to the files we use in this notebook, you can change the path from “/grand/TFXcan/imlab/users/lvairus/hackenf/data/” to “/content/drive/MyDrive/Enformer_Hackathon_2022/”, and modify what you need accordingly.\nThe next line of code will download the reference genome fasta file and index this file.\n\nprint(fasta_file)\n!ls -lth {fasta_file}\n\n/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa\n-rw-r--r-- 1 lvairus users 3.0G Jul  6 18:23 /grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa\n\n\n\n# reference genome and indexed\n# !mkdir /home/lvairus/hackenf/data/\n!wget -O - https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz | gunzip -c &gt; {fasta_file}\npyfaidx.Faidx(fasta_file)\n\n--2023-07-06 19:11:29--  https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz\nResolving proxy.alcf.anl.gov (proxy.alcf.anl.gov)... 140.221.69.42\nConnecting to proxy.alcf.anl.gov (proxy.alcf.anl.gov)|140.221.69.42|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 948731419 (905M) [application/x-gzip]\nSaving to: ‘STDOUT’\n\n-                     0%[                    ]       0  --.-KB/s               -                   100%[===================&gt;] 904.78M  52.4MB/s    in 17s     \n\n2023-07-06 19:11:46 (54.3 MB/s) - written to stdout [948731419/948731419]\n\n\n\nFaidx(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa\")\n\n\nThe next lines of code will download the variation bed files, and we have created links to help us download the variation bed files for each chromosome, for each gene.\n\nchrom_bed_downloads = pd.read_csv(\"https://uchicago.box.com/shared/static/du77wf31li38tciv8imivwu57svae03p.csv\")\nchrom_bed_downloads.index = chrom_bed_downloads[\"chroms\"]\n\nchrom_bed_downloads.head(5)\n\n\n\n\n\n\n\n\nchroms\nlink\n\n\nchroms\n\n\n\n\n\n\n1\n1\nhttps://uchicago.box.com/shared/static/9q9n4a0...\n\n\n2\n2\nhttps://uchicago.box.com/shared/static/1tk6a3f...\n\n\n3\n3\nhttps://uchicago.box.com/shared/static/77ldwqq...\n\n\n4\n4\nhttps://uchicago.box.com/shared/static/s0g48al...\n\n\n5\n5\nhttps://uchicago.box.com/shared/static/yafgxb1...\n\n\n\n\n\n\n\nWe will define a function to help us download bed variation files for a given gene or list of genes\n\ndef download_chrom_beds(chromosome, genes, downloads_table=chrom_bed_downloads):\n  '''\n  Downloads bed/variation files for a chromosome and list of genes\n  '''\n\n  link = downloads_table.loc[str(chromosome), \"link\"]\n  chr_which = 'chr' + chromosome\n  for gene in genes:\n    if os.path.exists('/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr' + chromosome + '/chr' + chromosome + '_' + gene + '.bed'): # if the file is in the folder, no need to download again\n      continue\n    !curl -L {link} --output /grand/TFXcan/imlab/users/lvairus/hackenf/data/chr_{chromosome}_bed.tar.gz && cd /grand/TFXcan/imlab/users/lvairus/hackenf/data/ && tar -zxf /grand/TFXcan/imlab/users/lvairus/hackenf/data/chr_{chromosome}_bed.tar.gz ./individual_beds/{chr_which}/{chr_which}_{gene}.bed\n\n    # remove the download tar.gz file\n    !rm /grand/TFXcan/imlab/users/lvairus/hackenf/data/chr_{chromosome}_bed.tar.gz\n\nWe don’t need this function yet. But we can test out how it works.\nAssuming we want to download the variation files for ‘ERAP1’, which is located on chromosome 5…\nThis will download the bed file into /grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr5/\n\ndownload_chrom_beds(chromosome = '5', genes=['ERAP1', 'ERAP2'])\n\nAnd when you need the file, you can read it in like…\n\nerap1_variations = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr5/chr5_ERAP1.bed', sep='\\t')\nerap1_variations.head(5)\n\n\n\n\n\n\n\n\n#CHROM\nPOS\nREF\nALT\nHG00096\nHG00097\nHG00099\nHG00100\nHG00101\nHG00102\n...\nNA20810\nNA20811\nNA20812\nNA20813\nNA20814\nNA20815\nNA20816\nNA20819\nNA20826\nNA20828\n\n\n\n\n0\n5\n95923584\nT\nC\n1|0\n0|1\n0|0\n0|0\n0|1\n0|1\n...\n0|0\n1|0\n1|0\n0|0\n0|1\n0|0\n0|0\n0|1\n0|0\n1|0\n\n\n1\n5\n95923823\nA\nG\n1|0\n0|1\n0|0\n0|0\n0|1\n0|1\n...\n0|0\n1|0\n1|0\n0|0\n0|1\n0|0\n0|0\n0|1\n0|0\n1|0\n\n\n2\n5\n95923836\nG\nA\n1|0\n0|1\n0|0\n0|0\n0|1\n0|1\n...\n0|0\n1|0\n1|0\n0|0\n0|1\n0|0\n0|0\n0|1\n0|0\n1|0\n\n\n3\n5\n95924552\nT\nC\n1|0\n0|1\n0|0\n0|0\n0|1\n0|1\n...\n0|0\n1|0\n1|0\n0|0\n0|1\n0|0\n0|0\n0|1\n0|0\n1|0\n\n\n4\n5\n95925045\nT\nA\n1|0\n0|1\n0|0\n0|0\n0|1\n0|1\n...\n0|0\n1|0\n1|0\n0|0\n0|1\n0|0\n0|0\n0|1\n0|0\n1|0\n\n\n\n\n5 rows × 459 columns\n\n\n\nYou can pass in a list of genes as long as they are all located on that chromosome.\nIn the next block of code, we download the TSS for each chromosome and the genes in that chromosome, as wells as the per chromosome gene annotations. We need this information to estimate predictions.\n\n!curl -L https://uchicago.box.com/shared/static/perc3uabzzd267cbp8zc0inwgrmur7pu.gz --output /grand/TFXcan/imlab/users/lvairus/hackenf/data/chr_tss.tar.xz && cd /grand/TFXcan/imlab/users/lvairus/hackenf/data/ && tar -zxf /grand/TFXcan/imlab/users/lvairus/hackenf/data/chr_tss.tar.xz\n\n!mkdir -p /grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms #creates a folder to hold our files\n!curl -L https://uchicago.box.com/shared/static/e2kiwrjlgqqio0pc37a2iz7l5bqbv57u.gz --output /grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_chroms.tar.gz && cd /grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/ && tar -zxf /grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_chroms.tar.gz\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100     7    0     7    0     0      7      0 --:--:-- --:--:-- --:--:--    10\n100 1783k  100 1783k    0     0  1151k      0  0:00:01  0:00:01 --:--:-- 5634k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100     6    0     6    0     0      6      0 --:--:-- --:--:-- --:--:--    11\n100  728k  100  728k    0     0   595k      0  0:00:01  0:00:01 --:--:--  595k\n\n\n\n\nHow do we want to go about using Enformer given all these files we just downloaded?\nAs we know, enformer’s input is a single strand genome sequence. Yet, we are interested in predicting on population level data which includes individual-specific variation. To get around this limitation, we will treat each individual as the sum of their haplotypes. Using the phased variant data around each gene (stored in the variant bed files) to modify the reference sequence, we can create two distinct haplotype sequences for each individual. The sum of both of Enformer’s haplotype predictions serves as an individual-specific, additive estimate which we can correlate with true predictions. Together, the files we downloaded give us all the information we need to build these haplotype sequences.\nAlthought enformer predicts a wide array of functional output, we will focus here on gene expression in lymphoblastoid cells allowing for correlation against ground truth Geuvadis gene expression data.\nThere are many functions that we have defined in the next code block. You can explore them later, but for now, simply run the block by clicking on the play button.\n\n\nCode\nNext, we have some functions that will help us along the way. Classes and methods defined in this code block can be found in the original Enformer usage colab notebook.\n\n# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\nSEQUENCE_LENGTH = 393216\n\nclass Enformer:\n\n  def __init__(self, tfhub_url):\n    self._model = hub.load(tfhub_url).model\n\n  def predict_on_batch(self, inputs):\n    predictions = self._model.predict_on_batch(inputs)\n    return {k: v.numpy() for k, v in predictions.items()}\n\n  @tf.function\n  def contribution_input_grad(self, input_sequence,\n                              target_mask, output_head='human'):\n    input_sequence = input_sequence[tf.newaxis]\n\n    target_mask_mass = tf.reduce_sum(target_mask)\n    with tf.GradientTape() as tape:\n      tape.watch(input_sequence)\n      prediction = tf.reduce_sum(\n          target_mask[tf.newaxis] *\n          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n\n    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n    input_grad = tf.squeeze(input_grad, axis=0)\n    return tf.reduce_sum(input_grad, axis=-1)\n\n\nclass EnformerScoreVariantsRaw:\n\n  def __init__(self, tfhub_url, organism='human'):\n    self._model = Enformer(tfhub_url)\n    self._organism = organism\n\n  def predict_on_batch(self, inputs):\n    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n\n    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n\n\nclass EnformerScoreVariantsNormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human'):\n    assert organism == 'human', 'Transforms only compatible with organism=human'\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      transform_pipeline = joblib.load(f)\n    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)\n\n\nclass EnformerScoreVariantsPCANormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human', num_top_features=500):\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      self._transform = joblib.load(f)\n    self._num_top_features = num_top_features\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)[:, :self._num_top_features]\n\n\n# TODO(avsec): Add feature description: Either PCX, or full names.\n\n\n# @title `variant_centered_sequences`\n\nclass FastaStringExtractor:\n\n    def __init__(self, fasta_file):\n        self.fasta = pyfaidx.Fasta(fasta_file)\n        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n        print(self._chromosome_sizes)\n\n    def extract(self, interval: Interval, **kwargs) -&gt; str:\n        # Truncate interval if it extends beyond the chromosome lengths.\n        chromosome_length = self._chromosome_sizes[interval.chrom]\n        trimmed_interval = Interval(interval.chrom,\n                                    max(interval.start, 0),\n                                    min(interval.end, chromosome_length),\n                                    )\n        # pyfaidx wants a 1-based interval\n        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n                                          trimmed_interval.start + 1,\n                                          trimmed_interval.stop).seq).upper()\n        # Fill truncated values with N's.\n        pad_upstream = 'N' * max(-interval.start, 0)\n        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n        return pad_upstream + sequence + pad_downstream\n\n    def close(self):\n        return self.fasta.close()\n\n\ndef one_hot_encode(sequence):\n  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n\n\n\n# @title `plot_tracks`\n\ndef plot_tracks(tracks, interval, height=1.5):\n  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n  for ax, (title, y) in zip(axes, tracks.items()):\n    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n    ax.set_title(title)\n    sns.despine(top=True, right=True, bottom=True)\n  ax.set_xlabel(str(interval))\n  plt.tight_layout()\n\nHere, we define some utility functions for ourselves, to help us make predictions and analyse our predictions.\n\nimport Bio\n\nfrom Bio.Seq import Seq\ndef create_rev_complement(dna_string):\n    return(str(Seq(dna_string).reverse_complement()))\n\n\ndef prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n\n  '''\n\n  Parameters:\n          predicitions (A numpy array): All predictions from the track\n          gene (a gene name, character): a gene\n          tss_df: a list of dataframe of genes and their transcription start sites\n  Returns:\n          A dictionary of cage experiment predictions and a list of transcription start sites\n\n  '''\n\n  output = dict()\n  for tdf in tss_df:\n    if gene not in tdf.genes.values:\n      continue\n    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n    gene_tss_list = list(set(gene_tss_list))\n  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n  output['gene_TSS'] = gene_tss_list # a list\n\n\n  return(output) # a dictionary\n\ndef quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n\n  '''\n  Parameters:\n          low_range (int): The lower interval\n          TSS (list of integers): A list of TSS for a gene\n          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n  Returns:\n          A dictionary of gene expression predictions for each TSS for a gene\n    '''\n  tss_predictions = dict()\n  for tss in TSS:\n    bin_start = low_range + ((768 + 320) * 128)\n    count = -1\n    while bin_start &lt; tss:\n      bin_start = bin_start + 128\n      count += 1\n    if count &gt;= len(cage_predictions)-1:\n      continue\n    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n    tss_predictions[tss] = cage_preds\n\n  return(tss_predictions)\n\ndef collect_intervals(chromosomes = [\"22\"], gene_list=None):\n\n  '''\n    Parameters :\n      chromosomes : a list of chromosome numbers; each element should be a string format\n      gene_list : a list of genes; the genes should be located on those chromosomes\n\n    Returns :\n      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n  '''\n\n  gene_intervals = {} # Collect intervals for our genes of interest\n\n  for chrom in chromosomes:\n    with open(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n      for line in chrom_genes:\n        split_line = line.strip().split(\"\\t\")\n        gene_intervals[split_line[2]] = [\n                                          split_line[0],\n                                          int(split_line[3]),\n                                          int(split_line[4])\n                                        ]\n\n  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n    return(use_genes)\n  elif isinstance(gene_list, type(None)):\n    return(gene_intervals)\n\n\ndef run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n  '''\n  Parameters :\n    gene_intervals : the results from calling `collect_intervals`\n    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n\n  Returns :\n    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n  '''\n\n  gene_output = dict()\n  gene_predictions = dict()\n\n  for gene in gene_intervals.keys():\n    global fasta_extractor\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2]) # creates an interval to select the right sequences\n    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n    try:\n      cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n    except:\n      continue\n    individual_results = dict()\n    individual_prediction = dict()\n\n    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n      use_individuals = individuals_list\n    elif isinstance(individuals_list, type(None)):\n      use_individuals = cur_gene_vars.columns[4:]\n\n    for individual in use_individuals:\n      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n      # two haplotypes per individual\n      haplo_1 = list(target_fa[:])\n      haplo_2 = list(target_fa[:])\n\n      ref_mismatch_count = 0\n      for i,row in cur_gene_vars.iterrows():\n\n        geno = row[individual].split(\"|\")\n        if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n          continue\n        if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n          continue\n        if geno[0] == \"1\":\n          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n        if geno[1] == \"1\":\n          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n      # predict on the individual's two haplotypes\n      global model\n      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n\n      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n      individual_prediction[individual] = temp_predictions\n\n      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n      temp_list = list()\n\n      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n\n      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n\n      temp_list.append(tss_predictions_1)\n      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n\n      individual_results[individual] = temp_list # save for the individual\n\n    gene_output[gene] = individual_results\n    gene_predictions[gene] = individual_prediction\n\n  return([gene_output, gene_predictions])\n\n\ndef collect_target_intervals(gene_intervals):\n\n  '''\n  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n  '''\n\n  target_intervals_dict = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\n    target_intervals_dict[gene] = target_interval\n\n  return(target_intervals_dict)\n\ndef prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n\n  '''\n  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n\n  Parameters:\n    - gene\n    - individual\n    - all_predictions\n  '''\n\n  haplo_predictions = all_predictions[gene][individual]\n  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n\n  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n  gene_intervals = collect_target_intervals(gene_intervals)\n\n  output = dict()\n  output['gene_tracks'] = gene_tracks\n  output['gene_intervals'] = gene_intervals[gene]\n\n  return(output)\n\ndef check_individuals(path_to_bed_file, list_of_individuals):\n\n  '''\n  Checks if an individual is missing in bed variation files.\n  These individuals should be removed prior to training\n  '''\n\n  myfile = open(path_to_bed_file, 'r')\n  myline = myfile.readline()\n  bed_names = myline.split('\\t')[4:]\n  myfile.close()\n\n  if set(list_of_individuals).issubset(set(bed_names)) == False:\n    missing = list(set(list_of_individuals).difference(bed_names))\n    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n  else:\n    missing = []\n    print('All individuals are present in the bed file.')\n\n  return(missing)\n\n\ndef plot_predixcan_vs_geuvadis(interested_gene, interested_individuals, geuvadis_expression, predixcan_expression):\n\n  '''\n  Show a plot and return correlation coefficient\n  '''\n  # from predixcan expression\n  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n  # from enformer\n  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n\n  # concatenate both\n  df_all = pd.concat([df_predixcan, df_geuvadis], axis=0)\n  df_all.index = ['Predixcan', 'GEUVADIS']\n\n  # plotting\n  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. GEUVADIS predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n\n  # correlation coefficient\n  corr_coef = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n\n  return([df_all, corr_coef])\n\ndef plot_enformer_vs_predixcan(prediction_results, interested_gene, interested_individuals, predixcan_expression, how='sum'):\n\n  '''\n  Show a plot and return correlation coefficient\n  '''\n\n  enformer_predictions = dict()\n\n  for gene, individuals in prediction_results[0].items():\n    temp_individual = dict()\n    for individual, haplo_predictions in individuals.items():\n      temp = list()\n      for i in range(0, len(haplo_predictions[0])):\n        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n      if how == 'sum':\n        temp_individual[individual] = np.sum(temp)\n      elif how == 'max':\n        temp_individual[individual] = np.max(temp)\n    enformer_predictions[gene] = temp_individual\n\n  # from predixcan expression\n  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n  # from enformer\n  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_predixcan.columns]\n\n  # concatenate both\n  df_all = pd.concat([df_enformer, df_predixcan], axis=0)\n  df_all.index = ['Enformer', 'Predixcan']\n\n  # plotting\n  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. Enformer predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n\n  # correlation coefficient\n  corr_coef_predix = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n\n  return([df_all, corr_coef_predix])\n\n\ndef plot_enformer_vs_geuvadis(prediction_results, interested_gene, interested_individuals, geuvadis_expression, how='sum'):\n\n  '''\n  Show a plot and return correlation coefficient\n  '''\n\n  enformer_predictions = dict()\n\n  for gene, individuals in prediction_results[0].items():\n    temp_individual = dict()\n    for individual, haplo_predictions in individuals.items():\n      temp = list()\n      for i in range(0, len(haplo_predictions[0])):\n        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n      if how == 'sum':\n        temp_individual[individual] = np.sum(temp)\n      elif how == 'max':\n        temp_individual[individual] = np.max(temp)\n    enformer_predictions[gene] = temp_individual\n\n  # from geuvadis expression\n  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n  #df_enformer = np.transpose(pd.DataFrame(enformer_predictions)).loc[:, df_geuvadis.columns]\n  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_geuvadis.columns]\n\n  # concatenate both\n  df_all = pd.concat([df_enformer, df_geuvadis], axis=0)\n  df_all.index = ['Enformer', 'GEUVADIS']\n\n  # plotting\n  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='blue').set(title='Enformer vs. Geuvadis predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n\n  # correlation coefficient\n  corr_coef_geu = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n\n  return([df_all, corr_coef_geu])"
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#make-predictions-on-the-geuvadis-dataset.",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#make-predictions-on-the-geuvadis-dataset.",
    "title": "blog hackenf",
    "section": "Make predictions on the GEUVADIS dataset.",
    "text": "Make predictions on the GEUVADIS dataset.\nHere, we will begin to make predictions. Excited?!\nWe still need the model itself. The model has been graciously hosted on Tensorflow Hub, which hosts many other models too. You can click on the link and explore. When you click the link, you can see that the model is about 892 Mb large. Quite big. We will use the url to the model to download and use it here.\nEarlier, we defined an Enformer class (see the codes section). We will load the model into this class. The model has been trained and the weights are freely available. All we need to do is to load this model and use it. Neat.\nWe also defined a class FastaStringExtractor, that can help us extract raw sequences from fasta files given the intervals we want. We will make use of this class too.\n\nmodel = Enformer(model_path) # here we load the model architecture.\n\nfasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extract raw sequence data\n\n{'chr1': 249250621, 'chr2': 243199373, 'chr3': 198022430, 'chr4': 191154276, 'chr5': 180915260, 'chr6': 171115067, 'chr7': 159138663, 'chrX': 155270560, 'chr8': 146364022, 'chr9': 141213431, 'chr10': 135534747, 'chr11': 135006516, 'chr12': 133851895, 'chr13': 115169878, 'chr14': 107349540, 'chr15': 102531392, 'chr16': 90354753, 'chr17': 81195210, 'chr18': 78077248, 'chr20': 63025520, 'chrY': 59373566, 'chr19': 59128983, 'chr22': 51304566, 'chr21': 48129895, 'chr6_ssto_hap7': 4928567, 'chr6_mcf_hap5': 4833398, 'chr6_cox_hap2': 4795371, 'chr6_mann_hap4': 4683263, 'chr6_apd_hap1': 4622290, 'chr6_qbl_hap6': 4611984, 'chr6_dbb_hap3': 4610396, 'chr17_ctg5_hap1': 1680828, 'chr4_ctg9_hap1': 590426, 'chr1_gl000192_random': 547496, 'chrUn_gl000225': 211173, 'chr4_gl000194_random': 191469, 'chr4_gl000193_random': 189789, 'chr9_gl000200_random': 187035, 'chrUn_gl000222': 186861, 'chrUn_gl000212': 186858, 'chr7_gl000195_random': 182896, 'chrUn_gl000223': 180455, 'chrUn_gl000224': 179693, 'chrUn_gl000219': 179198, 'chr17_gl000205_random': 174588, 'chrUn_gl000215': 172545, 'chrUn_gl000216': 172294, 'chrUn_gl000217': 172149, 'chr9_gl000199_random': 169874, 'chrUn_gl000211': 166566, 'chrUn_gl000213': 164239, 'chrUn_gl000220': 161802, 'chrUn_gl000218': 161147, 'chr19_gl000209_random': 159169, 'chrUn_gl000221': 155397, 'chrUn_gl000214': 137718, 'chrUn_gl000228': 129120, 'chrUn_gl000227': 128374, 'chr1_gl000191_random': 106433, 'chr19_gl000208_random': 92689, 'chr9_gl000198_random': 90085, 'chr17_gl000204_random': 81310, 'chrUn_gl000233': 45941, 'chrUn_gl000237': 45867, 'chrUn_gl000230': 43691, 'chrUn_gl000242': 43523, 'chrUn_gl000243': 43341, 'chrUn_gl000241': 42152, 'chrUn_gl000236': 41934, 'chrUn_gl000240': 41933, 'chr17_gl000206_random': 41001, 'chrUn_gl000232': 40652, 'chrUn_gl000234': 40531, 'chr11_gl000202_random': 40103, 'chrUn_gl000238': 39939, 'chrUn_gl000244': 39929, 'chrUn_gl000248': 39786, 'chr8_gl000196_random': 38914, 'chrUn_gl000249': 38502, 'chrUn_gl000246': 38154, 'chr17_gl000203_random': 37498, 'chr8_gl000197_random': 37175, 'chrUn_gl000245': 36651, 'chrUn_gl000247': 36422, 'chr9_gl000201_random': 36148, 'chrUn_gl000235': 34474, 'chrUn_gl000239': 33824, 'chr21_gl000210_random': 27682, 'chrUn_gl000231': 27386, 'chrUn_gl000229': 19913, 'chrM': 16571, 'chrUn_gl000226': 15008, 'chr18_gl000207_random': 4262}\n\n\n\nEXERCISE 1:\nFor evaluation, we need to sum the predictions around each unique TSS for a given gene. We will be using this a lot so it is important that we define what it means. Essentially, for a gene with one TSS, we take the sum of predicitions of the 128 bp output bin containing the TSS and its two immediate neighboring bins. We do this for each haplotype and each TSS to give TSS-level predictions.\nTo get individual-level estimates for a whole gene, we sum each haplotype TSS estimate to summarize TSS-level predictions per individual, and then take either the sum or max of TSS-level predictions to summarize at the gene level.\nThere are many genes and many individuals in our datasets. To make illustration simpler, we will use four genes, ERAP1, ERAP2, NUDT2, and PEX6, located on chromosome 5, 5, 9, and 6 respectively. We will use predictions for 10 randomly selected individuals located in the bed files.\n\ndownload_chrom_beds(chromosome = \"5\", genes = ['ERAP1', 'ERAP2'])\ndownload_chrom_beds(chromosome = \"9\", genes = ['NUDT2'])\ndownload_chrom_beds(chromosome = \"6\", genes = ['PEX6'])\n\nHere, we read into a dataframe the TSS (transcription start sites) per gene for the chromosomes we are interested in. The dataframe has three columns. The first contains the genes, and the second contains the TSS(s) for that gene, and the third contains the strand information. We are interested in genes located on chromosomes 5, 6 and 9.\n\nchr5_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr5_tss_by_gene.txt', sep='\\t')\nchr6_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr6_tss_by_gene.txt', sep='\\t')\nchr9_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr9_tss_by_gene.txt', sep='\\t')\n\nchr9_tss.head(10)\n\n\n\n\n\n\n\n\ngenes\ntxStart_Sites\nstrand\n\n\n\n\n0\nDDX11L5\n11987, 12134\n+\n\n\n1\nXXyac-YRM2039.2\n29739, 25007, 19145, 29259\n-\n\n\n2\nMIR1302-11\n27657\n+\n\n\n3\nMIR1302-9\n30144\n+\n\n\n4\nFAM138C\n35841, 35856\n-\n\n\n5\nRP11-143M1.7\n52680\n-\n\n\n6\nRP11-143M1.2\n72701, 72706, 72716\n+\n\n\n7\nRP11-143M1.3\n102850, 102941\n-\n\n\n8\nRP11-143M1.4\n113754\n-\n\n\n9\nFOXD4\n118417\n-\n\n\n\n\n\n\n\n\nPreparing inputs for Enformer\nNow that we have downloaded the genetic information that we need, we want to prepare the inputs for Enformer.\nWe need the following - The genes we want to predict for - The genomic interval for these genes - Information about the transcription start sites for these genes - The individuals we want to predict for\nWe have a utility function that helps to define the intervals of a gene, and resize this interval to make it acceptable for Enformer. Enformer needs a specific, defined sequence length. We use the collect_intervals function. The result is a dictionary that contains chromosome and interval information for each gene.\nFor example, let’s explore ERAP1…\n\nERAP1_intervals = collect_intervals(chromosomes=['5'], gene_list=['ERAP1'])\nERAP1_target_intervals = collect_target_intervals(ERAP1_intervals)\nERAP1_intervals, ERAP1_target_intervals\n\n({'ERAP1': ['5', 96096521, 96143803]},\n {'ERAP1': Interval(chrom='chr5', start=96096521, end=96143803, name='', strand='.', ...)})\n\n\nERAP1_target_intervals is an Interval object created using the kipoiseq package we installed earlier. It is used during predictions, and we don’t need to know the methods of this object for the purpose of the next questions.\nHowever, we have similar information in ERAP1_intervals, which is a python dictionary of lists. For the questions below, we will use the ERAP1_intervals object.\n\n\nQuestion 1a\nWhat is the size of this interval? Hint: Look at the ERAP1_intervals, and remember that Python is 0-based indexed. You need to access the key of this dictionary, which is the gene name, and for the value, which is a list, you can access the first element using 0, the second element using 1, and so on.\n\nERAP1_intervals['ERAP1'][2] - ERAP1_intervals['ERAP1'][1] # your answers go in the ...\n\n47282\n\n\n\n\nNote\nYou can roughly confirm this interval by going to the UCSC genome browser or Ensemble genome browser. We have provided a link for UCSC genome browser’s interval length for ERAP1 here. Click on this link, the answer is right at the top of the browser.\nEnformer takes in a defined sequence length. When we provide a gene and collect its intervals, we need to resize this interval to be acceptable for Enformer. Here, we will use the Intervals object define earlier, ERAP1_target_intervals.\n\nERAP1_target_interval_resized = ERAP1_target_intervals['ERAP1'].resize(SEQUENCE_LENGTH)\nERAP1_target_interval_resized\n\nInterval(chrom='chr5', start=95923554, end=96316770, name='', strand='.', ...)\n\n\n\n\nQuestion 1b\nWhat is the length of this interval? Simply run the next line of code.\n\nERAP1_target_interval_resized.end - ERAP1_target_interval_resized.start\n\n393216\n\n\nEssentially, we resized the length of the gene and pad it with the native sequences to the left and to the right, such that the length of the input sequence is 393216, and we can imagine our gene right at the center of this wider interval. This is the same interval length used to train ENCODE data to build Enformer. Since this value is pre-define, we really cannot change it. This is information that Enformer uses to make very good predictions. Below, we confirm that this is true.\n\n(ERAP1_target_interval_resized.end - ERAP1_target_interval_resized.start) == SEQUENCE_LENGTH\n\nTrue\n\n\n\n\nMaking predictions with Enformer\nWe will select 10 individuals (we have provided 10 randomly sample individuals for ease), and use four genes, ERAP1, ERAP2, NUDT2, and PEX6, located on chromosome 5, 5, 9, and 6 respectively\nWe will collect the intervals that correspond to these genes, collect the sequences for that interval from the reference fasta file, loop through each individual’s variations in the bed files we provided, switch around the variations for each haplotype and predict expression.\nEventually, for each individual, we should have predictions corresponding to each haplotype. We expect that since the haplotypes are different, the predictions should vary too.\nAdditionally, we need the TSS for these genes. Remember that we read in the dataframe earlier.\n\nexercise_1_genes = ['ERAP1', 'NUDT2', 'ERAP2', 'PEX6'] # our genes of interest\n#exercise_1_gene = ['NUDT2', 'ERAP2'] # our gene of interest\n\nexercise_1_individuals = ['NA11992', 'NA19235', 'NA20770', 'HG00232', 'HG00342', 'NA20502', 'NA19189', 'HG00108', 'HG00380', 'NA12872'] # individuals we are interested in\n\nexercise_1_chromosomes = ['5','9', '6'] # the gene is on chromosomes 5 9 and 6\n\nexercise_1_tss_dfs = [chr5_tss, chr9_tss, chr6_tss] # we use the TSS information\n\n\nchr9_tss\n\n\n\n\n\n\n\n\ngenes\ntxStart_Sites\nstrand\n\n\n\n\n0\nDDX11L5\n11987, 12134\n+\n\n\n1\nXXyac-YRM2039.2\n29739, 25007, 19145, 29259\n-\n\n\n2\nMIR1302-11\n27657\n+\n\n\n3\nMIR1302-9\n30144\n+\n\n\n4\nFAM138C\n35841, 35856\n-\n\n\n...\n...\n...\n...\n\n\n2199\nTUBBP5\n141044565, 141069437, 141069497\n+\n\n\n2200\nAL591424.1\n141070938\n-\n\n\n2201\nRP11-885N19.6\n141093775\n-\n\n\n2202\nFAM157B\n141106637, 141107518\n+\n\n\n2203\nRP11-885N19.5\n141130159\n+\n\n\n\n\n2204 rows × 3 columns\n\n\n\n\n\nQUESTION 2\nWhat is the id of the 8th individual? Hint: Python used 0-based indexing\n\nexercise_1_individuals[7]\n\n'HG00108'\n\n\n\n# answer\nprint('The 8th individual is {}'.format(exercise_1_individuals[7])) # your code goes into the ellipsis\n\nThe 8th individual is HG00108\n\n\nIt is possible to have individuals not present in our variation bed files for some reasons. So, we will do some sanity checks.\nUsing the check_individuals functions, we will check if all these individuals are present in the bed file for that gene.\n\nfor num,gene in zip(['5','5','6','9'],['ERAP1','ERAP2','PEX6','NUDT2']):\n    check_individuals(f'/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr{num}/chr{num}_{gene}.bed', exercise_1_individuals)\n\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\n\n\n\n# answer\nmissing_1 = check_individuals(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr9/chr9_NUDT2.bed\", list_of_individuals = exercise_1_individuals)\nmissing_2 = check_individuals(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr5/chr5_ERAP2.bed\", list_of_individuals = exercise_1_individuals)\nmissing_3 = check_individuals(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr5/chr5_ERAP1.bed\", list_of_individuals = exercise_1_individuals)\nmissing_4 = check_individuals(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr6/chr6_PEX6.bed\", list_of_individuals = exercise_1_individuals)\nmissing_1, missing_2, missing_3, missing_4\n\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\n\n\n([], [], [], [])\n\n\nIt looks like all the individuals are present. Very nice! We are good to go.\nTo make predictions, we first collect the intervals for the genes we want to predict for.\n\nexercise_1_interval = collect_intervals(chromosomes=exercise_1_chromosomes, gene_list=exercise_1_genes) # here, we collect the intervals for that gene\nexercise_1_interval\n\n{'ERAP1': ['5', 96096521, 96143803],\n 'NUDT2': ['9', 34329504, 34343709],\n 'ERAP2': ['5', 96211643, 96255420],\n 'PEX6': ['6', 42931608, 42946958]}\n\n\nNext, we use the run_predictions function\n\nexercise_1_predictions = run_predictions(gene_intervals=exercise_1_interval, tss_dataframe=exercise_1_tss_dfs, individuals_list=exercise_1_individuals) # here we make predictions and save it.\n\nCurrently on gene ERAP1, and predicting on individual NA11992...\nCurrently on gene ERAP1, and predicting on individual NA19235...\nCurrently on gene ERAP1, and predicting on individual NA20770...\nCurrently on gene ERAP1, and predicting on individual HG00232...\nCurrently on gene ERAP1, and predicting on individual HG00342...\nCurrently on gene ERAP1, and predicting on individual NA20502...\nCurrently on gene ERAP1, and predicting on individual NA19189...\nCurrently on gene ERAP1, and predicting on individual HG00108...\nCurrently on gene ERAP1, and predicting on individual HG00380...\nCurrently on gene ERAP1, and predicting on individual NA12872...\nCurrently on gene NUDT2, and predicting on individual NA11992...\nCurrently on gene NUDT2, and predicting on individual NA19235...\nCurrently on gene NUDT2, and predicting on individual NA20770...\nCurrently on gene NUDT2, and predicting on individual HG00232...\nCurrently on gene NUDT2, and predicting on individual HG00342...\nCurrently on gene NUDT2, and predicting on individual NA20502...\nCurrently on gene NUDT2, and predicting on individual NA19189...\nCurrently on gene NUDT2, and predicting on individual HG00108...\nCurrently on gene NUDT2, and predicting on individual HG00380...\nCurrently on gene NUDT2, and predicting on individual NA12872...\nCurrently on gene ERAP2, and predicting on individual NA11992...\nCurrently on gene ERAP2, and predicting on individual NA19235...\nCurrently on gene ERAP2, and predicting on individual NA20770...\nCurrently on gene ERAP2, and predicting on individual HG00232...\nCurrently on gene ERAP2, and predicting on individual HG00342...\nCurrently on gene ERAP2, and predicting on individual NA20502...\nCurrently on gene ERAP2, and predicting on individual NA19189...\nCurrently on gene ERAP2, and predicting on individual HG00108...\nCurrently on gene ERAP2, and predicting on individual HG00380...\nCurrently on gene ERAP2, and predicting on individual NA12872...\nCurrently on gene PEX6, and predicting on individual NA11992...\nCurrently on gene PEX6, and predicting on individual NA19235...\nCurrently on gene PEX6, and predicting on individual NA20770...\nCurrently on gene PEX6, and predicting on individual HG00232...\nCurrently on gene PEX6, and predicting on individual HG00342...\nCurrently on gene PEX6, and predicting on individual NA20502...\nCurrently on gene PEX6, and predicting on individual NA19189...\nCurrently on gene PEX6, and predicting on individual HG00108...\nCurrently on gene PEX6, and predicting on individual HG00380...\nCurrently on gene PEX6, and predicting on individual NA12872...\n\n\nNB: If you intend to make predictions across many individuals and genes, it will be faster if you have larger GPU access. For now, we are using limited GPU. So, we have to limit our predictions.\nQuite fast right? Very nice.\nOur prediction object, exercise_1_predictions is a list of length two. - The first item in the list corresponds to the sum of predictions around each unique TSS, for each haplotype, for each individual, for each gene.\n\nThe second item in the list corresponds to the CAGE:B lymphoblastoid cell line predictions across all 128bp bins for each haplotype, for each individual, for the genes. We will use the second item for plotting the tracks.\n\nLet us take a look at the object.\n\nprint(\"The exercise_1_predictions object is a {} of length {}.\".format(type(exercise_1_predictions).__name__, len(exercise_1_predictions)))\n\nThe exercise_1_predictions object is a list of length 2.\n\n\n\nexercise_1_predictions[0]\n\n{'ERAP1': {'NA11992': [{96122464: 1.5845575,\n    96143625: 489.71454,\n    96116885: 5.046175,\n    96126329: 6.616495,\n    96143642: 489.71454,\n    96143803: 512.83966,\n    96143612: 489.71454,\n    96129374: 4.2131667},\n   {96122464: 1.497031,\n    96143625: 494.1168,\n    96116885: 4.87383,\n    96126329: 6.5148587,\n    96143642: 494.1168,\n    96143803: 521.8027,\n    96143612: 494.1168,\n    96129374: 4.1427984}],\n  'NA19235': [{96122464: 1.4510643,\n    96143625: 495.29688,\n    96116885: 4.4305553,\n    96126329: 6.32933,\n    96143642: 495.29688,\n    96143803: 522.2148,\n    96143612: 495.29688,\n    96129374: 4.0896263},\n   {96122464: 1.4198842,\n    96143625: 484.1412,\n    96116885: 4.385815,\n    96126329: 6.062807,\n    96143642: 484.1412,\n    96143803: 511.79333,\n    96143612: 484.1412,\n    96129374: 4.039564}],\n  'NA20770': [{96122464: 1.4971781,\n    96143625: 494.13232,\n    96116885: 4.876236,\n    96126329: 6.5235286,\n    96143642: 494.13232,\n    96143803: 521.78955,\n    96143612: 494.13232,\n    96129374: 4.1479464},\n   {96122464: 1.5023532,\n    96143625: 486.97495,\n    96116885: 4.826562,\n    96126329: 6.543599,\n    96143642: 486.97495,\n    96143803: 514.4984,\n    96143612: 486.97495,\n    96129374: 4.2009516}],\n  'HG00232': [{96122464: 1.5801451,\n    96143625: 489.6238,\n    96116885: 5.0468493,\n    96126329: 6.631588,\n    96143642: 489.6238,\n    96143803: 512.0131,\n    96143612: 489.6238,\n    96129374: 4.2263203},\n   {96122464: 1.4746226,\n    96143625: 496.61792,\n    96116885: 5.0096426,\n    96126329: 6.5015197,\n    96143642: 496.61792,\n    96143803: 524.09894,\n    96143612: 496.61792,\n    96129374: 4.1730084}],\n  'HG00342': [{96122464: 1.4783711,\n    96143625: 489.08597,\n    96116885: 4.456544,\n    96126329: 6.4388595,\n    96143642: 489.08597,\n    96143803: 511.05814,\n    96143612: 489.08597,\n    96129374: 4.1379647},\n   {96122464: 1.4745966,\n    96143625: 496.4183,\n    96116885: 5.0095057,\n    96126329: 6.50322,\n    96143642: 496.4183,\n    96143803: 523.8677,\n    96143612: 496.4183,\n    96129374: 4.173162}],\n  'NA20502': [{96122464: 1.4886063,\n    96143625: 489.81024,\n    96116885: 4.469452,\n    96126329: 6.4524903,\n    96143642: 489.81024,\n    96143803: 511.72656,\n    96143612: 489.81024,\n    96129374: 4.1528716},\n   {96122464: 1.489933,\n    96143625: 489.32104,\n    96116885: 4.458976,\n    96126329: 6.444271,\n    96143642: 489.32104,\n    96143803: 511.135,\n    96143612: 489.32104,\n    96129374: 4.147463}],\n  'NA19189': [{96122464: 1.5061176,\n    96143625: 493.48938,\n    96116885: 4.876781,\n    96126329: 6.522683,\n    96143642: 493.48938,\n    96143803: 521.1688,\n    96143612: 493.48938,\n    96129374: 4.1551123},\n   {96122464: 1.5114217,\n    96143625: 494.4071,\n    96116885: 4.8783083,\n    96126329: 6.521857,\n    96143642: 494.4071,\n    96143803: 522.12213,\n    96143612: 494.4071,\n    96129374: 4.1585693}],\n  'HG00108': [{96122464: 1.575064,\n    96143625: 488.97064,\n    96116885: 5.0048943,\n    96126329: 6.605063,\n    96143642: 488.97064,\n    96143803: 511.85977,\n    96143612: 488.97064,\n    96129374: 4.207043},\n   {96122464: 1.5207586,\n    96143625: 498.7388,\n    96116885: 4.641093,\n    96126329: 6.4792533,\n    96143642: 498.7388,\n    96143803: 527.22986,\n    96143612: 498.7388,\n    96129374: 4.149161}],\n  'HG00380': [{96122464: 1.4761775,\n    96143625: 496.32318,\n    96116885: 5.0209956,\n    96126329: 6.5039134,\n    96143642: 496.32318,\n    96143803: 523.7153,\n    96143612: 496.32318,\n    96129374: 4.173094},\n   {96122464: 1.479995,\n    96143625: 495.49808,\n    96116885: 4.7748117,\n    96126329: 6.435356,\n    96143642: 495.49808,\n    96143803: 522.5722,\n    96143612: 495.49808,\n    96129374: 4.1001253}],\n  'NA12872': [{96122464: 1.4861214,\n    96143625: 489.702,\n    96116885: 4.468792,\n    96126329: 6.455694,\n    96143642: 489.702,\n    96143803: 511.5416,\n    96143612: 489.702,\n    96129374: 4.1401815},\n   {96122464: 1.4745966,\n    96143625: 496.4183,\n    96116885: 5.0095057,\n    96126329: 6.50322,\n    96143642: 496.4183,\n    96143803: 523.8677,\n    96143612: 496.4183,\n    96129374: 4.173162}]},\n 'NUDT2': {'NA11992': [{34329504: 360.31055}, {34329504: 349.04797}],\n  'NA19235': [{34329504: 359.58936}, {34329504: 355.90884}],\n  'NA20770': [{34329504: 368.71173}, {34329504: 359.92462}],\n  'HG00232': [{34329504: 368.40317}, {34329504: 360.11316}],\n  'HG00342': [{34329504: 348.69574}, {34329504: 348.73532}],\n  'NA20502': [{34329504: 360.1745}, {34329504: 368.5061}],\n  'NA19189': [{34329504: 368.2572}, {34329504: 358.46478}],\n  'HG00108': [{34329504: 367.91898}, {34329504: 359.66962}],\n  'HG00380': [{34329504: 366.38528}, {34329504: 368.71173}],\n  'NA12872': [{34329504: 368.60864}, {34329504: 360.29413}]},\n 'ERAP2': {'NA11992': [{96215268: 1.9581358,\n    96211690: 3.5747912,\n    96232107: 6.8337584,\n    96212204: 101.02355,\n    96212210: 101.02355,\n    96249042: 1.8737028,\n    96232276: 18.423489,\n    96224921: 3.1584282,\n    96228122: 2.9266233,\n    96211643: 2.8729196,\n    96216637: 3.288146},\n   {96215268: 1.9143871,\n    96211690: 3.8210707,\n    96232107: 6.656333,\n    96212204: 99.06468,\n    96212210: 99.06468,\n    96249042: 1.829967,\n    96232276: 17.99731,\n    96224921: 3.0347857,\n    96228122: 2.8349643,\n    96211643: 3.0821114,\n    96216637: 2.9466062}],\n  'NA19235': [{96215268: 1.6590314,\n    96211690: 3.4477823,\n    96232107: 6.0083904,\n    96212204: 90.935,\n    96212210: 90.935,\n    96249042: 1.797974,\n    96232276: 14.7234955,\n    96224921: 2.9633546,\n    96228122: 2.5902596,\n    96211643: 2.6008434,\n    96216637: 2.3639824},\n   {96215268: 1.6566705,\n    96211690: 3.7383955,\n    96232107: 7.1729035,\n    96212204: 99.408966,\n    96212210: 99.408966,\n    96249042: 1.8008903,\n    96232276: 19.947186,\n    96224921: 2.995337,\n    96228122: 2.8169553,\n    96211643: 3.0155046,\n    96216637: 2.8945346}],\n  'NA20770': [{96215268: 1.9108489,\n    96211690: 3.8652668,\n    96232107: 6.79965,\n    96212204: 100.53483,\n    96212210: 100.53483,\n    96249042: 1.843105,\n    96232276: 18.332998,\n    96224921: 3.0767512,\n    96228122: 2.8603945,\n    96211643: 3.1207733,\n    96216637: 2.995961},\n   {96215268: 2.1261544,\n    96211690: 3.587429,\n    96232107: 6.781275,\n    96212204: 100.93416,\n    96212210: 100.93416,\n    96249042: 1.8869461,\n    96232276: 18.228317,\n    96224921: 3.2119985,\n    96228122: 2.9573545,\n    96211643: 2.886695,\n    96216637: 3.0828037}],\n  'HG00232': [{96215268: 1.5979345,\n    96211690: 3.4368386,\n    96232107: 5.8956723,\n    96212204: 88.83617,\n    96212210: 88.83617,\n    96249042: 1.6416408,\n    96232276: 14.657543,\n    96224921: 2.7001524,\n    96228122: 2.3652134,\n    96211643: 2.7703807,\n    96216637: 2.3909903},\n   {96215268: 1.6584711,\n    96211690: 3.4323988,\n    96232107: 5.991882,\n    96212204: 90.35279,\n    96212210: 90.35279,\n    96249042: 1.7810708,\n    96232276: 14.7353115,\n    96224921: 2.949048,\n    96228122: 2.5692582,\n    96211643: 2.5880797,\n    96216637: 2.3923383}],\n  'HG00342': [{96215268: 1.903702,\n    96211690: 4.3292146,\n    96232107: 6.9356337,\n    96212204: 106.676506,\n    96212210: 106.676506,\n    96249042: 1.9019154,\n    96232276: 16.906658,\n    96224921: 3.3359914,\n    96228122: 2.9514675,\n    96211643: 3.5364437,\n    96216637: 3.9636111},\n   {96215268: 1.6578631,\n    96211690: 3.4409864,\n    96232107: 6.009323,\n    96212204: 90.35808,\n    96212210: 90.35808,\n    96249042: 1.7842112,\n    96232276: 14.769115,\n    96224921: 2.9539285,\n    96228122: 2.575068,\n    96211643: 2.5913248,\n    96216637: 2.3919063}],\n  'NA20502': [{96215268: 1.65951,\n    96211690: 3.4384847,\n    96232107: 6.003534,\n    96212204: 90.649796,\n    96212210: 90.649796,\n    96249042: 1.8017914,\n    96232276: 14.686028,\n    96224921: 2.9850273,\n    96228122: 2.61036,\n    96211643: 2.5942028,\n    96216637: 2.3541157},\n   {96215268: 1.6675327,\n    96211690: 3.5029452,\n    96232107: 6.785567,\n    96212204: 97.276794,\n    96212210: 97.276794,\n    96249042: 1.7746121,\n    96232276: 18.383774,\n    96224921: 2.93766,\n    96228122: 2.7639658,\n    96211643: 2.8132868,\n    96216637: 2.6917744}],\n  'NA19189': [{96215268: 1.9119611,\n    96211690: 3.827299,\n    96232107: 6.7530813,\n    96212204: 99.792816,\n    96212210: 99.792816,\n    96249042: 1.8168527,\n    96232276: 18.252033,\n    96224921: 3.022784,\n    96228122: 2.803005,\n    96211643: 3.088863,\n    96216637: 2.9935055},\n   {96215268: 1.8717865,\n    96211690: 4.1822605,\n    96232107: 6.358903,\n    96212204: 97.49959,\n    96212210: 97.49959,\n    96249042: 1.8374182,\n    96232276: 15.719281,\n    96224921: 3.1845908,\n    96228122: 2.6329162,\n    96211643: 3.4111338,\n    96216637: 3.2497323}],\n  'HG00108': [{96215268: 1.9505453,\n    96211690: 3.4820411,\n    96232107: 6.674739,\n    96212204: 99.98324,\n    96212210: 99.98324,\n    96249042: 1.846915,\n    96232276: 18.036423,\n    96224921: 3.0932627,\n    96228122: 2.8669367,\n    96211643: 2.7990851,\n    96216637: 3.143051},\n   {96215268: 1.6843762,\n    96211690: 3.5142884,\n    96232107: 6.0852957,\n    96212204: 90.470894,\n    96212210: 90.470894,\n    96249042: 1.800012,\n    96232276: 14.905607,\n    96224921: 2.9662786,\n    96228122: 2.5963242,\n    96211643: 2.6558666,\n    96216637: 2.4217227}],\n  'HG00380': [{96215268: 1.6373007,\n    96211690: 3.446891,\n    96232107: 5.892266,\n    96212204: 88.69023,\n    96212210: 88.69023,\n    96249042: 1.7481296,\n    96232276: 14.527841,\n    96224921: 2.9107213,\n    96228122: 2.5149286,\n    96211643: 2.770537,\n    96216637: 2.3483326},\n   {96215268: 1.725192,\n    96211690: 3.5751612,\n    96232107: 7.095453,\n    96212204: 101.86155,\n    96212210: 101.86155,\n    96249042: 1.856543,\n    96232276: 19.044638,\n    96224921: 2.966233,\n    96228122: 2.8206906,\n    96211643: 2.6822937,\n    96216637: 2.796311}],\n  'NA12872': [{96215268: 1.6635227,\n    96211690: 3.432705,\n    96232107: 6.0694833,\n    96212204: 90.82424,\n    96212210: 90.82424,\n    96249042: 1.8022054,\n    96232276: 14.841341,\n    96224921: 2.9893208,\n    96228122: 2.6220691,\n    96211643: 2.5858727,\n    96216637: 2.4037988},\n   {96215268: 1.6578631,\n    96211690: 3.4409864,\n    96232107: 6.009323,\n    96212204: 90.35808,\n    96212210: 90.35808,\n    96249042: 1.7842112,\n    96232276: 14.769115,\n    96224921: 2.9539285,\n    96228122: 2.575068,\n    96211643: 2.5913248,\n    96216637: 2.3919063}]},\n 'PEX6': {'NA11992': [{42946888: 309.1448, 42946958: 309.1448},\n   {42946888: 309.73895, 42946958: 309.73895}],\n  'NA19235': [{42946888: 344.31375, 42946958: 344.31375},\n   {42946888: 344.2588, 42946958: 344.2588}],\n  'NA20770': [{42946888: 357.8733, 42946958: 357.8733},\n   {42946888: 309.7414, 42946958: 309.7414}],\n  'HG00232': [{42946888: 344.83328, 42946958: 344.83328},\n   {42946888: 309.7692, 42946958: 309.7692}],\n  'HG00342': [{42946888: 357.85205, 42946958: 357.85205},\n   {42946888: 311.31656, 42946958: 311.31656}],\n  'NA20502': [{42946888: 357.66873, 42946958: 357.66873},\n   {42946888: 309.80698, 42946958: 309.80698}],\n  'NA19189': [{42946888: 348.38687, 42946958: 348.38687},\n   {42946888: 358.8003, 42946958: 358.8003}],\n  'HG00108': [{42946888: 358.191, 42946958: 358.191},\n   {42946888: 344.83533, 42946958: 344.83533}],\n  'HG00380': [{42946888: 309.71356, 42946958: 309.71356},\n   {42946888: 358.16995, 42946958: 358.16995}],\n  'NA12872': [{42946888: 359.53476, 42946958: 359.53476},\n   {42946888: 358.23953, 42946958: 358.23953}]}}\n\n\n\n\nPlotting the CAGE:B lymphoblastoid cell line tracks\nNext, we will plot the tracks. We have already defined two helper functions, prepare_for_plot_tracks and plot_tracks to plot the expression along the TSS for a gene, for an individual and for each haplotype.\nFor NUDT2…\n\ntemp = prepare_for_plot_tracks(gene=exercise_1_genes[1], individual=exercise_1_individuals[0], all_predictions=exercise_1_predictions[1], chromosome=['9'])\nplot_tracks(tracks=temp['gene_tracks'], interval=temp['gene_intervals'])\n\n\n\n\nLooks nice!\nAlthough it looks like there is no variation in the predictions for the haplotypes, we can take a look at the actual prediction values across the TSS.\nThe columns are the transcription start sites, and the rows are the haplotypes for the individual. The entries are the sum of the predictions at the TSS, at TSS - 1, and at the TSS + 1.\nWe will look at the first individual, NA11992, for NUDT2…\n\npd.DataFrame(exercise_1_predictions[0][exercise_1_genes[1]][exercise_1_individuals[0]], index=['haplotype_1', 'haplotype_2'])\n\n\n\n\n\n\n\n\n34329504\n\n\n\n\nhaplotype_1\n360.310547\n\n\nhaplotype_2\n349.047974\n\n\n\n\n\n\n\nWe will look at the first individual, NA11992, for PEX6…\n\npd.DataFrame(exercise_1_predictions[0][exercise_1_genes[3]][exercise_1_individuals[0]], index=['haplotype_1', 'haplotype_2'])\n\n\n\n\n\n\n\n\n42946888\n42946958\n\n\n\n\nhaplotype_1\n309.144806\n309.144806\n\n\nhaplotype_2\n309.738953\n309.738953\n\n\n\n\n\n\n\nMerely looking at the values, it looks like there are variations in the predictions across the haplotypes and the TSS. We expected some variations because we are predicting expression for each haplotype, which tend to have variations in them. Very nice!"
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#comparing-with-true-expression-from-geuvadis-and-with-predixcan",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#comparing-with-true-expression-from-geuvadis-and-with-predixcan",
    "title": "blog hackenf",
    "section": "Comparing with true expression from GEUVADIS and with Predixcan",
    "text": "Comparing with true expression from GEUVADIS and with Predixcan\nWe should read in the GEUVADIS and Predixcan predictions.\n\ngeuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\ngeuvadis_gene_expression.head(5)\n\n\n\n\n\n\n\n\ngene_id\ngene_name\nTargetID\nChr\nCoord\nHG00096\nHG00097\nHG00099\nHG00100\nHG00101\n...\nNA20810\nNA20811\nNA20812\nNA20813\nNA20814\nNA20815\nNA20816\nNA20819\nNA20826\nNA20828\n\n\n\n\n0\nENSG00000223972.4\nDDX11L1\nENSG00000223972.4\n1\n11869\n0.320818\n0.344202\n0.354225\n0.478064\n-0.102815\n...\n1.008605\n0.384489\n0.581284\n0.513981\n0.667449\n0.350890\n0.186103\n-0.037976\n0.405439\n0.199143\n\n\n1\nENSG00000227232.3\nWASH7P\nENSG00000227232.3\n1\n29806\n33.714457\n20.185174\n18.095407\n24.100871\n29.018719\n...\n30.980194\n34.086207\n39.678442\n29.643513\n27.120420\n29.121624\n31.117198\n32.047074\n22.798959\n23.563874\n\n\n2\nENSG00000243485.1\nMIR1302-11\nENSG00000243485.1\n1\n29554\n0.240408\n0.157456\n0.218806\n0.320878\n0.067833\n...\n0.065940\n0.228784\n0.140642\n0.283905\n0.273821\n0.286311\n0.324060\n0.049574\n0.255288\n0.157440\n\n\n3\nENSG00000238009.2\nRP11-34P13.7\nENSG00000238009.2\n1\n133566\n0.328272\n0.327932\n0.090064\n0.420443\n0.220269\n...\n0.274071\n0.384179\n0.533693\n0.307221\n0.307367\n0.400278\n0.612321\n0.666633\n0.281138\n1.346129\n\n\n4\nENSG00000239945.1\nRP11-34P13.8\nENSG00000239945.1\n1\n91105\n0.332171\n-0.032164\n0.017323\n0.424677\n0.214025\n...\n0.347323\n0.346744\n0.073580\n0.400396\n0.470517\n0.069749\n0.299353\n0.090019\n0.282554\n-0.157170\n\n\n\n\n5 rows × 467 columns\n\n\n\n\npredixcan_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/4k68u7x7rxjpoljfdva6qipjxwzd3l0g.txt', sep=' ')\npredixcan_gene_expression.head(5)\n\n\n\n\n\n\n\n\ngene_names_proper\ngene_name\nHG00315\nHG00327\nHG00334\nHG00339\nHG00341\nHG00346\nHG00353\nHG00358\n...\nNA20760\nNA20765\nNA20772\nNA20796\nNA20804\nNA20809\nNA20811\nNA20816\nNA20828\nNA20506\n\n\n\n\n0\nENSG00000002016\nRAD52\n-0.250104\n0.025857\n-0.044889\n-0.126075\n-0.019377\n-0.305435\n-0.084487\n-0.083447\n...\n0.067738\n-0.032721\n-0.044850\n-0.136171\n0.030402\n-0.145576\n0.000571\n0.021220\n0.006563\n-0.012295\n\n\n1\nENSG00000002549\nLAP3\n-0.139077\n-0.324475\n-0.314899\n-0.316845\n-0.279671\n-0.142608\n-0.318413\n0.028499\n...\n-0.308563\n-0.150983\n0.017815\n-0.333274\n-0.130020\n-0.312917\n-0.289931\n-0.148905\n-0.324063\n-0.151374\n\n\n2\nENSG00000002726\nAOC1\n0.134822\n0.004770\n-0.182188\n-0.238028\n0.044468\n-0.250673\n-0.116671\n-0.243399\n...\n0.018929\n-0.021651\n0.010531\n0.364958\n0.131044\n-0.009168\n-0.219884\n-0.424765\n-0.404101\n0.006370\n\n\n3\nENSG00000002822\nMAD1L1\n-0.130900\n-0.138393\n-0.113105\n0.106536\n-0.026348\n-0.070047\n-0.062220\n-0.018478\n...\n-0.159111\n-0.127137\n-0.037308\n-0.032433\n-0.213594\n-0.156237\n-0.187337\n-0.115429\n-0.235621\n-0.059553\n\n\n4\nENSG00000003393\nALS2\n0.250872\n-0.202676\n0.271500\n0.282373\n0.199417\n-0.179208\n-0.598147\n-0.140201\n...\n0.238821\n0.250585\n0.185087\n0.042159\n0.244893\n-0.185666\n0.242587\n0.234396\n-0.294932\n0.154260\n\n\n\n\n5 rows × 460 columns\n\n\n\n\nQUESTION 3a\nWhat is the dimension/size/shape of the geuvadis_gene_expression dataframe? Hint: You can use the .shape method on a dataframe.\n\ngeuvadis_dimension = geuvadis_gene_expression.shape\nprint(\"The geuvadis_gene_expression dataframe has {} rows and {} columns\".format(*geuvadis_dimension))\n\nThe geuvadis_gene_expression dataframe has 23722 rows and 467 columns\n\n\n\n\nQUESTION 4b\nWhat is the dimension/size/shape of the predixcan_gene_expression dataframe? Hint: You can use the .shape method on a dataframe.\n\npredixcan_dimension = predixcan_gene_expression.shape\nprint(\"The predixcan_gene_expression dataframe has {} rows and {} columns\".format(*predixcan_dimension))\n\nThe predixcan_gene_expression dataframe has 4031 rows and 460 columns\n\n\nWe select the individuals and the gene from the geuvadis_gene_expression dataframe.\n\nerap1_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[0]].loc[:,exercise_1_individuals]\nnudt2_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[1]].loc[:,exercise_1_individuals]\nerap2_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[2]].loc[:,exercise_1_individuals]\npex6_geuvadis_expression = geuvadis_gene_expression[geuvadis_gene_expression.gene_name == exercise_1_genes[3]].loc[:,exercise_1_individuals]\n\n\nnudt2_geuvadis_expression\n\n\n\n\n\n\n\n\nNA11992\nNA19235\nNA20770\nHG00232\nHG00342\nNA20502\nNA19189\nHG00108\nHG00380\nNA12872\n\n\n\n\n10804\n23.713984\n14.787901\n16.181407\n13.594301\n20.765908\n16.877474\n12.753234\n11.754371\n10.113347\n17.138522\n\n\n\n\n\n\n\nWe will sum the prediction for both haplotypes for each TSS, and take the sum of the resulting values. The function used here can also take the max instead of the sums.\nWe have 3 utility functions to help us - plot_enformer_vs_guevadis - plot_predixcan_vs_geuvadis - plot_enformer_vs_predixcan (if you think this is necessary)\n\nerap1_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n                            interested_gene=exercise_1_genes[0], interested_individuals=exercise_1_individuals, how='sum')\nprint('Correlation coefficient: {}'.format(erap1_vs_geu[1]))\n\nCorrelation coefficient: 0.2332579720905815\n\n\n\n\n\n\npex6_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n                            interested_gene=exercise_1_genes[3], interested_individuals=exercise_1_individuals, how='sum')\n\nprint('Correlation coefficient: {}'.format(pex6_vs_geu[1]))\n\nCorrelation coefficient: 0.8671872936689365\n\n\n\n\n\n\nnudt_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n                            interested_gene=exercise_1_genes[1], interested_individuals=exercise_1_individuals, how='sum')\n\nprint('Correlation coefficient: {}'.format(nudt_vs_geu[1]))\n\nCorrelation coefficient: -0.747066163433306\n\n\n\n\n\n\nerap2_vs_geu = plot_enformer_vs_geuvadis(prediction_results=exercise_1_predictions, geuvadis_expression=geuvadis_gene_expression,\n                            interested_gene=exercise_1_genes[2], interested_individuals=exercise_1_individuals, how='sum')\n\nprint('Correlation coefficient: {}'.format(erap2_vs_geu[1]))\n\nCorrelation coefficient: -0.47059602771943965\n\n\n\n\n\nNow, we can see how Predixcan performs on these individuals\n\nerap1_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[0], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\nprint('The correlation coefficient: {}'.format(erap1_predix[1]))\n\nThe correlation coefficient: 0.8736403074571262\n\n\n\n\n\n\npex6_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[3], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\nprint('The correlation coefficient: {}'.format(pex6_predix[1]))\n\nThe correlation coefficient: 0.9747939454280228\n\n\n\n\n\n\nerap2_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[2], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\nprint('The correlation coefficient: {}'.format(erap2_predix[1]))\n\nThe correlation coefficient: 0.7541638507596199\n\n\n\n\n\n\nnudt2_predix = plot_predixcan_vs_geuvadis(interested_gene=exercise_1_genes[1], interested_individuals=exercise_1_individuals, geuvadis_expression=geuvadis_gene_expression, predixcan_expression=predixcan_gene_expression)\nprint('The correlation coefficient: {}'.format(nudt2_predix[1]))\n\nThe correlation coefficient: 0.7396287059598816\n\n\n\n\n\nQuite neat and impressive!"
  },
  {
    "objectID": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#exercise-2",
    "href": "posts/2023-07-06-hackenf/Hackathon_enformer_usage_participant.html#exercise-2",
    "title": "blog hackenf",
    "section": "EXERCISE 2",
    "text": "EXERCISE 2\nIn this exercise, you will get your hands dirty, and run Enformer on your gene(s) of interest.\n\nSelect your favorite gene(s). Note that the more genes you use, the longer it will take to run.\nRandomly select 10 individuals, just because we don’t have all the computational power.\nRun predictions\n\nWe only have data for a finite set of genes (sorry!). Here is a list of available genes you can use:\n\n!curl -L https://uchicago.box.com/shared/static/x8d7dx1ykefz49ep6sxot42v44sfvcv5.tsv --output /grand/TFXcan/imlab/users/lvairus/hackenf/data/all_genes.tsv\n\nwith open(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/all_genes.tsv\", \"r\") as ag:\n  all_genes = [line.strip() for line in ag]\nprint(len(all_genes))\nprint(\"First 5 genes all_genes:\", all_genes[0:5])\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100     5    0     5    0     0      5      0 --:--:-- --:--:-- --:--:--     5\n100 20052  100 20052    0     0  19486      0  0:00:01  0:00:01 --:--:-- 19486\n3114\nFirst 5 genes all_genes: ['PEX10', 'TMEM69', 'ATAD3A', 'BPNT1', 'SNIP1']\n\n\n\nSelect your genes\n\n\nmy_genes = ['TMEM69', 'SNIP1', 'RAP1GAP', 'AMIGO1']\nprint(\"My gene(s) are {}\".format(', '.join(my_genes)))\n\nMy gene(s) are TMEM69, SNIP1, RAP1GAP, AMIGO1\n\n\n\nRead in the TSS txt files where those chromosome are located. If you have genes located on more than one chromosome, copy the pd.read_table line for each chromosome you have, and replace the chromosome number (ellipses) as appropriate.\n\n\nmy_chromosomes = ['1'] # put in the chromosomes where the genes are located. Just the numbers will do, or you can put them in as a string type\n\n\nmy_tss_list = []\nfor chr in my_chromosomes:\n  chr = str(chr)\n  bed_file = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr{}_tss_by_gene.txt'.format(chr)\n  my_tss_list.append(pd.read_table(bed_file, sep='\\t')) # we read in the TSSs for each chromosome, and put them into a list\nmy_tss_list\n\n[           genes                                      txStart_Sites strand\n 0        DDX11L1                         11869, 11872, 11874, 12010      +\n 1         WASH7P    29370, 24886, 29370, 29570, 29806, 19305, 29344      -\n 2     MIR1302-11                                29554, 30267, 30366      +\n 3        FAM138A                                       36081, 36073      -\n 4        OR4G11P                                              62948      +\n ...          ...                                                ...    ...\n 4800      ZNF672  249132409, 249132479, 249132530, 249133027, 24...      +\n 4801      ZNF692  249152912, 249153271, 249153271, 249153271, 24...      -\n 4802  AL672294.1                                          249153363      +\n 4803       PGBD2         249200395, 249200442, 249200464, 249200571      +\n 4804  AL672183.2                                          249230780      +\n \n [4805 rows x 3 columns]]\n\n\n\nRandomly select 10 individuals\n\n\n# let us set a seed to randomly select 10 individuals\nnp.random.seed(2023)  # replace ... with an integer you want\n\nnumber_of_individuals = 10\n\nmy_individuals = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], size=number_of_individuals, replace=False) # individuals we are interested in\nmy_individuals\n\narray(['NA19144', 'NA18933', 'HG00327', 'NA19138', 'NA19096', 'HG00133',\n       'NA20757', 'NA20803', 'NA18923', 'HG00355'], dtype=object)\n\n\n\nWe want to make sure that we have complete variation information for all 10 individuals.\n\nFirst, we need to download the variation bed files for these individuals\n\ndownload_chrom_beds(chromosome='1', genes=my_genes) # remember that the genes should be on that chromosome, and you can use this code for each chromosome you have.\n\nRead in the variation bed files\n\nimport os\n\nmy_missing_list = list()\nfor chr in my_chromosomes:\n  for gene in my_genes:\n    chr = str(chr)\n    file_path = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr' + chr + '/chr' + chr + '_' + gene + '.bed'\n    if not os.path.exists(file_path):\n      continue\n    my_missing_list.append(check_individuals(file_path, my_individuals))\n\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\nAll individuals are present in the bed file.\n\n\n\nQUESTION 4\nAre there missing individuals? All answers, based on your results are correct. If there are missing individuals, can you remove them? You can add new code blocks as you like.\n\nmy_missing_list\n\n[[], [], [], []]\n\n\nIt looks like we are almost set to make predictions.\n\nMake predictions. First, we will collect the intervals for the genes we want, check the object and make sure we are on the right track. Next, we will call our run_predictions function.\n\n\nmy_intervals = collect_intervals(chromosomes= my_chromosomes, gene_list= my_genes) # here, we collect the intervals for that gene; replace ... with the right objects\nmy_intervals\n\n{'TMEM69': ['1', 46152886, 46160115],\n 'SNIP1': ['1', 38002142, 38019905],\n 'RAP1GAP': ['1', 21922708, 21995856],\n 'AMIGO1': ['1', 110046797, 110052360]}\n\n\n\nmy_predictions = run_predictions(gene_intervals= my_intervals, tss_dataframe= my_tss_list, individuals_list=my_individuals)\n\nCurrently on gene TMEM69, and predicting on individual NA19144...\nCurrently on gene TMEM69, and predicting on individual NA18933...\nCurrently on gene TMEM69, and predicting on individual HG00327...\nCurrently on gene TMEM69, and predicting on individual NA19138...\nCurrently on gene TMEM69, and predicting on individual NA19096...\nCurrently on gene TMEM69, and predicting on individual HG00133...\nCurrently on gene TMEM69, and predicting on individual NA20757...\nCurrently on gene TMEM69, and predicting on individual NA20803...\nCurrently on gene TMEM69, and predicting on individual NA18923...\nCurrently on gene TMEM69, and predicting on individual HG00355...\nCurrently on gene SNIP1, and predicting on individual NA19144...\nCurrently on gene SNIP1, and predicting on individual NA18933...\nCurrently on gene SNIP1, and predicting on individual HG00327...\nCurrently on gene SNIP1, and predicting on individual NA19138...\nCurrently on gene SNIP1, and predicting on individual NA19096...\nCurrently on gene SNIP1, and predicting on individual HG00133...\nCurrently on gene SNIP1, and predicting on individual NA20757...\nCurrently on gene SNIP1, and predicting on individual NA20803...\nCurrently on gene SNIP1, and predicting on individual NA18923...\nCurrently on gene SNIP1, and predicting on individual HG00355...\nCurrently on gene RAP1GAP, and predicting on individual NA19144...\nCurrently on gene RAP1GAP, and predicting on individual NA18933...\nCurrently on gene RAP1GAP, and predicting on individual HG00327...\nCurrently on gene RAP1GAP, and predicting on individual NA19138...\nCurrently on gene RAP1GAP, and predicting on individual NA19096...\nCurrently on gene RAP1GAP, and predicting on individual HG00133...\nCurrently on gene RAP1GAP, and predicting on individual NA20757...\nCurrently on gene RAP1GAP, and predicting on individual NA20803...\nCurrently on gene RAP1GAP, and predicting on individual NA18923...\nCurrently on gene RAP1GAP, and predicting on individual HG00355...\nCurrently on gene AMIGO1, and predicting on individual NA19144...\nCurrently on gene AMIGO1, and predicting on individual NA18933...\nCurrently on gene AMIGO1, and predicting on individual HG00327...\nCurrently on gene AMIGO1, and predicting on individual NA19138...\nCurrently on gene AMIGO1, and predicting on individual NA19096...\nCurrently on gene AMIGO1, and predicting on individual HG00133...\nCurrently on gene AMIGO1, and predicting on individual NA20757...\nCurrently on gene AMIGO1, and predicting on individual NA20803...\nCurrently on gene AMIGO1, and predicting on individual NA18923...\nCurrently on gene AMIGO1, and predicting on individual HG00355...\n\n\nAt this point, we will leave you to make your own plots…\n\ntemp = prepare_for_plot_tracks(gene=my_genes[0], individual=my_individuals[0], all_predictions=my_predictions[1], chromosome=['1'])\nplot_tracks(tracks=temp['gene_tracks'], interval=temp['gene_intervals'])\n\n\n\n\n\n# looking at SNIP1 for first person \n\npd.DataFrame(my_predictions[0][my_genes[1]][my_individuals[0]], index=['haplotype_1', 'haplotype_2'])\n\n\n\n\n\n\n\n\n38019905\n38019891\n38019849\n38019903\n\n\n\n\nhaplotype_1\n470.439636\n470.439636\n474.466827\n470.439636\n\n\nhaplotype_2\n467.985107\n467.985107\n472.042694\n467.985107"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html",
    "title": "Import Libraries",
    "section": "",
    "text": "import tensorflow as tf\n# Make sure the GPU is enabled \nassert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -&gt; Change runtime type -&gt; GPU'\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nimport tensorflow_hub as hub # for interacting with saved models and tensorflow hub\nimport joblib\nimport gzip # for manipulating compressed files\nimport kipoiseq # for manipulating fasta files\nfrom kipoiseq import Interval # same as above, really\nimport pyfaidx # to index our reference genome file\nimport pandas as pd # for manipulating dataframes\nimport numpy as np # for numerical computations\nimport matplotlib.pyplot as plt # for plotting\nimport matplotlib as mpl # for plotting\nimport seaborn as sns # for plotting\nimport pickle # for saving large objects\nimport os, sys # functions for interacting with the operating system\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nNum GPUs Available:  4"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#define-paths",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#define-paths",
    "title": "Import Libraries",
    "section": "Define Paths",
    "text": "Define Paths\n\ntransform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\nmodel_path = 'https://tfhub.dev/deepmind/enformer/1'\nfasta_file = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa'\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#define-functions",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#define-functions",
    "title": "Import Libraries",
    "section": "Define Functions",
    "text": "Define Functions\n\n# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\nSEQUENCE_LENGTH = 393216\n\nclass Enformer:\n\n  def __init__(self, tfhub_url):\n    self._model = hub.load(tfhub_url).model\n\n  def predict_on_batch(self, inputs):\n    predictions = self._model.predict_on_batch(inputs)\n    return {k: v.numpy() for k, v in predictions.items()}\n\n  @tf.function\n  def contribution_input_grad(self, input_sequence,\n                              target_mask, output_head='human'):\n    input_sequence = input_sequence[tf.newaxis]\n\n    target_mask_mass = tf.reduce_sum(target_mask)\n    with tf.GradientTape() as tape:\n      tape.watch(input_sequence)\n      prediction = tf.reduce_sum(\n          target_mask[tf.newaxis] *\n          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n\n    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n    input_grad = tf.squeeze(input_grad, axis=0)\n    return tf.reduce_sum(input_grad, axis=-1)\n\n\nclass EnformerScoreVariantsRaw:\n\n  def __init__(self, tfhub_url, organism='human'):\n    self._model = Enformer(tfhub_url)\n    self._organism = organism\n\n  def predict_on_batch(self, inputs):\n    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n\n    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n\n\nclass EnformerScoreVariantsNormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human'):\n    assert organism == 'human', 'Transforms only compatible with organism=human'\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      transform_pipeline = joblib.load(f)\n    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)\n\n\nclass EnformerScoreVariantsPCANormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human', num_top_features=500):\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      self._transform = joblib.load(f)\n    self._num_top_features = num_top_features\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)[:, :self._num_top_features]\n\n\n# TODO(avsec): Add feature description: Either PCX, or full names.\n\n\n# @title `variant_centered_sequences`\n\nclass FastaStringExtractor:\n\n    def __init__(self, fasta_file):\n        self.fasta = pyfaidx.Fasta(fasta_file)\n        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n    #import pd.Interval as Interval\n    def extract(self, interval: Interval, **kwargs) -&gt; str:\n        # Truncate interval if it extends beyond the chromosome lengths.\n        chromosome_length = self._chromosome_sizes[interval.chrom]\n        trimmed_interval = Interval(interval.chrom,\n                                    max(interval.start, 0),\n                                    min(interval.end, chromosome_length),\n                                    )\n        # pyfaidx wants a 1-based interval\n        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n                                          trimmed_interval.start + 1,\n                                          trimmed_interval.stop).seq).upper()\n        # Fill truncated values with N's.\n        pad_upstream = 'N' * max(-interval.start, 0)\n        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n        return pad_upstream + sequence + pad_downstream\n\n    def close(self):\n        return self.fasta.close()\n\n\ndef one_hot_encode(sequence):\n  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n\n\n\n# @title `plot_tracks`\n\ndef plot_tracks(tracks, interval, height=1.5):\n  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n  for ax, (title, y) in zip(axes, tracks.items()):\n    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n    ax.set_title(title)\n    sns.despine(top=True, right=True, bottom=True)\n  ax.set_xlabel(str(interval))\n  plt.tight_layout()\n\n\nimport Bio\n\nfrom Bio.Seq import Seq\ndef create_rev_complement(dna_string):\n    return(str(Seq(dna_string).reverse_complement()))\n\n\ndef prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n\n  '''\n\n  Parameters:\n          predicitions (A numpy array): All predictions from the track\n          gene (a gene name, character): a gene\n          tss_df: a list of dataframe of genes and their transcription start sites\n  Returns:\n          A dictionary of cage experiment predictions and a list of transcription start sites\n\n  '''\n\n  output = dict()\n  for tdf in tss_df:\n    if gene not in tdf.genes.values:\n      continue\n    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n    gene_tss_list = list(set(gene_tss_list))\n  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n  output['gene_TSS'] = gene_tss_list # a list\n\n\n  return(output) # a dictionary\n\ndef quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n\n  '''\n  Parameters:\n          low_range (int): The lower interval\n          TSS (list of integers): A list of TSS for a gene\n          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n  Returns:\n          A dictionary of gene expression predictions for each TSS for a gene\n    '''\n  tss_predictions = dict()\n  for tss in TSS:\n    bin_start = low_range + ((768 + 320) * 128)\n    count = -1\n    while bin_start &lt; tss:\n      bin_start = bin_start + 128\n      count += 1\n    if count &gt;= len(cage_predictions)-1:\n      continue\n    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n    tss_predictions[tss] = cage_preds\n\n  return(tss_predictions)\n\ndef collect_intervals(chromosomes = [\"22\"], gene_list=None):\n\n  '''\n    Parameters :\n      chromosomes : a list of chromosome numbers; each element should be a string format\n      gene_list : a list of genes; the genes should be located on those chromosomes\n\n    Returns :\n      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n  '''\n\n  gene_intervals = {} # Collect intervals for our genes of interest\n\n  for chrom in chromosomes:\n    with open(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n      for line in chrom_genes:\n        split_line = line.strip().split(\"\\t\")\n        gene_intervals[split_line[2]] = [\n                                          split_line[0],\n                                          int(split_line[3]),\n                                          int(split_line[4])\n                                        ]\n\n  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n    return(use_genes)\n  elif isinstance(gene_list, type(None)):\n    return(gene_intervals)\n\n\ndef run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n  '''\n  Parameters :\n    gene_intervals : the results from calling `collect_intervals`\n    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n\n  Returns :\n    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n  '''\n\n  gene_output = dict()\n  gene_predictions = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2]) # creates an interval to select the right sequences\n    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n    try:\n      cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n    except:\n      continue\n    individual_results = dict()\n    individual_prediction = dict()\n\n    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n      use_individuals = individuals_list\n    elif isinstance(individuals_list, type(None)):\n      use_individuals = cur_gene_vars.columns[4:]\n\n    for individual in use_individuals:\n      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n      # two haplotypes per individual\n      haplo_1 = list(target_fa[:])\n      haplo_2 = list(target_fa[:])\n\n      ref_mismatch_count = 0\n      for i,row in cur_gene_vars.iterrows():\n\n        geno = row[individual].split(\"|\")\n        if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n          continue\n        if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n          continue\n        if geno[0] == \"1\":\n          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n        if geno[1] == \"1\":\n          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n      # predict on the individual's two haplotypes\n      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n\n      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n      individual_prediction[individual] = temp_predictions\n\n      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n      temp_list = list()\n\n      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n\n      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n\n      temp_list.append(tss_predictions_1)\n      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n\n      individual_results[individual] = temp_list # save for the individual\n\n    gene_output[gene] = individual_results\n    gene_predictions[gene] = individual_prediction\n\n  return([gene_output, gene_predictions])\n\n\ndef collect_target_intervals(gene_intervals):\n\n  '''\n  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n  '''\n\n  target_intervals_dict = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\n    target_intervals_dict[gene] = target_interval\n\n  return(target_intervals_dict)\n\ndef prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n\n  '''\n  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n\n  Parameters:\n    - gene\n    - individual\n    - all_predictions\n  '''\n\n  haplo_predictions = all_predictions[gene][individual]\n  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n\n  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n  gene_intervals = collect_target_intervals(gene_intervals)\n\n  output = dict()\n  output['gene_tracks'] = gene_tracks\n  output['gene_intervals'] = gene_intervals[gene]\n\n  return(output)\n\ndef check_individuals(path_to_bed_file, list_of_individuals):\n\n  '''\n  Checks if an individual is missing in bed variation files.\n  These individuals should be removed prior to training\n  '''\n\n  myfile = open(path_to_bed_file, 'r')\n  myline = myfile.readline()\n  bed_names = myline.split('\\t')[4:]\n  myfile.close()\n\n  if set(list_of_individuals).issubset(set(bed_names)) == False:\n    missing = list(set(list_of_individuals).difference(bed_names))\n    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n  else:\n    missing = []\n    print('All individuals are present in the bed file.')\n\n  return(missing)\n\n\ndef geno_to_seq(gene, individual):\n      # two haplotypes per individual\n  haplo_1 = list(target_fa[:])\n  haplo_2 = list(target_fa[:])\n\n  ref_mismatch_count = 0\n  for i,row in cur_gene_vars.iterrows():\n\n    geno = row[individual].split(\"|\")\n    if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n      continue\n    if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n      continue\n    if geno[0] == \"1\":\n      haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n    if geno[1] == \"1\":\n      haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n  return haplo_1, haplo_2\n\n      # predict on the individual's two haplotypes\n    \n\n\ndef run_predictions2(gene, chrom, indiv):\n    '''\n    Parameters :\n       gene: gene to run (string)\n       chrom: chrom gene is on (string)\n       indiv: individual to run (string)\n       chrNtss: variable of tss for chr\n    Returns :\n        A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n    '''\n    \n    gene_intervals = collect_intervals(chromosomes=[chrom], gene_list=[gene])\n    individuals_list = [indiv]\n\n    for gene in gene_intervals.keys():\n        global fasta_extractor\n        gene_interval = gene_intervals[gene]\n        target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                            gene_interval[1],\n                                            gene_interval[2]) # creates an interval to select the right sequences\n        target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n        window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n        try:\n            cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n        except:\n            continue\n        individual_prediction = dict()\n\n        if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n            use_individuals = individuals_list\n        elif isinstance(individuals_list, type(None)):\n            use_individuals = cur_gene_vars.columns[4:]\n\n        for individual in use_individuals:\n            # two haplotypes per individual\n            haplo_1 = list(target_fa[:])\n            haplo_2 = list(target_fa[:])\n\n            ref_mismatch_count = 0\n            for i,row in cur_gene_vars.iterrows():\n\n                geno = row[individual].split(\"|\")\n                if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n                    continue\n                if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n                    continue\n                if geno[0] == \"1\":\n                    haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n                if geno[1] == \"1\":\n                    haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n            # predict on the individual's two haplotypes\n            global model\n\n            ohe_haplo_1 = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\n            ohe_haplo_2 = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\n\n            ohe_haplo_avg = np.add(ohe_haplo_1, ohe_haplo_2) / 2\n                                         \n            prediction_1 = model.predict_on_batch(ohe_haplo_1)['human'][0]\n            prediction_2 = model.predict_on_batch(ohe_haplo_2)['human'][0]\n            prediction_avg = model.predict_on_batch(ohe_haplo_avg)['human'][0]\n            \n            post_avg = (prediction_1 + prediction_2) / 2\n            pre_avg = prediction_avg\n\n    return([pre_avg, post_avg])\n\n\ndef get_relmax(arr):\n    col_max = np.max(arr, axis=0)\n    relmax = arr / col_max\n    return relmax\n\ndef get_relmed(arr):\n    col_med = np.median(arr, axis=0)\n    relmed = arr / col_med\n    return relmed\n\n\nclass RunCompare():\n\n    def __init__(self, gene, chrom, indiv):\n        # starting variables\n        self.gene = gene\n        self.chrom = chrom\n        self.indiv = indiv\n        # run predictions\n        self.pre_avg, self.post_avg = run_predictions2(gene, chrom, indiv)\n        # make diffmats\n        self.diffmat = self.pre_avg - self.post_avg\n        self.abs_diffmat = abs(self.diffmat)\n        self.rel_diffmat = self.abs_diffmat / (abs(self.pre_avg) + abs(self.post_avg) + 1**-16) * 100\n        self.relmax_diffmat = get_relmax(self.abs_diffmat)\n        self.relmed_diffmat = get_relmed(self.abs_diffmat)\n\n    def get_summary(self, arr):\n        summary = {\n            \"mean\": np.mean(arr),\n            \"median\": np.median(arr),\n            \"std_dev\": np.std(arr),\n            \"minimum\": np.min(arr),\n            \"maximum\": np.max(arr),\n            \"total_sum\": np.sum(arr),\n            \"q1\": np.percentile(arr, 25),\n            \"q2\": np.percentile(arr, 50),\n            \"q3\": np.percentile(arr, 75),\n            \"iqr\": np.percentile(arr, 75) - np.percentile(arr, 25)\n        }\n        return summary\n    \n    def get_outliers(self, arr, tol):\n        outs = arr[arr &gt; tol]\n        return outs\n    \n    def get_outlier_inds(self, arr, tol):\n        out_inds = np.where(arr &gt; tol)\n        out_inds_arr = np.array(list(zip(indices[0], indices[1])))\n\n        row_inds = out_inds[0]\n        col_inds = out_inds[1]\n\n        return [out_inds_arr, row_inds, col_inds]\n    \n    def plot_hist(self, arr, bin_num):\n        plt.hist(arr, bins=bin_num)\n        # Add labels and title\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        # Display the plot\n        plt.show()\n\n    def plot_tol_vs_outs(self, arr, mintol, maxtol, steps):\n        x = np.linspace(maxtol, mintol, steps)\n        y = []\n        for tol in x:\n            y.append(len(self.get_outliers(arr, tol)))\n\n        plt.scatter(x, y)\n        # Add labels and title\n        plt.xlabel('tolerance')\n        plt.ylabel('num outliers')\n        # Display the plot\n        plt.show()\n        return None\n    \n    def make_df(self, arr, tol):\n        global track_names\n        outs = self.get_outliers(arr, tol)\n        all_inds, col_inds, row_inds = self.get_outlier_inds(arr, tol)\n        data = {\n            'name': [track_names[i] for i in col_inds],\n            'bin': row_inds,\n            'diff': outs\n        }\n        df = pd.DataFrame(data)\n        df_sorted = df.sort_values('diff')\n        return df_sorted\n\n\ndef print_comparisons(pre_average, post_average, tolerance):\n\n    dict = {}\n    diffmat = pre_average - post_average\n\n    # abs diff matrix\n    abs = {}\n    print(\"Absolute Difference:\")\n\n    abs_diffmat = np.sqrt(np.square(diffmat)) # make abs diff mat\n    \n    abs_diffmat_summary = get_stats(abs_diffmat) # get summary of mat\n    print(f\"Summary Statistics: {abs_diffmat_summary}\") # print summary\n\n    # get outlier differences\n    outlier_abs_diff = abs_diffmat[abs_diffmat&gt;tolerance]\n\n\n    # make hist of out diffs\n\n    \n\n\n    # rel diff matrix\n    rel_diff = (abs_diff) / ((pre_average + post_average) + 10**-16)\n\n\n    # rel max diff matrix\n\n\n    dict[\"abs\"] = abs\n\n    return dict"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#prepare-input-data",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#prepare-input-data",
    "title": "Import Libraries",
    "section": "Prepare input data",
    "text": "Prepare input data\n\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')\n\n\ntrack_names = df_targets['description'].tolist()\n\n\nchrom_bed_downloads = pd.read_csv(\"https://uchicago.box.com/shared/static/du77wf31li38tciv8imivwu57svae03p.csv\")\nchrom_bed_downloads.index = chrom_bed_downloads[\"chroms\"]\n\nchrom_bed_downloads.head(10)\n\n\n\n\n\n\n\n\nchroms\nlink\n\n\nchroms\n\n\n\n\n\n\n1\n1\nhttps://uchicago.box.com/shared/static/9q9n4a0...\n\n\n2\n2\nhttps://uchicago.box.com/shared/static/1tk6a3f...\n\n\n3\n3\nhttps://uchicago.box.com/shared/static/77ldwqq...\n\n\n4\n4\nhttps://uchicago.box.com/shared/static/s0g48al...\n\n\n5\n5\nhttps://uchicago.box.com/shared/static/yafgxb1...\n\n\n6\n6\nhttps://uchicago.box.com/shared/static/9vpxc7z...\n\n\n7\n7\nhttps://uchicago.box.com/shared/static/hkru0gi...\n\n\n8\n8\nhttps://uchicago.box.com/shared/static/ruac33s...\n\n\n9\n9\nhttps://uchicago.box.com/shared/static/dfw6gkj...\n\n\n10\n10\nhttps://uchicago.box.com/shared/static/ek50gvt...\n\n\n\n\n\n\n\n\nchr1_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr17_tss_by_gene.txt', sep='\\t')\namigo1_variations = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr17/chr17_GSDMB.bed', sep='\\t')\ngeuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\ngeuvadis_gene_expression.head(5)\n\n\n\n\n\n\n\n\ngene_id\ngene_name\nTargetID\nChr\nCoord\nHG00096\nHG00097\nHG00099\nHG00100\nHG00101\n...\nNA20810\nNA20811\nNA20812\nNA20813\nNA20814\nNA20815\nNA20816\nNA20819\nNA20826\nNA20828\n\n\n\n\n0\nENSG00000223972.4\nDDX11L1\nENSG00000223972.4\n1\n11869\n0.320818\n0.344202\n0.354225\n0.478064\n-0.102815\n...\n1.008605\n0.384489\n0.581284\n0.513981\n0.667449\n0.350890\n0.186103\n-0.037976\n0.405439\n0.199143\n\n\n1\nENSG00000227232.3\nWASH7P\nENSG00000227232.3\n1\n29806\n33.714457\n20.185174\n18.095407\n24.100871\n29.018719\n...\n30.980194\n34.086207\n39.678442\n29.643513\n27.120420\n29.121624\n31.117198\n32.047074\n22.798959\n23.563874\n\n\n2\nENSG00000243485.1\nMIR1302-11\nENSG00000243485.1\n1\n29554\n0.240408\n0.157456\n0.218806\n0.320878\n0.067833\n...\n0.065940\n0.228784\n0.140642\n0.283905\n0.273821\n0.286311\n0.324060\n0.049574\n0.255288\n0.157440\n\n\n3\nENSG00000238009.2\nRP11-34P13.7\nENSG00000238009.2\n1\n133566\n0.328272\n0.327932\n0.090064\n0.420443\n0.220269\n...\n0.274071\n0.384179\n0.533693\n0.307221\n0.307367\n0.400278\n0.612321\n0.666633\n0.281138\n1.346129\n\n\n4\nENSG00000239945.1\nRP11-34P13.8\nENSG00000239945.1\n1\n91105\n0.332171\n-0.032164\n0.017323\n0.424677\n0.214025\n...\n0.347323\n0.346744\n0.073580\n0.400396\n0.470517\n0.069749\n0.299353\n0.090019\n0.282554\n-0.157170\n\n\n\n\n5 rows × 467 columns\n\n\n\n\nmodel = Enformer(model_path) # here we load the model architecture.\n\nfasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data\n\n\ngene_intervals = collect_intervals(chromosomes=['17'], gene_list=['GSDMB'])\nprint(gene_intervals)\n\n{'GSDMB': ['17', 38060848, 38077313]}"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#run-predictions",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#run-predictions",
    "title": "Import Libraries",
    "section": "Run Predictions",
    "text": "Run Predictions\nWe’ll pick one individual at random.\n\n# rand_individual = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], replace=False) # individuals we are interested in\nrand_individual = 'NA12413'\n\n'NA12413'\n\n\n\ngene = 'GSDMB'\ngene_interval = gene_intervals[gene]\ntarget_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\ntarget_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))\nwindow_coords = target_interval.resize(SEQUENCE_LENGTH)\ncur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n\n\nhaplo_1, haplo_2 = geno_to_seq(gene, rand_individual)\n\nhaplo_1_enc = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\nhaplo_2_enc = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\naverage_enc = np.add(haplo_1_enc, haplo_2_enc) / 2\n\n\nprediction_1 = model.predict_on_batch(haplo_1_enc)['human'][0]\nprediction_2 = model.predict_on_batch(haplo_2_enc)['human'][0]\n\npost_average = (prediction_1 + prediction_2) / 2\npre_average = model.predict_on_batch(average_enc)['human'][0]"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#comparing-predictions",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#comparing-predictions",
    "title": "Import Libraries",
    "section": "Comparing Predictions",
    "text": "Comparing Predictions\n\npre_average2, post_average2 = run_predictions2(gene, '17', rand_individual)\n\nCurrently on gene GSDMB, and predicting on individual NA12413...\n\n\n\ndiff = pre_average - post_average\n\nabs_diff = np.sqrt(np.square(diff))\n\nrel_diff = (abs_diff) / ((pre_average + post_average) + 10**-16)\n\n\n# Summary Statistics of Absolute Differece\narr = abs_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.011741725\nMedian: 0.0024814606\nStandard Deviation: 0.06555718\nMinimum: 0.0\nMaximum: 10.2612915\nSum: 55895.87\n\n\n\n# Summary Statistics of Relative Difference\narr = rel_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.00026652514\nMedian: 8.4674466e-05\nStandard Deviation: 0.0011749842\nMinimum: 0.0\nMaximum: 0.24099354\nSum: 1268.779\n\n\n\nbigDiff = abs_diff[abs_diff&gt;1]\nlen(bigDiff)\n\n72\n\n\n\n# Plot the histogram\nplt.hist(bigDiff, bins=20)\n\n# Add labels and title\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Histogram')\n\n# Display the plot\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "title": "Import Libraries",
    "section": "In which tracks is it not precise?",
    "text": "In which tracks is it not precise?\n\n# max diff tolerance is 1. If a diff is greater than 1 we will count it as too big\ntolerance = 1\n\nindices = np.where(abs_diff &gt; tolerance)\nindices[0][0], indices[1][0]\n\nind_of_big_diffs = np.array(list(zip(indices[0], indices[1])))\nlen(ind_of_big_diffs), ind_of_big_diffs\n\n(72,\n array([[ 773, 4740],\n        [ 773, 4746],\n        [ 773, 4747],\n        [ 773, 4748],\n        [ 773, 4754],\n        [ 773, 4759],\n        [ 773, 4760],\n        [ 773, 4764],\n        [ 773, 4766],\n        [ 773, 4770],\n        [ 773, 4777],\n        [ 773, 4782],\n        [ 773, 4797],\n        [ 773, 4808],\n        [ 773, 4810],\n        [ 773, 4815],\n        [ 773, 4816],\n        [ 773, 4817],\n        [ 773, 4818],\n        [ 773, 4819],\n        [ 773, 4868],\n        [ 773, 4869],\n        [ 773, 4870],\n        [ 773, 4874],\n        [ 773, 4877],\n        [ 773, 4879],\n        [ 773, 4881],\n        [ 773, 4884],\n        [ 773, 4885],\n        [ 773, 4886],\n        [ 773, 4887],\n        [ 773, 4890],\n        [ 773, 4892],\n        [ 773, 4893],\n        [ 773, 4897],\n        [ 773, 4898],\n        [ 773, 4900],\n        [ 773, 4902],\n        [ 773, 4905],\n        [ 773, 4906],\n        [ 773, 4909],\n        [ 773, 4920],\n        [ 773, 5056],\n        [ 773, 5057],\n        [ 773, 5072],\n        [ 773, 5073],\n        [ 773, 5078],\n        [ 773, 5079],\n        [ 773, 5080],\n        [ 773, 5106],\n        [ 773, 5110],\n        [ 773, 5115],\n        [ 773, 5127],\n        [ 773, 5144],\n        [ 773, 5150],\n        [ 773, 5196],\n        [ 773, 5198],\n        [ 773, 5212],\n        [ 773, 5213],\n        [ 773, 5236],\n        [ 773, 5238],\n        [ 773, 5300],\n        [ 829, 2652],\n        [ 830,  733],\n        [ 830,  746],\n        [ 830,  801],\n        [ 830,  810],\n        [ 830,  812],\n        [ 830,  814],\n        [ 830,  815],\n        [ 830,  822],\n        [ 830, 3647]]))\n\n\n\ncols\n\n# all the indices of the columns where the diff exceeds tolerance\ncol_inds = indices[1]\n\n\ncounts = Counter(col_inds)\n[(key,value) for key,value in counts.items() if value &gt; 8]\n\n[]\n\n\n\nprint(f\"Number of unique col ind: {len(set(col_inds))} \\nTotal col ind: {len(col_inds)}\")\n\nNumber of unique col ind: 72 \nTotal col ind: 72\n\n\n\nplt.hist(col_inds, bins=200)  # Specify the number of bins\nplt.title('Histogram of col indexes')\nplt.show()\n\n\n\n\nAnalysis: the difference exceeds the tolerance in 227 unique columns that are pretty evenly distributed, so enformer doesn’t necessarily do better or worse with averaging before/after in any particular cell line\ni want to get the amount of times it affects each col 227 uniqe cols\n\n\nrows\n\nlen(set(indices[0])), len(indices[0])\n\n(3, 72)\n\n\n\n# Summary Statistics of rows\narr1 = indices[0]\n\nprint(\"Mean:\", np.mean(arr1))\nprint(\"Median:\", np.median(arr1))\nprint(\"Standard Deviation:\", np.std(arr1))\nprint(\"Minimum:\", np.min(arr1))\nprint(\"Maximum:\", np.max(arr1))\nprint(\"Sum:\", np.sum(arr1))\n\nq1 = np.percentile(arr, 25)\nq3 = np.percentile(arr, 75)\niqr = q3 - q1\n\nprint(\"Q1:\", q1)\nprint(\"Q3:\", q3)\nprint(\"Interquartile Range:\", iqr)\n\nMean: 780.9027777777778\nMedian: 773.0\nStandard Deviation: 19.678075590631757\nMinimum: 773\nMaximum: 830\nSum: 56225\n\n\n\nplt.hist(indices[0], bins=30)  # Specify the number of bins\nplt.title('Histogram of row indexes')\nplt.show()\n\n\n\n\nAnalysis: There are only a few specific locations where enformer does worse"
  },
  {
    "objectID": "posts/2023-07-17-compare-avgs/Compare_averages.html#comparing-across-tracks",
    "href": "posts/2023-07-17-compare-avgs/Compare_averages.html#comparing-across-tracks",
    "title": "Import Libraries",
    "section": "Comparing across tracks",
    "text": "Comparing across tracks\n\nres = []\nfor i in range(5313):\n    pre_track = pre_average[:, i]\n    post_track = post_average[:, i]\n    corr = np.corrcoef(pre_track, post_track)[0][1]\n    res.append(corr)\n\nThe results from both methods are nearly identical.\n\nprint(min(res), max(res))\n\n0.9989958894392978 0.9999999912865261"
  },
  {
    "objectID": "posts/2023-07-11-plotting-preds/index.html",
    "href": "posts/2023-07-11-plotting-preds/index.html",
    "title": "Plotting Enformer Usage Notebook Predictions",
    "section": "",
    "text": "Exploring matrix\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\ndata &lt;- read.csv('/Users/lauvav/Desktop/matrix_data.csv', header = FALSE)\n\nggplot(data, aes(x = V1, y = V2)) +\n  geom_point()\n\nmatrix &lt;- as.matrix(data)\n\nclass(matrix)\n\nimage(matrix[-1,])\n\n\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = read.csv(targets_txt, sep='\\t')"
  },
  {
    "objectID": "posts/2023-07-05-hackenf/index.html",
    "href": "posts/2023-07-05-hackenf/index.html",
    "title": "Hackathon Enformer",
    "section": "",
    "text": "today we worked on the hackathon enformer ipynb (finally)\ni was slow to start because of polaris and having all the right packages installed. It finally ended up working when I changed the ! to a % when installing packages. However you only change the installations from ! to %, not any other bash code that makes folders and such because Dante changed all of them to % and his code didn’t work.\nI learned in polaris my /home/user directory (where I first started and had my hackathon files) doesn’t have that much space in it 15GB so Haky showed us a path to more space where imlab is working. /grand/TFXcan/imlab/users/ in this directory we made our own little user folders to put our own personal things. we will use the data directory in imlab to put the data that we’ll all use for future projects.\nI moved all my hackathon stuff into a new hackenf dir in my users dir\nstorage and compute stuff is different so although TFXcan ran out of hours we can still use TFXcan for storage space. TFXcan is a project that gets processing allocation and storage allocation. They used up all the the processing hours but we still have storage space.\nin the VSCode terminal, code . opens a new VSCode window with the directort you’re currently standing in. you can use this when you can’t access folders such as the root.\nQuestion: how does gene target interval resizing work? is the starting interval\nit says “Essentially, we resized the length of the gene and pad it with the native sequences to the left and to the right, such that the length of the input sequence is 393216, and we can imagine our gene right at the center of this wider interval”\nso we first started by getting an interval of length 3 bins centered around a TSS. But since enformer takes a different input size we expand the interval length. So then what was the point of choosing a bin size if we’re changing the interval anyway?\nls -lth tells you the access information to the directories/files\n07-06:\nCAGE predicts gene expression\n\nI dont understand what these graphs are for and what they mean"
  },
  {
    "objectID": "posts/2023-06-21-iris-nn/test copy.html",
    "href": "posts/2023-06-21-iris-nn/test copy.html",
    "title": "Iris Neural Network Training",
    "section": "",
    "text": "# importing packages\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\n\n\n\n# defining NN\n\nclass Net(nn.Module):\n    def __init__(self, layer_sizes):\n        super(Net, self).__init__()\n        self.layers = nn.ModuleList()\n        self.num_layers = len(layer_sizes) - 1\n\n        # Create hidden layers\n        for i in range(self.num_layers):\n            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n        \n        # output layer\n        self.layers.append(nn.Sigmoid())\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            x = torch.relu(self.layers[i](x))\n\n        return x\n\n\n# defining dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        L = self.x.shape[0]\n        return L\n\n    def __getitem__(self, i):\n        return (self.x[i, :], self.y[i])\n\n\n# getting data\n\niris = datasets.load_iris() # all data\n\ndata = torch.from_numpy(iris.data).float() # splitting into data tensors (X)\ntarget = torch.from_numpy(iris.target).long() # and target tensors (Y)\n\n# splitting dataset into training and testing groups\ntrainX, testX, trainY, testY = train_test_split(data, target, test_size=0.1, random_state=42)\n# X is data/attributes\n# Y is targets/labels\n\n# making data a Dataset object\ntrainDataset = MyDataset(trainX, trainY)\ntestDataset = MyDataset(testX, testY)\n\n# putting Dataset into Loader\ntrainLoader = DataLoader(trainDataset, batch_size=8, shuffle=False)\n# testLoader = DataLoader(testDataset, batch_size=4, shuffle=True)\n\n\nlayer_sizes = [4, 40, 40, 40, 3]  # Input size, hidden layer sizes, output size\nnet = Net(layer_sizes)\nnet\n\nNet(\n  (layers): ModuleList(\n    (0): Linear(in_features=4, out_features=40, bias=True)\n    (1-2): 2 x Linear(in_features=40, out_features=40, bias=True)\n    (3): Linear(in_features=40, out_features=3, bias=True)\n    (4): Sigmoid()\n  )\n)\n\n\n\noptimizer = optim.SGD(net.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n\n# training NN\n\nnepochs = 5000\nepoch_loss = []\ntest_loss = []\n\nfor epoch in range(nepochs):\n    net.train()\n    iter_loss = 0\n    dt_size = 0\n    for i, (bX, bY) in enumerate(trainLoader):\n        optimizer.zero_grad()   # zero the gradient buffers\n        output = net(bX)\n        loss = criterion(output, bY)\n        loss.backward()\n        optimizer.step()\n        #print(f'iteration {i}: loss {loss.item()}')\n        iter_loss += loss.item()*bX.shape[0]\n        dt_size += bX.shape[0]\n    epoch_loss.append(iter_loss/dt_size)\n    \n    net.eval() # tell the network you want to evaluate\n    with torch.no_grad():\n        output = net(testX)\n        loss = criterion(output, testY)\n        test_loss.append(loss.item())\n\n    \n    # print(f'epoch {epoch}: loss {iter_loss/(i+1)}')\n\n    # print(loss)\n    # epoch_loss\n\n\nimport matplotlib.pyplot as plt\n#plt.plot(epoch_loss)\n\nplt.plot(epoch_loss, label='train')\nplt.plot(test_loss, label='test', alpha=0.2)\nplt.legend(loc=\"upper right\")\n\n&lt;matplotlib.legend.Legend at 0x292a95dd0&gt;\n\n\n\n\n\n\n# testing NN\n\nprint(\"testing\")\noptimizer.zero_grad()\noutput = net(testX)\nprint(testX.shape)\nloss = criterion(output, testY)\nprint(loss)\n# print(output)\n\ntesting\ntorch.Size([15, 4])\ntensor(0.4740, grad_fn=&lt;NllLossBackward0&gt;)\n\n\n\n# analyzing and printing results\n\npreds = []\nfor row in output:\n    if row.max() == row[0]:\n        preds.append(0)\n    elif row.max() == row[1]:\n        preds.append(1)\n    else:\n        preds.append(2)\ntPreds = torch.tensor(preds).view(15,1)\ntTargets = testY.view(15,1)\n\nresult = torch.cat([tPreds,tTargets], dim=1)\nprint(result)\ncorrect = 0\nfor row in result:\n    if row[0] == row[1]:\n        correct += 1\n\nprint(correct)\n\ntensor([[1, 1],\n        [0, 0],\n        [2, 2],\n        [1, 1],\n        [1, 1],\n        [0, 0],\n        [1, 1],\n        [2, 2],\n        [1, 1],\n        [1, 1],\n        [2, 2],\n        [0, 0],\n        [0, 0],\n        [0, 0],\n        [0, 0]])\n15"
  },
  {
    "objectID": "posts/2023-06-21-iris-nn/test.html",
    "href": "posts/2023-06-21-iris-nn/test.html",
    "title": "Iris Neural Network Training",
    "section": "",
    "text": "# importing packages\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\n\n\n\n# defining NN\n\nclass Net(nn.Module):\n    def __init__(self, layer_sizes):\n        super(Net, self).__init__()\n        self.layers = nn.ModuleList()\n        self.num_layers = len(layer_sizes) - 1\n\n        # Create hidden layers\n        for i in range(self.num_layers):\n            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n        \n        # output layer\n        self.layers.append(nn.Sigmoid())\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            x = torch.relu(self.layers[i](x))\n\n        return x\n\n\n# defining dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        L = self.x.shape[0]\n        return L\n\n    def __getitem__(self, i):\n        return (self.x[i, :], self.y[i])\n\n\n# getting data\n\niris = datasets.load_iris() # all data\n\ndata = torch.from_numpy(iris.data).float() # splitting into data tensors (X)\ntarget = torch.from_numpy(iris.target).long() # and target tensors (Y)\n\n# splitting dataset into training and testing groups\ntrainX, testX, trainY, testY = train_test_split(data, target, test_size=0.1, random_state=42)\n# X is data/attributes\n# Y is targets/labels\n\n# making data a Dataset object\ntrainDataset = MyDataset(trainX, trainY)\ntestDataset = MyDataset(testX, testY)\n\n# putting Dataset into Loader\ntrainLoader = DataLoader(trainDataset, batch_size=8, shuffle=False)\n# testLoader = DataLoader(testDataset, batch_size=4, shuffle=True)\n\n\nlayer_sizes = [4, 40, 40, 40, 3]  # Input size, hidden layer sizes, output size\nnet = Net(layer_sizes)\nnet\n\nNet(\n  (layers): ModuleList(\n    (0): Linear(in_features=4, out_features=40, bias=True)\n    (1-2): 2 x Linear(in_features=40, out_features=40, bias=True)\n    (3): Linear(in_features=40, out_features=3, bias=True)\n    (4): Sigmoid()\n  )\n)\n\n\n\noptimizer = optim.SGD(net.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n\n# training NN\n\nnepochs = 50000\nepoch_loss = []\ntest_loss = []\n\nfor epoch in range(nepochs):\n    net.train()\n    iter_loss = 0\n    dt_size = 0\n    for i, (bX, bY) in enumerate(trainLoader):\n        optimizer.zero_grad()   # zero the gradient buffers\n        output = net(bX)\n        loss = criterion(output, bY)\n        loss.backward()\n        optimizer.step()\n        #print(f'iteration {i}: loss {loss.item()}')\n        iter_loss += loss.item()*bX.shape[0]\n        dt_size += bX.shape[0]\n    epoch_loss.append(iter_loss/dt_size)\n    \n    net.eval() # tell the network you want to evaluate\n    with torch.no_grad():\n        output = net(testX)\n        loss = criterion(output, testY)\n        test_loss.append(loss.item())\n\n    \n    # print(f'epoch {epoch}: loss {iter_loss/(i+1)}')\n\n    # print(loss)\n    # epoch_loss\n\n\nimport matplotlib.pyplot as plt\n#plt.plot(epoch_loss)\n\nplt.plot(epoch_loss, label='train')\nplt.plot(test_loss, label='test', alpha=0.2)\nplt.legend(loc=\"upper right\")\n\n&lt;matplotlib.legend.Legend at 0x292a95dd0&gt;\n\n\n\n\n\n\n# testing NN\n\nprint(\"testing\")\noptimizer.zero_grad()\noutput = net(testX)\nprint(testX.shape)\nloss = criterion(output, testY)\nprint(loss)\n# print(output)\n\ntesting\ntorch.Size([15, 4])\ntensor(0.4740, grad_fn=&lt;NllLossBackward0&gt;)\n\n\n\n# analyzing and printing results\n\npreds = []\nfor row in output:\n    if row.max() == row[0]:\n        preds.append(0)\n    elif row.max() == row[1]:\n        preds.append(1)\n    else:\n        preds.append(2)\ntPreds = torch.tensor(preds).view(15,1)\ntTargets = testY.view(15,1)\n\nresult = torch.cat([tPreds,tTargets], dim=1)\nprint(result)\ncorrect = 0\nfor row in result:\n    if row[0] == row[1]:\n        correct += 1\n\nprint(correct)\n\ntensor([[1, 1],\n        [0, 0],\n        [2, 2],\n        [1, 1],\n        [1, 1],\n        [0, 0],\n        [1, 1],\n        [2, 2],\n        [1, 1],\n        [1, 1],\n        [2, 2],\n        [0, 0],\n        [0, 0],\n        [0, 0],\n        [0, 0]])\n15"
  },
  {
    "objectID": "posts/2023-07-07-parsl-sheet/index.html",
    "href": "posts/2023-07-07-parsl-sheet/index.html",
    "title": "Parsl Cheatsheet",
    "section": "",
    "text": "Imports\n\nimport parsl\nfrom parsl.app.app import python_app, bash_app\n\n\n\nMaking a python function parallelizable:\n\n@python_app\ndef py_func(param):\n  # import any packages you need\n  # code \n\n# call function normally and it will be run async\nmy_func(param) \n\n\n\nMaking a bash function parallelizable\n\nimport parsl\nfrom parsl.app.app import bash_app\n\n@bash_app\ndef bash_func(stdout='path/output.stdout', stderr='path/error.stderr'):\n    return 'bash code string'\n\n# call function\nbash_func().result()\n\n# read the output file\nwith open('output-filename.stdout', 'r') as f:\n     print(f.read())\n\n\n\nAppFutures\nwhen you run apps that take a long time, instead of getting a variable for your return result, you get an appfuture variable, which holds information about the running code.\n\n@python_app\ndef func ():\n    # code\n\n#assigning variable\napp_future = func()\n\n# boolean on whether the function is finished running or not\napp_future.done()\n\n# returns result, warning: calling this will make you wait until the function is finished\napp_future.result()\n\n# returns any exceptions raised during the app execution.\napp_future.exception()\n\n# attribute of appfuture, list of all DataFutures of function\napp_future.outputs\n\n\n\nDataFutures\nwhen you run apps that take a long time that return files, instead of getting the files for your results, you get an datafutures, which can be accessed through your appfuture’s attributes, and which contain information about the files you will receive.\n\n#assigning variable\ndata_future1 = app_future[0]\n\n# boolean on whether the data is available\ndata_future1.done()\n\n# retrieves the data object (e.g., file path, value) when it becomes available.\ndata_future1.result()\n\n# retrieves any exceptions raised during the data retrieval.\ndata_future1.exception()\n\n# references the parent AppFuture object that produced the data.\ndata_future1.parent\n\n\n\ndataflowkernel\nwip"
  },
  {
    "objectID": "posts/2023-06-23-conda/index.html",
    "href": "posts/2023-06-23-conda/index.html",
    "title": "Using Conda",
    "section": "",
    "text": "You use python to code\nthe python software itself is a directory somewhere on your computer.\nThere can actually be multiple python directories on your computer that you could use. Each can be in a different directory and have different packages available to it.\nConda is a software that lets you create an “environment” for coding\nan environment is just a directory stored somewhere in your computer that holds all the softwares and packages that your computer accesses when you use them for coding.\nYou want to use environments to organize the softwares/packages you use for different projects that might not need the same softwares/packages.\nWhen you code python (in VSCode for example), you’ll need to install packages like numpy or matplotlib to access more functions for your code. These packages are just directories that have to be stored somewhere on your computer, and your computer has to know where to look to access these packages and their functions.\nTo look for packages, (if the package directory isn’t in the immediate directory you’re currently standing in?), your computer looks at a variable called PATH. This\nyou can check the path to the current python you’re using and what environment it’s in by writing “which python” in a bash shell (like terminal on your computer or in VSCode)\nwhich python\nNow, let’s create our own new env\nto make a new env\nconda create —name envname\nactivate env to go in it and start using it\nconda activate envname\nYou’ll need to install python in your new env with\nconda install python\nThen install pip in your env to help with installing packages\nconda install pip\nOnce you have python and pip, install python packages with pip\npython -m pip install packagename\nTo leave your env and deactivate it (returns to default env)\nconda deactivate"
  },
  {
    "objectID": "posts/2023-06-23-polaris/index.html",
    "href": "posts/2023-06-23-polaris/index.html",
    "title": "Using Polaris",
    "section": "",
    "text": "You first need to have an account with ALCF, the Argonne Facility, the place that owns the supercomputer we want to use. Haky signed us up for it\nWe got an email with instructions on how to set up a password for logging into the supercomputer. We do this using the MobilePass+ app (careful not to use the MobilePass app that doesn’t have a + at the end). Enter a pin for the mobile pass app.\nOnce you have the pass set up, it will provide you with passwords that change each time you use it."
  },
  {
    "objectID": "posts/2023-06-23-polaris/index.html#conda-on-polaris",
    "href": "posts/2023-06-23-polaris/index.html#conda-on-polaris",
    "title": "Using Polaris",
    "section": "Conda on Polaris",
    "text": "Conda on Polaris\nPolaris has its own conda env that you can use\nIn your polaris login node:\nLoad the conda env\nmodule load conda/2023-01-10-unstable\nactivate the base\nconda activate base\nMake sure you’re standing in your home directory\nmkdir -p venvs/polaris/2023-01-10\ncreate a virtual environment\npython3 -m venv venvs/polaris/2023-01-10 --system-site-packages\nactivate the env\nsource venvs/polaris/2023-01-10/bin/activate\\\nupgrade pip and do something with “setuptools wheel”\npython3 -m pip install --upgrade pip setuptools wheel\nyou’re now free to pip install packages as needed into an isolated env with\npython3 -m pip install &lt;package&gt;\n:)"
  },
  {
    "objectID": "posts/2023-06-23-polaris/index.html#requesting-compute-node",
    "href": "posts/2023-06-23-polaris/index.html#requesting-compute-node",
    "title": "Using Polaris",
    "section": "Requesting Compute Node",
    "text": "Requesting Compute Node\nAs I said before, you start at a login node and must get to a compute node to run code. if you run code on the login node they’ll kick you out (?)\nqsub -I -A AIHPC4EDU -l walltime=1:00:00 -l filesystems=home:grand -q debug\nyou might have to replace AIHPC4EDU and -q debug with something else, ask Haky\nit takes a minute to get you to the compute node\nOnce you’re there, you’re in a new computer so you’ll have to activate your envs again\nload conda\nmodule load conda/2023-01-10-unstable\nactivate conda base\nconda activate base\nactivate your venv\nsource venvs/polaris/2023-01-10/bin/activate\n\nUsing Jupyter Notebook\nget your ip address\nmy_ip_address=$( ip rule | grep -w '0:' | awk '{print $3;exit}' )\nprint your ip address\necho $my_ip_address\njupyter-notebook --no-browser --ip=$my_ip_address --port=15005 # should be between 15000 and 30000"
  },
  {
    "objectID": "posts/2023-07-11-m1gpu/index.html",
    "href": "posts/2023-07-11-m1gpu/index.html",
    "title": "How to install GPU-enabled tensorflow on a mac M1",
    "section": "",
    "text": "Sam’s link\n\nin terminal, activate the conda base you want this package to be in:\ninstall new tensorflow with the code below\n\nconda install -c apple tensorflow-deps\npip install tensorflow-macos\npip install tensorflow_hub\npip install tensorflow-metal\n\n\ncheck in python script if the new gpu is available\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nif you’re on a jupyter notebook and it’s not showing up, you might have to restart your kernel\nyou should get an output that looks someting like this\n[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 10497265438367669336\nxla_global_id: -1\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nlocality {\n  bus_id: 1\n}\nincarnation: 2909437390696073084\nphysical_device_desc: \"device: 0, name: METAL, pci bus id: &lt;undefined&gt;\"\nxla_global_id: -1\n]\n2023-07-11 09:53:34.723239: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n2023-07-11 09:53:34.723298: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n2023-07-11 09:53:34.723308: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n2023-07-11 09:53:34.723367: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n2023-07-11 09:53:34.723385: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)\nif only the CPU shows up, it was not successful"
  },
  {
    "objectID": "posts/2023-06-06-post-with-code/index.html",
    "href": "posts/2023-06-06-post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/2023-07-18-targets-query/targets.html",
    "href": "posts/2023-07-18-targets-query/targets.html",
    "title": "Laura's Blog",
    "section": "",
    "text": "# import packages\nimport requests, json\nimport pandas as pd\n\n\n# Force return from the server in JSON format\nheaders = {'accept': 'application/json'}\n \n# This URL locates the ENCODE biosample with accession number ENCBS000AAA\nurl = 'https://www.encodeproject.org/files/ENCFF991ND/?format=json'\n \n# GET the object\nresponse = requests.get(url, headers=headers)\n \n# Extract the JSON response as a Python dictionary\nencff = response.json()\n\n# encff['biosample_ontology']['system_slims']\nencff\n\n{'@type': ['HTTPNotFound', 'Error'],\n 'status': 'error',\n 'code': 404,\n 'title': 'Not Found',\n 'description': 'The resource could not be found.',\n 'detail': '/files/ENCFF991ND/'}\n\n\n\n# get og df\n# loop over IDs and get each slim\n\n\n# get original targets df\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf = pd.read_csv(targets_txt, sep='\\t')\n\n\ndef get_json(id):\n    headers = {'accept': 'application/json'}\n    url = f'https://www.encodeproject.org/files/{id}/?format=json'\n    response = requests.get(url, headers=headers)\n    encff = response.json()\n    return encff\n\n\n# Make a dictionary of all encffs (only first time)\n \n# encffs = {}\n# for id in df['identifier']:\n#     encffs[id] = get_json(id)\n\n\n# # Save encffs to a file\n# with open('/Users/lauvav/Desktop/deep-learning/encffs.json', 'w') as file:\n#     json.dump(encffs, file, indent=4)\n\n\n# Load the variable from the saved encffs file\n\nwith open('/Users/lauvav/Desktop/deep-learning/encffs.json', 'r') as file:\n    encffs = json.load(file)\n\n\ndef get_slims(id):\n    encff = encffs[id]\n    system = 'NA'\n    cell = 'NA'\n    organ = 'NA'\n    developmental = 'NA'\n    \n    try:\n        bio_ont = encff['biosample_ontology']\n        system_list = bio_ont['system_slims']\n        cell_list = bio_ont['cell_slims']\n        organ_list = bio_ont['organ_slims']\n        developmental_list = bio_ont['developmental_slims']\n    \n        system = ', '.join(system_list)\n        cell = ', '.join(cell_list)\n        organ = ', '.join(organ_list)\n        developmental = ', '.join(developmental_list)\n    except KeyError:\n        pass\n    \n    return [system, cell, organ, developmental]\n\n\nfor index, row in df.iterrows():\n    system, cell, organ, dev = get_slims(row['identifier'])\n\n    df.at[index, 'system_slims'] = system\n    df.at[index, 'cell_slims'] = cell\n    df.at[index, 'organ_slims'] = organ\n    df.at[index, 'developmental_slims'] = dev\n\n\ndf\n\n\n\n\n\n\n\n\nindex\ngenome\nidentifier\nfile\nclip\nscale\nsum_stat\ndescription\nsystem_slims\ncell_slims\norgan_slims\ndevelopmental_slims\n\n\n\n\n0\n0\n0\nENCFF833POA\n/home/drk/tillage/datasets/human/dnase/encode/...\n32\n2\nmean\nDNASE:cerebellum male adult (27 years) and mal...\ncentral nervous system\n\nbrain\nectoderm\n\n\n1\n1\n0\nENCFF110QGM\n/home/drk/tillage/datasets/human/dnase/encode/...\n32\n2\nmean\nDNASE:frontal cortex male adult (27 years) and...\ncentral nervous system\n\nbrain\nectoderm\n\n\n2\n2\n0\nENCFF880MKD\n/home/drk/tillage/datasets/human/dnase/encode/...\n32\n2\nmean\nDNASE:chorion\n\n\nextraembryonic component\nmesoderm\n\n\n3\n3\n0\nENCFF463ZLQ\n/home/drk/tillage/datasets/human/dnase/encode/...\n32\n2\nmean\nDNASE:Ishikawa treated with 0.02% dimethyl sul...\nreproductive system\ncancer cell\nuterus\n\n\n\n4\n4\n0\nENCFF890OGQ\n/home/drk/tillage/datasets/human/dnase/encode/...\n32\n2\nmean\nDNASE:GM03348\nintegumental system\nfibroblast\nskin of body, connective tissue\nectoderm\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5308\n5308\n0\nCNhs14239\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:epithelioid sarcoma cell line:HS-ES-2R\nNA\nNA\nNA\nNA\n\n\n5309\n5309\n0\nCNhs14240\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:squamous cell lung carcinoma cell line:RE...\nNA\nNA\nNA\nNA\n\n\n5310\n5310\n0\nCNhs14241\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:gastric cancer cell line:GSS\nNA\nNA\nNA\nNA\n\n\n5311\n5311\n0\nCNhs14244\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:carcinoid cell line:NCI-H727\nNA\nNA\nNA\nNA\n\n\n5312\n5312\n0\nCNhs14245\n/home/drk/tillage/datasets/human/cage/fantom/C...\n384\n1\nsum\nCAGE:lung adenocarcinoma, papillary cell line:...\nNA\nNA\nNA\nNA\n\n\n\n\n5313 rows × 12 columns\n\n\n\n\n# Makes columns for one ind\n# df.at[2, 'system_slims'] = add_system(df.at[2, 'identifier'])\n\n# Make columns for a list of inds\n# row_indices = range(10)\n# for row_index in row_indices:\n#     system, cell, organ, dev = get_slims(df.at[row_index, 'identifier'])\n\n#     df.loc[row_index, 'system_slims'] = system\n#     df.loc[row_index, 'cell_slims'] = cell\n#     df.loc[row_index, 'organ_slims'] = organ\n#     df.loc[row_index, 'developmental_slims'] = dev"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html",
    "href": "posts/2023-06-08-python-basics/index.html",
    "title": "Python Basics",
    "section": "",
    "text": "Type\nName\nDescription\nExamples\n\n\n\n\nInteger\nint\nall integers\n-2, -1, 0, 1, 2\n\n\nFloat\nfloat\nall decimals\n1.0, 2.5, 4.987\n\n\nString\nstr\nsequence of characters\n“any text enclosed in single or double quotes, includes spaces and special characters”\n\n\nBoolean\nbool\nexpression that is True or False\nTrue, False, 2==2 (is read as True), 2==1 (is read as False)\n\n\n\nName variables using “camel case” format. Single word variable names should be all lowercase and multi-word names should have all but the first word capitalized capitalize every word after the first and have the rest as lowercase it’s best for variable names to be short but clear so you know what it’s referring to (This is not required but is good practice) example: word, twoWords, varNameExample, variable can contain numbers but cannot start with them Important: variables cannot be named special words that are already define in python, such as any datatype or built-in python function. Python will get confused because the variable name and function name and will give you an error. restricted variable names: int, float, str, bool, if, else, for, while, in, list, dict, def, class"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#operations",
    "href": "posts/2023-06-08-python-basics/index.html#operations",
    "title": "Python Basics",
    "section": "Operations:",
    "text": "Operations:\nPython can compute simple calculations with operators\n\n\n\nCharacter\nOperation\nExample\n\n\n\n\n+\naddition\n1 + 2 -&gt; 3\n\n\n-\nsubtraction\n10 - 5 -&gt; 5\n\n\n*\nmultiplication\n3 * 4 -&gt; 12\n\n\n/\ndivision\n15 / 3 -&gt; 5\n\n\n**\npower\n4 ** 2 -&gt; 16\n\n\n//\nfloor division\n7 // 2 -&gt; 3\n\n\n\n(There don’t need to be spaces between the numbers and operations, it’s up to you)"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#user-input",
    "href": "posts/2023-06-08-python-basics/index.html#user-input",
    "title": "Python Basics",
    "section": "User Input",
    "text": "User Input\nIf you want to interact with the user of your code, use the input() command\n# General Format: \nuserInput = input(\"message\")\nRunnning this line of code will prompt the user to enter a response based on what you write in the “message.” Their response will then get assigned to your variable, in this case userInput\n# Example\nuserName = input(\"What's your name? \")"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#common-functions",
    "href": "posts/2023-06-08-python-basics/index.html#common-functions",
    "title": "Python Basics",
    "section": "Common Functions",
    "text": "Common Functions\nprint(\"text\") # prints out what you write in \"text\"\nlen() # returns the length of a string, list, tuple, or dictionary"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#lists",
    "href": "posts/2023-06-08-python-basics/index.html#lists",
    "title": "Python Basics",
    "section": "Lists",
    "text": "Lists\nMaking a list: Lists can be made up of any datatype you can initialize your list with or without elements\n# Empty list\nmyList = []\n\n# List with elements\nnumList = [1, 2, 3, 4, 5]\ncolorList = ['red', 'yellow', 'green', 'blue', 'pink']\nAccessing list values by index: Python numbers each element in order, but it starts from 0\n\n\n\nIndex\n0\n1\n2\n3\n4\n\n\n\n\nnumList\n1\n2\n3\n4\n5\n\n\ncolorList\n‘red’\n‘yellow’\n‘green’\n‘blue’\n‘pink’\n\n\n\n\nthis can get confusing so just keep the 0 index in mind when coding.\n# Accessing elements by index\nlistName[index] # returns the element at the index given\n\n# examples\ncolorList[0] # returns 'red'\ncolorList[4] # returns 'pink'\ncolorList[5] # returns an error because there isn't an index of 5\nThere’s a bunch of other more specific things you can do with lists but you can just look those up as you need while you code"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#if-else-statements",
    "href": "posts/2023-06-08-python-basics/index.html#if-else-statements",
    "title": "Python Basics",
    "section": "If Else Statements",
    "text": "If Else Statements\nif condition:\n    # do something\nelse:\n    # do another thing\nyou can also add more possible conditions with elif\nif condition:\n    # do something\nelif other_condition:\n    # do something else\nelif other_condition:\n    # do something else \nelse:\n    # do another thing"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#for-and-while-loops",
    "href": "posts/2023-06-08-python-basics/index.html#for-and-while-loops",
    "title": "Python Basics",
    "section": "For and While Loops",
    "text": "For and While Loops\nfor i in range(5):\n    # do something 5 times, \n    # i starts at 0 and ends at 4, increasing by 1 each time\ncolors = ['red', 'yellow', 'green', 'blue', 'pink']\nfor x in numList:\n        # do something with x\n        # x will start at the first index and end at the last index, \n        # going up one index each time\nWhile loops continue until the condition given to them is False\nwhile condition:\n    # do something\n    # something happens that changes the condition to become False\nbe careful not to make an infinite loop. There must always be something in the loop that changes the condition to eventually become False"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#making-functions",
    "href": "posts/2023-06-08-python-basics/index.html#making-functions",
    "title": "Python Basics",
    "section": "Making Functions",
    "text": "Making Functions\ndef functionName(parameter):\n        # do something\n        return result\nNote: there doesn’t always have to be a parameter and there doesn’t always have to be a result"
  },
  {
    "objectID": "posts/2023-06-08-python-basics/index.html#object-oriented-programming",
    "href": "posts/2023-06-08-python-basics/index.html#object-oriented-programming",
    "title": "Python Basics",
    "section": "Object Oriented Programming:",
    "text": "Object Oriented Programming:\nGeneral format:\n# Creating a class\n\nclass ClassName:\n    def __init__(self, parameters):\n        # Constructor\n             self.parameters = parameters   # setting up the variables in the object\n\n    def methodName(self, parameters):\n        # Method\n        return result\n\n# Creating an instance of the class (this is the object)\nobject = ClassName(parameters)\n\n# Calling methods on object\nobject.methodName(parameters)\nself will always be a parameter in all the functions when creating a class because it needs a way of knowing how to refer to itself. however, self does not appear as a parameter outside of creating the class (I think because it’s implied? idk don’t worry about it), so when you create the object and call methods on it, you don’t use self in the parameters.\nExample:\nclass Car:\n    def __init__(self, brand, color):\n        self.brand = brand\n        self.color = color\n      \n    def changeColor(self, newColor)\n        self.color = newColor\n\n    def startEngine(self):\n        print(\"Engine started for\", self.brand)\n\n# Creating objects of the Car class\ncar1 = Car(\"Toyota\", \"Red\")\ncar2 = Car(\"Honda\", \"Blue\")\n\n\n# Accessing attributes of objects\nprint(car1.brand)  # Output: \"Toyota\"\nprint(car1.color)  # Output: \"Red\"\n\nprint(car2.brand)  # Output: \"Honda\"\nprint(car2.color)  # Output: \"Blue\"\n\n# Calling methods on objects\ncar1.changeColor()\ncar1.start_engine()  # Output: Engine started for Toyota\ncar2.start_engine()  # Output: Engine started for Honda"
  },
  {
    "objectID": "posts/2023-06-06-LLM/index.html",
    "href": "posts/2023-06-06-LLM/index.html",
    "title": "Large Language Models",
    "section": "",
    "text": "In his article “Large Language Models in Molecular Biology,” Serafim Batzoglou discusses recent advancements in deep learning-based language models and their potential to significantly impact the field of molecular biology. The convergence of LLMs with large-scale genomic and population health data is expected to propel the understanding and modeling of biomolecular systems with a level of accuracy that surpasses human capacity.\n\nLarge Language Models (LLMs):\nLLMs are advanced neural networks capable of generating text that resembles human language. They’re trained with vast amounts of data and learn to predict subsequent words in a sentence based on preceding words, allowing them to understand patterns, relationships, and context within the text.\n\n\nThe Genetic Dogma:\n\nThe central dogma of molecular biology describes the unidirectional flow of genetic information from DNA to RNA to protein. Within the DNA, there are approximately 20,000 genes responsible for synthesizing proteins, which play crucial roles in various biological processes: acting as structural components, enzymes, and facilitating communication within cells.\nThe process of protein synthesis includes transcription, splicing, and translation. Transcription produces messenger RNA (mRNA) by copying a DNA segment, which is then spliced to remove introns and retain exons, forming mature mRNA. Translation decodes the mRNA sequence into amino acids, which are linked to form proteins.\nGene regulation, mediated by transcription factors and other proteins, ensures the timely and appropriate expression of genes within cells. Chromatin structure, consisting of DNA wrapped around histone proteins, plays a role in gene accessibility and regulation; and histone modifications and DNA methylation influence gene expression by changing chromatin structure.\n\n\nGenetic Variation:\nAn individuals’ DNA and environmental influences shapes their biology throughout their lifetime. While humans share over 99.9% identical DNA, our DNA variants account for the heritability of traits, including contributions to health and disease.\nDNA variants are introduced through mutations in the DNA inherited from parents. Most variants are benign, while some may be deleterious or beneficial. Deleterious variants tend to be statistically eliminated from the population over time through natural selection. Essential genes are conserved with little to no mutation across generations due to their crucial role in fitness. Conversely, less significant genes are prone to more mutations as they have minimal fitness consequences and can be passed down without significant impact.\nAdvancements in DNA sequencing technologies have made data collection rapid and cost-effective. Sequencing-based methods can measure various molecular functions, such as gene expression and chromatin structure. Other technologies like mass spectrometry and X-ray crystallography provide insights into protein levels and structures.\nGenome-wide association studies (GWAS) correlate genetic variants with specific phenotypes, providing valuable insights into gene functions and disease mechanisms. However, large language models (LLMs) are expected to surpass traditional association analyses in linking genetic variation to function. The combination of DNA sequencing technologies, data generation capabilities, and LLMs holds promise in advancing our understanding of genetic variation and its impact on molecular mechanisms and human physiology.\n\n\nProminent Language Models in Molecular Biology:\nIn recent years, significant progress has been made in modeling the central dogma of molecular biology, offering insights into gene function and expression. While fully transforming molecular biology into a computational science or engineering human health is still a work in progress, the current momentum suggests that it’s achievable with more data and development. For example, language models like LLMs excel at learning intricate statistical properties of complex sequential data.\nBreakthroughs in different stages of the central dogma exemplify this progress. Methods like SpliceAI accurately predict gene structure by identifying splicing sites, aiding in genetic disease diagnosis. Advances in protein structure prediction, particularly with AlphaFold, have come close to solving the protein folding problem, revolutionizing biological research and drug discovery. Tools like PrimateAI-3D help annotate genetic variants as benign or pathogenic, contributing to disease diagnosis and drug target identification. Language models such as Enformer show promise in predicting gene expression from DNA sequences alone, shedding light on gene regulation. Foundation models like scGPT and Nucleotide Transformer, trained on extensive data, provide valuable insights into single-cell biology and raw DNA sequences, facilitating various downstream applications.\n\nOverall, the progress in modeling the central dogma of molecular biology demonstrates the potential of AI and deep learning in understanding gene function, expression, and regulation. Continued advancements and integration of diverse data sources will enhance our understanding of molecular biology and its impact on medicine and human health.\n\n\nLooking Forward\nThe availability of rich and affordable data is a significant driver of progress in this field. Advances in DNA sequencing technology have significantly reduced the cost of genome sequencing and other molecular assays, enabling comprehensive profiling of gene expression, chromatin structure, and other molecular layers. Initiatives like the UK Biobank and All Of Us project have collected extensive genetic and health data from large cohorts of participants, offering a wealth of information for research purposes. Cancer-focused companies, such as Tempus and Foundation Medicine, are also building vast genomic databases with clinical information.\nWhile developing these technologies, privacy concerns and the role of LLMs in clinical practice must be addressed. Proper informed consent and privacy measures are essential when training LLMs with participant data. LLMs should be seen as tools to assist healthcare professionals rather than replace them. Patient trust and verification remain crucial aspects of their application in clinical settings.\nLLMs are well-suited to integrate and analyze these diverse datasets. Through autoregressive or masked language modeling, these models can learn from single-cell datasets, functional genomics data, and clinical records to understand gene pathways, genomic variants, and their associations with human health. However, the challenge lies in technical innovations to represent and integrate different layers of information and scale up the model’s processing capacity.\nSuch an advanced LLM could have various applications, including clinical diagnosis, drug development, and advancing our understanding of molecular biology. It could aid doctors in making precise diagnoses, identify potential drug targets, and assist in personalized medicine. Additionally, the model could offer suggestions for additional experiments and contribute to filling gaps in data.\n\n\nConclusion\nMolecular biology’s transition into a computational science is facilitated by the combination of extensive data acquisition and powerful models like LLMs. In the coming years, these models will enable accurate predictions of the complex biomolecular interactions that connect our DNA, cellular biology, and overall health. This advancement is expected to have a profound impact on various aspects of medicine. Additionally, the development of open foundation models that integrate genomic and medical data will drive research, innovation, and facilitate the practice of precision medicine."
  },
  {
    "objectID": "posts/2023-06-06-welcome/index.html",
    "href": "posts/2023-06-06-welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2023-07-03-diabetes/diabetes2.html",
    "href": "posts/2023-07-03-diabetes/diabetes2.html",
    "title": "Laura's Blog",
    "section": "",
    "text": "import numpy as np  # library used for working with arrays\nimport pandas as pd # library used for data manipulation and analysis\n\nimport seaborn as sns # library for visualization\nimport matplotlib.pyplot as plt # library for visualization\n%matplotlib inline\n\n\n# to suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.datasets import load_diabetes\nimport pandas as pd\n\n# Load the diabetes dataset\ndiabetes = load_diabetes()\n\n# Convert the dataset's data to a DataFrame\ndf = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n\n# Add the target variable to the DataFrame\ndf['target'] = diabetes.target\n\n# Show the DataFrame\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\ntarget\n\n\n\n\n0\n0.038076\n0.050680\n0.061696\n0.021872\n-0.044223\n-0.034821\n-0.043401\n-0.002592\n0.019907\n-0.017646\n151.0\n\n\n1\n-0.001882\n-0.044642\n-0.051474\n-0.026328\n-0.008449\n-0.019163\n0.074412\n-0.039493\n-0.068332\n-0.092204\n75.0\n\n\n2\n0.085299\n0.050680\n0.044451\n-0.005670\n-0.045599\n-0.034194\n-0.032356\n-0.002592\n0.002861\n-0.025930\n141.0\n\n\n3\n-0.089063\n-0.044642\n-0.011595\n-0.036656\n0.012191\n0.024991\n-0.036038\n0.034309\n0.022688\n-0.009362\n206.0\n\n\n4\n0.005383\n-0.044642\n-0.036385\n0.021872\n0.003935\n0.015596\n0.008142\n-0.002592\n-0.031988\n-0.046641\n135.0\n\n\n\n\n\n\n\n\n# finds the number of columns in the dataset\ntotal_cols=len(df.axes[1])\nprint(\"Number of Columns: \"+str(total_cols))\n\nNumber of Columns: 11\n\n\n\n# finds the number of rows in the dataset\ntotal_rows = len(df.axes[0])\nprint(\"Number of Rows: \"+str(total_rows))\n\nNumber of Rows: 442\n\n\n\nprint('The dimension of the DataFrame is: ', df.ndim)\n\nThe dimension of the DataFrame is:  2\n\n\n\ndf.size\n\n4862\n\n\n\n#The info() function is used to print a concise summary of a DataFrame.\n#This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 442 entries, 0 to 441\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   age     442 non-null    float64\n 1   sex     442 non-null    float64\n 2   bmi     442 non-null    float64\n 3   bp      442 non-null    float64\n 4   s1      442 non-null    float64\n 5   s2      442 non-null    float64\n 6   s3      442 non-null    float64\n 7   s4      442 non-null    float64\n 8   s5      442 non-null    float64\n 9   s6      442 non-null    float64\n 10  target  442 non-null    float64\ndtypes: float64(11)\nmemory usage: 38.1 KB\n\n\n\n# checking for missing values (null)\n#functions that return a boolean value indicating whether the passed in argument value is in fact missing data.\n# this is an example of chaining methods\n\ndf.isnull().values.any()\n\nFalse\n\n\n\n#it can also output if there is any missing values each of the columns\n\ndf.isnull().any()\n\nage       False\nsex       False\nbmi       False\nbp        False\ns1        False\ns2        False\ns3        False\ns4        False\ns5        False\ns6        False\ntarget    False\ndtype: bool\n\n\n\n# We should find the summary statistics for all variables except 'outcome' in the dataset. \n# It is our output variable in our case. \n# Summary statistics of data represent descriptive statistics. \n# Descriptive statistics include those that summarize:\n# the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values. \n\ndf.iloc[:,0:10].describe()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\n\n\n\n\ncount\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n4.420000e+02\n\n\nmean\n-2.511817e-19\n1.230790e-17\n-2.245564e-16\n-4.797570e-17\n-1.381499e-17\n3.918434e-17\n-5.777179e-18\n-9.042540e-18\n9.293722e-17\n1.130318e-17\n\n\nstd\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n4.761905e-02\n\n\nmin\n-1.072256e-01\n-4.464164e-02\n-9.027530e-02\n-1.123988e-01\n-1.267807e-01\n-1.156131e-01\n-1.023071e-01\n-7.639450e-02\n-1.260971e-01\n-1.377672e-01\n\n\n25%\n-3.729927e-02\n-4.464164e-02\n-3.422907e-02\n-3.665608e-02\n-3.424784e-02\n-3.035840e-02\n-3.511716e-02\n-3.949338e-02\n-3.324559e-02\n-3.317903e-02\n\n\n50%\n5.383060e-03\n-4.464164e-02\n-7.283766e-03\n-5.670422e-03\n-4.320866e-03\n-3.819065e-03\n-6.584468e-03\n-2.592262e-03\n-1.947171e-03\n-1.077698e-03\n\n\n75%\n3.807591e-02\n5.068012e-02\n3.124802e-02\n3.564379e-02\n2.835801e-02\n2.984439e-02\n2.931150e-02\n3.430886e-02\n3.243232e-02\n2.791705e-02\n\n\nmax\n1.107267e-01\n5.068012e-02\n1.705552e-01\n1.320436e-01\n1.539137e-01\n1.987880e-01\n1.811791e-01\n1.852344e-01\n1.335973e-01\n1.356118e-01\n\n\n\n\n\n\n\n\nsns.displot(df['bp'], kind='kde')\nplt.show()\n\n\n\n\n\ndf[df['s6']==df['s6'].max()]['bmi']\nprint(df.loc[[23]])\nprint(df.loc[[117]])\nprint(df.loc[[350]])\n# 177 350\n\n         age      sex       bmi        bp        s1        s2        s3  \\\n23  0.045341  0.05068  0.060618  0.031065  0.028702 -0.047347 -0.054446   \n\n         s4        s5        s6  target  \n23  0.07121  0.133597  0.135612   245.0  \n          age       sex       bmi        bp        s1        s2        s3  \\\n117  0.059871 -0.044642 -0.021295  0.087287  0.045213  0.031567 -0.047082   \n\n          s4        s5        s6  target  \n117  0.07121  0.079122  0.135612   281.0  \n         age      sex       bmi        bp        s1        s2        s3  \\\n350 -0.02731  0.05068  0.060618  0.107944  0.012191 -0.017598 -0.002903   \n\n           s4        s5        s6  target  \n350 -0.002592  0.070207  0.135612   243.0  \n\n\n\n# mean \nm1 = df['bmi'].mean() \nprint(m1) \n\n# median \nm2 = df['bmi'].median() \nprint(m2)\n\n# mode  \nm3 = df['bmi'].mode()[0] \nprint(m3)\n\n-2.2455642172282577e-16\n-0.007283766209687899\n-0.03099563183506548\n\n\n\n# How many women's Glucose levels are above the mean level of Glucose \n# mean() method finds the mean of all numerical values in a series or column.\nv1 = df[df['s6']&gt;df['s6'].mean()].shape[0]\nprint(v1)\n\n# count the number of women that have their 'BloodPressure' equal to the median of 'BloodPressure' \nv2 = df[df['bp']==df['bp'].median()].shape[0]\nprint(v2)\n\n# and their 'BMI' less than the median of 'BMI'\nv3 = df[df['bmi']&lt;df['bmi'].median()].shape[0]\nprint(v3)\n\n218\n21\n218\n\n\n\ndf1 = df[(df['bp']==df['bp'].median()) & (df['bmi']&lt;df['bmi'].median())]\nnumber_of_patients=len(df1.axes[0])\nprint(\"Number of patients: \" +str(number_of_patients))\n\nNumber of patients: 9\n\n\n\n# Getting a pairwise distribution between Glucose, Skin thickness and Diabetes pedigree function.\nsns.pairplot(data=df,vars=['s6', 'bp', 'bmi'], hue = 'target')\nplt.show()\n\n\n\n\n\n# Studying the correlation between glucose and insulin using a Scatter Plot.\nsns.scatterplot(x='s6',y='bmi',data=df, hue = 'target')\nplt.show()\n\n\n\n\n\n# The scatter plot above implies that mostly the increase in glucose does relatively little change in insulin levels \n# It also shows that in some the increase in glucose increases in insulin. \n# This could probably be outliers.\n\n# Let us explore the possibility of outliers using the Box Plot.\n# Boxplot is a way to visualize the five-number summary of the variable. \n# Boxplot gives information about the outliers in the data.\n\n\nplt.boxplot(df['age'])\n\nplt.title('Boxplot of Age')\nplt.ylabel('age')\nplt.show()\n# The box plot shows the presence of outliers above the horizontal line.\n\n\n\n\n\n# Understanding the number of women in different age groups with diabetes.\nplt.hist(pima[pima['Outcome']==1]['Age'], bins = 5)\nplt.title('Distribution of Age for Women who has Diabetes')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n\n# Of all the women with diabetes most are from the age between 22 to 30.\n# The frequency of women with diabetes decreases as age increases.\n\n\n\n\n\n# understanding the number of women in different age groups without diabetes.\n\nplt.hist(pima[pima['Outcome']==0]['Age'], bins = 5)\nplt.title('Distribution of Age for Women who do not have Diabetes')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n\n# The highest number of Women without diabetes range between ages 22 to 33.\n# Women between the age of 22 to 35 are at the highest risk of diabetes \n# and also the is the highest number of those without diabetes.\n\n\n\n\n\n# The IQR or Inter Quartile Range is a statistical measure for the variability in a given data.\n# It is a methodology that is generally used to filter outliers in a dataset\n\nQ1 = pima.quantile(0.25)\nQ3 = pima.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)\n\nPregnancies                   5.0000\nGlucose                      41.2500\nBloodPressure                18.0000\nSkinThickness                32.0000\nInsulin                     127.2500\nBMI                           9.3000\nDiabetesPedigreeFunction      0.3825\nAge                          17.0000\nOutcome                       1.0000\ndtype: float64\n\n\n\n# Correlation is a statistic that measures the degree to which two variables move with each other.\ncorr_matrix = df.iloc[:,0:10].corr()\ncorr_matrix\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\n\n\n\n\nage\n1.000000\n0.173737\n0.185085\n0.335428\n0.260061\n0.219243\n-0.075181\n0.203841\n0.270774\n0.301731\n\n\nsex\n0.173737\n1.000000\n0.088161\n0.241010\n0.035277\n0.142637\n-0.379090\n0.332115\n0.149916\n0.208133\n\n\nbmi\n0.185085\n0.088161\n1.000000\n0.395411\n0.249777\n0.261170\n-0.366811\n0.413807\n0.446157\n0.388680\n\n\nbp\n0.335428\n0.241010\n0.395411\n1.000000\n0.242464\n0.185548\n-0.178762\n0.257650\n0.393480\n0.390430\n\n\ns1\n0.260061\n0.035277\n0.249777\n0.242464\n1.000000\n0.896663\n0.051519\n0.542207\n0.515503\n0.325717\n\n\ns2\n0.219243\n0.142637\n0.261170\n0.185548\n0.896663\n1.000000\n-0.196455\n0.659817\n0.318357\n0.290600\n\n\ns3\n-0.075181\n-0.379090\n-0.366811\n-0.178762\n0.051519\n-0.196455\n1.000000\n-0.738493\n-0.398577\n-0.273697\n\n\ns4\n0.203841\n0.332115\n0.413807\n0.257650\n0.542207\n0.659817\n-0.738493\n1.000000\n0.617859\n0.417212\n\n\ns5\n0.270774\n0.149916\n0.446157\n0.393480\n0.515503\n0.318357\n-0.398577\n0.617859\n1.000000\n0.464669\n\n\ns6\n0.301731\n0.208133\n0.388680\n0.390430\n0.325717\n0.290600\n-0.273697\n0.417212\n0.464669\n1.000000\n\n\n\n\n\n\n\n\n# 'annot=True' returns the correlation values\nplt.figure(figsize=(8,8))\nsns.heatmap(corr_matrix, annot = True)\n\n# display the plot\nplt.show()\n\n\n\n\n\n# The closer the correlation is to 1, the more positively correlated they are; \n# that is as one increases so does the other and the closer to 1 the stronger this relationship is.\n# A correlation closer to -1 is similar,\n# but instead of both increasing one variable will decrease as the other increases."
  },
  {
    "objectID": "posts/2023-07-03-diabetes/diabetes1.html",
    "href": "posts/2023-07-03-diabetes/diabetes1.html",
    "title": "Laura's Blog",
    "section": "",
    "text": "import numpy as np  # library used for working with arrays\nimport pandas as pd # library used for data manipulation and analysis\n\n\nimport seaborn as sns # library for visualization\nimport matplotlib.pyplot as plt # library for visualization\n%matplotlib inline\n\n\n# to suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport statsmodels.api as sm # library for logistic regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n\n#read csv dataset\n\npima = pd.read_csv(\"diabetes.csv\") # load and reads the csv file\npima\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n763\n10\n101\n76\n48\n180\n32.9\n0.171\n63\n0\n\n\n764\n2\n122\n70\n27\n0\n36.8\n0.340\n27\n0\n\n\n765\n5\n121\n72\n23\n112\n26.2\n0.245\n30\n0\n\n\n766\n1\n126\n60\n0\n0\n30.1\n0.349\n47\n1\n\n\n767\n1\n93\n70\n31\n0\n30.4\n0.315\n23\n0\n\n\n\n\n768 rows × 9 columns\n\n\n\n\n# Logistic Regression\n# x_train, x_test, y_train, y_test = train_test_split(pima.iloc[:,0:8], pima.iloc[:,8], test_size=0.2, random_state=42)\nx_train, y_train = pima.iloc[:,0:8], pima.iloc[:,8]\nx_train = sm.add_constant(x_train)\nmodel = sm.GLM(y_train, x_train, family=sm.families.Binomial())\nresults = model.fit()\nprint(results.summary())\npima.iloc[:,8].mean()\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                Outcome   No. Observations:                  768\nModel:                            GLM   Df Residuals:                      759\nModel Family:                Binomial   Df Model:                            8\nLink Function:                  Logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -361.72\nDate:                Mon, 03 Jul 2023   Deviance:                       723.45\nTime:                        16:12:23   Pearson chi2:                     836.\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.2964\nCovariance Type:            nonrobust                                         \n============================================================================================\n                               coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------------\nconst                       -8.4047      0.717    -11.728      0.000      -9.809      -7.000\nPregnancies                  0.1232      0.032      3.840      0.000       0.060       0.186\nGlucose                      0.0352      0.004      9.481      0.000       0.028       0.042\nBloodPressure               -0.0133      0.005     -2.540      0.011      -0.024      -0.003\nSkinThickness                0.0006      0.007      0.090      0.929      -0.013       0.014\nInsulin                     -0.0012      0.001     -1.322      0.186      -0.003       0.001\nBMI                          0.0897      0.015      5.945      0.000       0.060       0.119\nDiabetesPedigreeFunction     0.9452      0.299      3.160      0.002       0.359       1.531\nAge                          0.0149      0.009      1.593      0.111      -0.003       0.033\n============================================================================================\n\n\n0.3489583333333333\n\n\n\n# Testing Logistic Regression\npredictions = results.predict(x_train)\n\n\n\n\narray([[445,  55],\n       [112, 156]])\n\n\n\nbinaryPreds = []\nfor pred in predictions:\n    if pred &gt;= 0.9:\n        binaryPreds.append(1)\n    else:\n        binaryPreds.append(0)\n\narray = []\nfor i in range(len(y_train)):\n    array.append((y_train.iloc[i], binaryPreds[i]))\n\nincorrect = 0\nfor i in array:\n    if i[0]!=i[1]:\n        incorrect += 1\nprint(1-(incorrect/len(array)))\n\ncm = confusion_matrix(y_train, binaryPreds)\nprint(cm)\n\nprint((cm[0][0]+cm[1][1])/cm.sum())\n\n0.67578125\n[[496   4]\n [245  23]]\n0.67578125\n\n\n\n# finds the number of columns in the dataset\ntotal_cols=len(pima.axes[1])\nprint(\"Number of Columns: \"+str(total_cols))\n\nNumber of Columns: 9\n\n\n\npima.head(10)\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n5\n5\n116\n74\n0\n0\n25.6\n0.201\n30\n0\n\n\n6\n3\n78\n50\n32\n88\n31.0\n0.248\n26\n1\n\n\n7\n10\n115\n0\n0\n0\n35.3\n0.134\n29\n0\n\n\n8\n2\n197\n70\n45\n543\n30.5\n0.158\n53\n1\n\n\n9\n8\n125\n96\n0\n0\n0.0\n0.232\n54\n1\n\n\n\n\n\n\n\n\n# finds the number of rows in the dataset\ntotal_rows = len(pima.axes[0])\nprint(\"Number of Rows: \"+str(total_rows))\n\nNumber of Rows: 768\n\n\n\nprint('The dimension of the DataFrame is: ', pima.ndim)\n\nThe dimension of the DataFrame is:  2\n\n\n\npima.size\n\n6912\n\n\n\n#The info() function is used to print a concise summary of a DataFrame.\n#This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.\n\npima.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n\n\n\n# checking for missing values (null)\n#functions that return a boolean value indicating whether the passed in argument value is in fact missing data.\n# this is an example of chaining methods\n\npima.isnull().values.any()\n\nFalse\n\n\n\n#it can also output if there is any missing values each of the columns\n\npima.isnull().any()\n\nPregnancies                 False\nGlucose                     False\nBloodPressure               False\nSkinThickness               False\nInsulin                     False\nBMI                         False\nDiabetesPedigreeFunction    False\nAge                         False\nOutcome                     False\ndtype: bool\n\n\n\n#excludes the outcome column \npima.iloc[:,0:8].describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n\n\n\n\n\n\n\n\nsns.displot(pima['BloodPressure'], kind='kde') \nplt.show() \n\n\n\n\n\n# What is the BMI of the person having the highest glucose?\npima[pima['Glucose']==pima['Glucose'].max()]['BMI']\n\n661    42.9\nName: BMI, dtype: float64\n\n\n\n# mean \nm1 = pima['BMI'].mean() \nprint(m1) \n\n# median \nm2 = pima['BMI'].median() \nprint(m2)\n\n# mode  \nm3 = pima['BMI'].mode()[0] \nprint(m3)\n\nNameError: name 'df' is not defined\n\n\n\n# How many women's Glucose levels are above the mean level of Glucose \n# mean() method finds the mean of all numerical values in a series or column.\nv1 = pima[pima['Glucose']&gt;pima['Glucose'].mean()].shape[0]\nprint(v1)\n\n# count the number of women that have their 'BloodPressure' equal to the median of 'BloodPressure' \nv2 = pima[pima['BloodPressure']==pima['BloodPressure'].median()].shape[0]\nprint(v2)\n\n# and their 'BMI' less than the median of 'BMI'\nv3 = pima[pima['BMI']&lt;pima['BMI'].median()].shape[0]\nprint(v3)\n\n349\n44\n373\n\n\n\npima1 = pima[(pima['BloodPressure']==pima['BloodPressure'].median()) & (pima['BMI']&lt;pima['BMI'].median())]\nnumber_of_women=len(pima1.axes[0])\nprint(\"Number of women:\" +str(number_of_women))\n\nNumber of women:22\n\n\n\n# Getting a pairwise distribution between Glucose, Skin thickness and Diabetes pedigree function.\nsns.pairplot(data=pima,vars=['Glucose', 'SkinThickness', 'DiabetesPedigreeFunction'], hue = 'Outcome')\nplt.show()\n\n\n\n\n\n# Studying the correlation between glucose and insulin using a Scatter Plot.\nsns.scatterplot(x='Glucose',y='Insulin',data=pima, hue = 'Outcome')\nplt.show()\n\n\n\n\n\n# The scatter plot above implies that mostly the increase in glucose does relatively little change in insulin levels \n# It also shows that in some the increase in glucose increases in insulin. \n# This could probably be outliers.\n\n# Let us explore the possibility of outliers using the Box Plot.\n# Boxplot is a way to visualize the five-number summary of the variable. \n# Boxplot gives information about the outliers in the data.\n\n\nplt.boxplot(pima['Age'])\n\nplt.title('Boxplot of Age')\nplt.ylabel('Age')\nplt.show()\n# The box plot shows the presence of outliers above the horizontal line.\n\n\n\n\n\n# Understanding the number of women in different age groups with diabetes.\nplt.hist(pima[pima['Outcome']==1]['Age'], bins = 5)\nplt.title('Distribution of Age for Women who has Diabetes')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n\n# Of all the women with diabetes most are from the age between 22 to 30.\n# The frequency of women with diabetes decreases as age increases.\n\n\n\n\n\n# understanding the number of women in different age groups without diabetes.\n\nplt.hist(pima[pima['Outcome']==0]['Age'], bins = 5)\nplt.title('Distribution of Age for Women who do not have Diabetes')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n\n# The highest number of Women without diabetes range between ages 22 to 33.\n# Women between the age of 22 to 35 are at the highest risk of diabetes \n# and also the is the highest number of those without diabetes.\n\n\n\n\n\n# The IQR or Inter Quartile Range is a statistical measure for the variability in a given data.\n# It is a methodology that is generally used to filter outliers in a dataset\n\nQ1 = pima.quantile(0.25)\nQ3 = pima.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)\n\nPregnancies                   5.0000\nGlucose                      41.2500\nBloodPressure                18.0000\nSkinThickness                32.0000\nInsulin                     127.2500\nBMI                           9.3000\nDiabetesPedigreeFunction      0.3825\nAge                          17.0000\nOutcome                       1.0000\ndtype: float64\n\n\n\n# Correlation is a statistic that measures the degree to which two variables move with each other.\ncorr_matrix = pima.iloc[:,0:8].corr()\ncorr_matrix\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\n\n\n\n\nPregnancies\n1.000000\n0.129459\n0.141282\n-0.081672\n-0.073535\n0.017683\n-0.033523\n0.544341\n\n\nGlucose\n0.129459\n1.000000\n0.152590\n0.057328\n0.331357\n0.221071\n0.137337\n0.263514\n\n\nBloodPressure\n0.141282\n0.152590\n1.000000\n0.207371\n0.088933\n0.281805\n0.041265\n0.239528\n\n\nSkinThickness\n-0.081672\n0.057328\n0.207371\n1.000000\n0.436783\n0.392573\n0.183928\n-0.113970\n\n\nInsulin\n-0.073535\n0.331357\n0.088933\n0.436783\n1.000000\n0.197859\n0.185071\n-0.042163\n\n\nBMI\n0.017683\n0.221071\n0.281805\n0.392573\n0.197859\n1.000000\n0.140647\n0.036242\n\n\nDiabetesPedigreeFunction\n-0.033523\n0.137337\n0.041265\n0.183928\n0.185071\n0.140647\n1.000000\n0.033561\n\n\nAge\n0.544341\n0.263514\n0.239528\n-0.113970\n-0.042163\n0.036242\n0.033561\n1.000000\n\n\n\n\n\n\n\n\n# 'annot=True' returns the correlation values\nplt.figure(figsize=(8,8))\nsns.heatmap(corr_matrix, annot = True)\n\n# display the plot\nplt.show()\n\n\n\n\n\n# The closer the correlation is to 1, the more positively correlated they are; \n# that is as one increases so does the other and the closer to 1 the stronger this relationship is.\n# A correlation closer to -1 is similar,\n# but instead of both increasing one variable will decrease as the other increases."
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html",
    "title": "Import Libraries",
    "section": "",
    "text": "import tensorflow as tf\n# Make sure the GPU is enabled \nassert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -&gt; Change runtime type -&gt; GPU'\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nimport tensorflow_hub as hub # for interacting with saved models and tensorflow hub\nimport joblib\nimport gzip # for manipulating compressed files\nimport kipoiseq # for manipulating fasta files\nfrom kipoiseq import Interval # same as above, really\nimport pyfaidx # to index our reference genome file\nimport pandas as pd # for manipulating dataframes\nimport numpy as np # for numerical computations\nimport matplotlib.pyplot as plt # for plotting\nimport matplotlib as mpl # for plotting\nimport seaborn as sns # for plotting\nimport pickle # for saving large objects\nimport os, sys # functions for interacting with the operating system\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n2023-07-17 19:17:14.481091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\nNum GPUs Available:  4"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#define-paths",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#define-paths",
    "title": "Import Libraries",
    "section": "Define Paths",
    "text": "Define Paths\n\ntransform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\nmodel_path = 'https://tfhub.dev/deepmind/enformer/1'\nfasta_file = '/grand/TFXcan/imlab/users/lvairus/hackenf/data/genome.fa'\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#define-functions",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#define-functions",
    "title": "Import Libraries",
    "section": "Define Functions",
    "text": "Define Functions\n\n# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\nSEQUENCE_LENGTH = 393216\n\nclass Enformer:\n\n  def __init__(self, tfhub_url):\n    self._model = hub.load(tfhub_url).model\n\n  def predict_on_batch(self, inputs):\n    predictions = self._model.predict_on_batch(inputs)\n    return {k: v.numpy() for k, v in predictions.items()}\n\n  @tf.function\n  def contribution_input_grad(self, input_sequence,\n                              target_mask, output_head='human'):\n    input_sequence = input_sequence[tf.newaxis]\n\n    target_mask_mass = tf.reduce_sum(target_mask)\n    with tf.GradientTape() as tape:\n      tape.watch(input_sequence)\n      prediction = tf.reduce_sum(\n          target_mask[tf.newaxis] *\n          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n\n    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n    input_grad = tf.squeeze(input_grad, axis=0)\n    return tf.reduce_sum(input_grad, axis=-1)\n\n\nclass EnformerScoreVariantsRaw:\n\n  def __init__(self, tfhub_url, organism='human'):\n    self._model = Enformer(tfhub_url)\n    self._organism = organism\n\n  def predict_on_batch(self, inputs):\n    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n\n    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n\n\nclass EnformerScoreVariantsNormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human'):\n    assert organism == 'human', 'Transforms only compatible with organism=human'\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      transform_pipeline = joblib.load(f)\n    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)\n\n\nclass EnformerScoreVariantsPCANormalized:\n\n  def __init__(self, tfhub_url, transform_pkl_path,\n               organism='human', num_top_features=500):\n    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n      self._transform = joblib.load(f)\n    self._num_top_features = num_top_features\n\n  def predict_on_batch(self, inputs):\n    scores = self._model.predict_on_batch(inputs)\n    return self._transform.transform(scores)[:, :self._num_top_features]\n\n\n# TODO(avsec): Add feature description: Either PCX, or full names.\n\n\n# @title `variant_centered_sequences`\n\nclass FastaStringExtractor:\n\n    def __init__(self, fasta_file):\n        self.fasta = pyfaidx.Fasta(fasta_file)\n        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n    #import pd.Interval as Interval\n    def extract(self, interval: Interval, **kwargs) -&gt; str:\n        # Truncate interval if it extends beyond the chromosome lengths.\n        chromosome_length = self._chromosome_sizes[interval.chrom]\n        trimmed_interval = Interval(interval.chrom,\n                                    max(interval.start, 0),\n                                    min(interval.end, chromosome_length),\n                                    )\n        # pyfaidx wants a 1-based interval\n        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n                                          trimmed_interval.start + 1,\n                                          trimmed_interval.stop).seq).upper()\n        # Fill truncated values with N's.\n        pad_upstream = 'N' * max(-interval.start, 0)\n        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n        return pad_upstream + sequence + pad_downstream\n\n    def close(self):\n        return self.fasta.close()\n\n\ndef one_hot_encode(sequence):\n  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n\n\n\n# @title `plot_tracks`\n\ndef plot_tracks(tracks, interval, height=1.5):\n  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n  for ax, (title, y) in zip(axes, tracks.items()):\n    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n    ax.set_title(title)\n    sns.despine(top=True, right=True, bottom=True)\n  ax.set_xlabel(str(interval))\n  plt.tight_layout()\n\n\nimport Bio\n\nfrom Bio.Seq import Seq\ndef create_rev_complement(dna_string):\n    return(str(Seq(dna_string).reverse_complement()))\n\n\ndef prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n\n  '''\n\n  Parameters:\n          predicitions (A numpy array): All predictions from the track\n          gene (a gene name, character): a gene\n          tss_df: a list of dataframe of genes and their transcription start sites\n  Returns:\n          A dictionary of cage experiment predictions and a list of transcription start sites\n\n  '''\n\n  output = dict()\n  for tdf in tss_df:\n    if gene not in tdf.genes.values:\n      continue\n    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n    gene_tss_list = list(set(gene_tss_list))\n  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n  output['gene_TSS'] = gene_tss_list # a list\n\n\n  return(output) # a dictionary\n\ndef quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n\n  '''\n  Parameters:\n          low_range (int): The lower interval\n          TSS (list of integers): A list of TSS for a gene\n          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n  Returns:\n          A dictionary of gene expression predictions for each TSS for a gene\n    '''\n  tss_predictions = dict()\n  for tss in TSS:\n    bin_start = low_range + ((768 + 320) * 128)\n    count = -1\n    while bin_start &lt; tss:\n      bin_start = bin_start + 128\n      count += 1\n    if count &gt;= len(cage_predictions)-1:\n      continue\n    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n    tss_predictions[tss] = cage_preds\n\n  return(tss_predictions)\n\ndef collect_intervals(chromosomes = [\"22\"], gene_list=None):\n\n  '''\n    Parameters :\n      chromosomes : a list of chromosome numbers; each element should be a string format\n      gene_list : a list of genes; the genes should be located on those chromosomes\n\n    Returns :\n      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n  '''\n\n  gene_intervals = {} # Collect intervals for our genes of interest\n\n  for chrom in chromosomes:\n    with open(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n      for line in chrom_genes:\n        split_line = line.strip().split(\"\\t\")\n        gene_intervals[split_line[2]] = [\n                                          split_line[0],\n                                          int(split_line[3]),\n                                          int(split_line[4])\n                                        ]\n\n  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n    return(use_genes)\n  elif isinstance(gene_list, type(None)):\n    return(gene_intervals)\n\n\ndef run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n  '''\n  Parameters :\n    gene_intervals : the results from calling `collect_intervals`\n    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n\n  Returns :\n    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n  '''\n\n  gene_output = dict()\n  gene_predictions = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2]) # creates an interval to select the right sequences\n    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n    try:\n      cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n    except:\n      continue\n    individual_results = dict()\n    individual_prediction = dict()\n\n    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n      use_individuals = individuals_list\n    elif isinstance(individuals_list, type(None)):\n      use_individuals = cur_gene_vars.columns[4:]\n\n    for individual in use_individuals:\n      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n      # two haplotypes per individual\n      haplo_1 = list(target_fa[:])\n      haplo_2 = list(target_fa[:])\n\n      ref_mismatch_count = 0\n      for i,row in cur_gene_vars.iterrows():\n\n        geno = row[individual].split(\"|\")\n        if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n          continue\n        if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n          continue\n        if geno[0] == \"1\":\n          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n        if geno[1] == \"1\":\n          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n      # predict on the individual's two haplotypes\n      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n\n      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in\n      individual_prediction[individual] = temp_predictions\n\n      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n      temp_list = list()\n\n      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n\n      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n\n      temp_list.append(tss_predictions_1)\n      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n\n      individual_results[individual] = temp_list # save for the individual\n\n    gene_output[gene] = individual_results\n    gene_predictions[gene] = individual_prediction\n\n  return([gene_output, gene_predictions])\n\n\ndef collect_target_intervals(gene_intervals):\n\n  '''\n  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n  '''\n\n  target_intervals_dict = dict()\n\n  for gene in gene_intervals.keys():\n    gene_interval = gene_intervals[gene]\n    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\n    target_intervals_dict[gene] = target_interval\n\n  return(target_intervals_dict)\n\ndef prepare_for_plot_tracks(gene, individual, all_predictions, chromosome=['22']):\n\n  '''\n  This returns a dictionary of gene tracks and gene intervals, prepared for the function plot_tracks.\n\n  Parameters:\n    - gene\n    - individual\n    - all_predictions\n  '''\n\n  haplo_predictions = all_predictions[gene][individual]\n  gene_tracks = {gene + ' | ' + individual + ' | haplotype 1': np.log10(1 + haplo_predictions[0]),\n                gene + ' | ' + individual + ' | haplotype 2': np.log10(1 + haplo_predictions[1])}\n\n  gene_intervals = collect_intervals(chromosomes=chromosome, gene_list=[gene])\n  gene_intervals = collect_target_intervals(gene_intervals)\n\n  output = dict()\n  output['gene_tracks'] = gene_tracks\n  output['gene_intervals'] = gene_intervals[gene]\n\n  return(output)\n\ndef check_individuals(path_to_bed_file, list_of_individuals):\n\n  '''\n  Checks if an individual is missing in bed variation files.\n  These individuals should be removed prior to training\n  '''\n\n  myfile = open(path_to_bed_file, 'r')\n  myline = myfile.readline()\n  bed_names = myline.split('\\t')[4:]\n  myfile.close()\n\n  if set(list_of_individuals).issubset(set(bed_names)) == False:\n    missing = list(set(list_of_individuals).difference(bed_names))\n    print('This (or these) individual(s) is/are not present: {}'.format(missing))\n  else:\n    missing = []\n    print('All individuals are present in the bed file.')\n\n  return(missing)\n\n\ndef geno_to_seq(gene, individual):\n      # two haplotypes per individual\n  haplo_1 = list(target_fa[:])\n  haplo_2 = list(target_fa[:])\n\n  ref_mismatch_count = 0\n  for i,row in cur_gene_vars.iterrows():\n\n    geno = row[individual].split(\"|\")\n    if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n      continue\n    if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n      continue\n    if geno[0] == \"1\":\n      haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n    if geno[1] == \"1\":\n      haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n  return haplo_1, haplo_2\n\n      # predict on the individual's two haplotypes\n    \n\n\ndef run_predictions2(gene, chrom, indiv):\n    '''\n    Parameters :\n       gene: gene to run (string)\n       chrom: chrom gene is on (string)\n       indiv: individual to run (string)\n       chrNtss: variable of tss for chr\n    Returns :\n        A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n    '''\n    \n    gene_intervals = collect_intervals(chromosomes=[chrom], gene_list=[gene])\n    individuals_list = [indiv]\n\n    for gene in gene_intervals.keys():\n        global fasta_extractor\n        gene_interval = gene_intervals[gene]\n        target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                            gene_interval[1],\n                                            gene_interval[2]) # creates an interval to select the right sequences\n        target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n        window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n        try:\n            cur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n        except:\n            continue\n        individual_prediction = dict()\n\n        if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n            use_individuals = individuals_list\n        elif isinstance(individuals_list, type(None)):\n            use_individuals = cur_gene_vars.columns[4:]\n\n        for individual in use_individuals:\n            # two haplotypes per individual\n            haplo_1 = list(target_fa[:])\n            haplo_2 = list(target_fa[:])\n\n            ref_mismatch_count = 0\n            for i,row in cur_gene_vars.iterrows():\n\n                geno = row[individual].split(\"|\")\n                if (row[\"POS\"]-window_coords.start-1) &gt;= len(haplo_2):\n                    continue\n                if (row[\"POS\"]-window_coords.start-1) &lt; 0:\n                    continue\n                if geno[0] == \"1\":\n                    haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n                if geno[1] == \"1\":\n                    haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n\n            # predict on the individual's two haplotypes\n            global model\n\n            ohe_haplo_1 = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\n            ohe_haplo_2 = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\n\n            ohe_haplo_avg = np.add(ohe_haplo_1, ohe_haplo_2) / 2\n                                         \n            prediction_1 = model.predict_on_batch(ohe_haplo_1)['human'][0]\n            prediction_2 = model.predict_on_batch(ohe_haplo_2)['human'][0]\n            prediction_avg = model.predict_on_batch(ohe_haplo_avg)['human'][0]\n            \n            post_avg = (prediction_1 + prediction_2) / 2\n            pre_avg = prediction_avg\n\n    return([pre_avg, post_avg])\n\n\ndef get_summary(arr):\n    stats = {\n        \"mean\": np.mean(arr),\n        \"median\": np.median(arr),\n        \"std_dev\": np.std(arr),\n        \"minimum\": np.min(arr),\n        \"maximum\": np.max(arr),\n        \"total_sum\": np.sum(arr),\n        \"q1\": np.percentile(arr, 25),\n        \"q2\": np.percentile(arr, 50),\n        \"q3\": np.percentile(arr, 75),\n        \"iqr\": np.percentile(arr, 75) - np.percentile(arr, 25)\n    }\n    return stats\n\ndef make_hist(arr, bin_num):\n    plt.hist(arr, bins=bin_num)\n\n    # Add labels and title\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n\n    # Display the plot\n    plt.show()\n\n\ndef get_relmax(arr):\n    col_max = np.max(arr, axis=0)\n    relmax = arr / col_max\n    return relmax\n\n\ndef get_relmed(arr):\n    col_med = np.median(arr, axis=0)\n    relmed = arr / col_med\n    return relmed\n\n\nclass My_class:\n    def __init__(self, gene, chrom, indiv):\n        # save starting variables\n        self.gene = gene\n        self.chrom = chrom\n        self.indiv = indiv\n        # run predictions\n        self.pre_avg, self.post_avg = run_predictions2(gene, chrom, indiv)\n        # get difference matrices\n        self.diffmat = self.pre_avg - self.post_avg\n        self.abs_diffmat = abs(self.diffmat) # check this\n        self.rel_diffmat = self.abs_diffmat / (abs(self.pre_avg) + abs(self.post_avg) + 1**-16) * 100\n        self.relmax_diffmat = get_relmax(self.abs_diffmat)\n        self.relmed_diffmat = get_relmed(self.abs_diffmat)\n    \n    def get_diffmats(self):\n        return [self.abs_diffmat, self.rel_diffmat, self.relmax_diffmat, self.relmed_diffmat]\n\n    def get_summary(self, arr):\n        stats = {\n        \"mean\": np.mean(arr),\n        \"median\": np.median(arr),\n        \"std_dev\": np.std(arr),\n        \"minimum\": np.min(arr),\n        \"maximum\": np.max(arr),\n        \"total_sum\": np.sum(arr),\n        \"q1\": np.percentile(arr, 25),\n        \"q2\": np.percentile(arr, 50),\n        \"q3\": np.percentile(arr, 75),\n        \"iqr\": np.percentile(arr, 75) - np.percentile(arr, 25)\n        }\n        return stats\n    \n    def get_outliers(self, arr, tol):\n        outliers = arr[arr&gt;tol]\n        return outliers\n    \n    def make_hist(self, arr, bin_num):\n        plt.hist(arr, bins=bin_num)\n        # Add labels and title\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        # Display the plot\n        plt.show()\n        return None\n    \n    def get_outlier_inds(self, arr, tol):\n        # get inds of outliers list of [row,col] lists\n        outlier_inds = np.where(arr &gt; tol)\n        outlier_inds_arr = np.array(list(zip(outlier_inds[0], outlier_inds[1])))\n\n        # define outlier row inds\n        row_inds = outlier_inds[0]      # all outlier row inds\n        \n        #define outlier col inds\n        col_inds = outlier_inds[1]      # all outlier col inds\n\n        print(\"to get list of unique inds: set(inds_arr) \")\n        print(\"get count of inds: Counter(inds_arr)\")\n\n        return (outlier_inds_arr, row_inds, col_inds)\n    \n    def make_table(self, arr, tol):\n        # input difference arr and tolerance\n        # get outliers with tolerance\n        outs = arr[arr&gt;tol]\n        out_inds = np.where(arr &gt; tol)\n        col_inds = out_inds[1]   \n        row_inds = out_inds[0]\n        # labels for track names from col names\n        global track_names\n        # row_inds \n        # outlier values \n        data = {\n            'track': [track_names[i] for i in col_inds],\n            'bin': row_inds,\n            'diff': outs\n        }\n        df = pd.DataFrame(data)\n        return df\n    \n    def plot_tol_numouts(self, arr, mintol, maxtol, steps):\n        x = np.linspace(maxtol, mintol, steps)\n        y = []\n        for tol in x:\n            y.append(len(self.get_outliers(arr, tol)))\n        # Create scatter plot\n        plt.scatter(x, y)\n        # Add labels and title\n        plt.xlabel('Tolerance')\n        plt.ylabel('Amount of Outliers')\n        # Display the plot\n        plt.show()\n        return None\n\n\n\ndef print_comparisons(pre_average, post_average, tolerance):\n\n    dict = {}\n    diffmat = pre_average - post_average\n\n    # abs diff matrix\n    abs = {}\n    print(\"Absolute Difference:\")\n\n    # make abs diff mat\n    abs_mat = np.sqrt(np.square(diffmat))\n    abs['mat'] = abs_mat\n\n    # get summary of mat\n    abs_mat_summary = get_summary(abs_mat)\n    abs['mat_summary'] = abs_mat_summary\n    print(f\"Summary Statistics: \\n{abs_mat_summary}\")\n\n    # get outlier differences\n    outlier_abs = abs_mat[abs_mat&gt;tolerance]\n    abs[\"outliers\"] = outlier_abs\n    print(f'num outliers: \\n{len(outlier_abs)}')\n\n    # summary of outliers\n    outlier_abs_summary = get_summary(outlier_abs)\n    abs['outliers-summary'] = outlier_abs_summary\n    print(f'Summary of Outliers: \\n{outlier_abs_summary}')\n\n    # histogram of outliers \n    print(\"Histogram of Outliers for Absolute Difference\")\n    make_hist(outlier_abs, 20)\n\n    # get inds of outliers list of [row,col] lists\n    outlier_abs_inds = np.where(abs_mat &gt; tolerance)\n    outlier_abs_inds_arr = np.array(list(zip(outlier_abs_inds[0], outlier_abs_inds[1])))\n    abs['outlier-inds'] = outlier_abs_inds_arr\n    # define outlier row inds\n    row_inds = outlier_abs_inds[0]      # all outlier row inds\n    row_inds_uq = set(row_inds)         # unique outlier row inds\n    row_inds_count = Counter(row_inds)  # counter of outlier row inds\n    #define outlier col inds\n    col_inds = outlier_abs_inds[1]      # all outlier col inds\n    col_inds_uq = set(col_inds)         # unique outlier col inds\n    col_inds_count = Counter(col_inds)  # counter of outlier col inds\n\n    #hist of row outlier inds\n    print(f'num unique row outlier inds: {len(row_inds_uq)}')\n    make_hist(row_inds)\n\n    #hist of col outlier inds\n\n\n\n    # rel diff matrix\n    #rel_diff = (abs_diff) / ((pre_average + post_average) + 10**-16)\n\n\n    # rel max diff matrix\n\n\n    dict[\"abs\"] = abs\n\n    return dict"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#prepare-input-data",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#prepare-input-data",
    "title": "Import Libraries",
    "section": "Prepare input data",
    "text": "Prepare input data\nWe want to predict epigenome around HINT2 TSS on chromosome 9.\n\ntargets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\ndf_targets = pd.read_csv(targets_txt, sep='\\t')\n\n\ntrack_names = df_targets['description'].tolist()\ntrack_names\n\n['DNASE:cerebellum male adult (27 years) and male adult (35 years)',\n 'DNASE:frontal cortex male adult (27 years) and male adult (35 years)',\n 'DNASE:chorion',\n 'DNASE:Ishikawa treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'DNASE:GM03348',\n 'DNASE:GM03348 genetically modified using transduction treated with 3 ug/mL doxycycline for 10 days',\n 'DNASE:AG08395',\n 'DNASE:AG08396',\n 'DNASE:AG20443',\n 'DNASE:frontal cortex female adult (67 years) and female adult (80 years)',\n 'DNASE:H54',\n 'DNASE:GM10248',\n 'DNASE:GM12878',\n 'DNASE:GM12891',\n 'DNASE:GM12892',\n 'DNASE:GM18507',\n 'DNASE:GM19238',\n 'DNASE:GM19239',\n 'DNASE:GM19240',\n 'DNASE:H1-hESC',\n 'DNASE:H7-hESC',\n 'DNASE:H9',\n 'DNASE:heart male adult (27 years) and male adult (35 years)',\n 'DNASE:HEK293T',\n 'DNASE:HeLa-S3 treated with interferon alpha for 4 hours',\n 'DNASE:HeLa-S3',\n 'DNASE:hepatocyte',\n 'DNASE:HepG2',\n 'DNASE:HTR-8/SVneo',\n 'DNASE:endothelial cell of umbilical vein newborn',\n 'DNASE:CWRU1 male',\n 'DNASE:iPS-NIHi11 male adult (71 year) originated from AG20443',\n 'DNASE:iPS-NIHi7 female adult (85 years) originated from AG08395',\n 'DNASE:K562 treated with 1 uM vorinostat for 72 hours',\n 'DNASE:K562 G2 phase',\n 'DNASE:K562 G1 phase',\n 'DNASE:LNCaP clone FGC',\n 'DNASE:LNCaP clone FGC treated with 1 nM 17B-hydroxy-17-methylestra-4,9,11-trien-3-one for 12 hours',\n 'DNASE:MCF-7 originated from MCF-7',\n 'DNASE:medulloblastoma',\n 'DNASE:epidermal melanocyte',\n 'DNASE:CD14-positive monocyte female',\n 'DNASE:keratinocyte female',\n 'DNASE:osteoblast',\n 'DNASE:psoas muscle male adult (27 years) and male adult (35 years)',\n 'DNASE:T47D treated with 10 nM 17B-estradiol for 30 minutes',\n 'DNASE:urothelium cell line',\n 'DNASE:A549',\n 'DNASE:AG04449',\n 'DNASE:AG04450',\n 'DNASE:AG09309',\n 'DNASE:AG09319',\n 'DNASE:AG10803',\n 'DNASE:fibroblast of the aortic adventitia female',\n 'DNASE:BE2C',\n 'DNASE:BJ',\n 'DNASE:HS-27A',\n 'DNASE:HS-5',\n 'DNASE:stromal cell of bone marrow male',\n 'DNASE:Caco-2',\n 'DNASE:B cell female adult (43 years)',\n 'DNASE:hematopoietic multipotent progenitor cell',\n 'DNASE:naive thymus-derived CD4-positive, alpha-beta T cell male adult (26 years)',\n 'DNASE:CMK',\n 'DNASE:GM04503',\n 'DNASE:GM04504',\n 'DNASE:GM06990',\n 'DNASE:GM12864',\n 'DNASE:GM12865',\n 'DNASE:GM12878',\n 'DNASE:H1-hESC',\n 'DNASE:cardiac mesoderm',\n 'DNASE:cardiac mesoderm',\n 'DNASE:cardiac mesoderm',\n 'DNASE:cardiac mesoderm',\n 'DNASE:H7-hESC',\n 'DNASE:astrocyte of the hippocampus',\n 'DNASE:astrocyte of the spinal cord',\n 'DNASE:astrocyte of the cerebellum',\n 'DNASE:amniotic epithelial cell',\n 'DNASE:brain microvascular endothelial cell',\n 'DNASE:brain pericyte',\n 'DNASE:smooth muscle cell of the brain vasculature female',\n 'DNASE:cardiac fibroblast',\n 'DNASE:cardiac fibroblast female',\n 'DNASE:cardiac muscle cell',\n 'DNASE:fibroblast of the conjunctiva',\n 'DNASE:choroid plexus epithelial cell',\n 'DNASE:HCT116',\n 'DNASE:epithelial cell of esophagus',\n 'DNASE:HeLa-S3 G1b phase',\n 'DNASE:HepG2',\n 'DNASE:foreskin fibroblast male newborn',\n 'DNASE:HFF-Myc originated from foreskin fibroblast',\n 'DNASE:fibroblast of gingiva',\n 'DNASE:iris pigment epithelial cell',\n 'DNASE:HL-60',\n 'DNASE:mammary epithelial cell female',\n 'DNASE:fibroblast of mammary gland female',\n 'DNASE:dermis blood vessel endothelial cell female adult',\n 'DNASE:dermis blood vessel endothelial cell female adult',\n 'DNASE:dermis blood vessel endothelial cell male newborn',\n 'DNASE:dermis microvascular lymphatic vessel endothelial cell female',\n 'DNASE:dermis microvascular lymphatic vessel endothelial cell male',\n 'DNASE:dermis blood vessel endothelial cell male newborn',\n 'DNASE:lung microvascular endothelial cell female',\n 'DNASE:lung microvascular endothelial cell female',\n 'DNASE:non-pigmented ciliary epithelial cell',\n 'DNASE:pulmonary artery endothelial cell female',\n 'DNASE:fibroblast of pulmonary artery',\n 'DNASE:fibroblast of peridontal ligament male',\n 'DNASE:fibroblast of lung',\n 'DNASE:renal cortical epithelial cell',\n 'DNASE:kidney epithelial cell',\n 'DNASE:glomerular endothelial cell',\n 'DNASE:retinal pigment epithelial cell',\n 'DNASE:skeletal muscle myoblast',\n 'DNASE:myotube originated from skeletal muscle myoblast',\n 'DNASE:endothelial cell of umbilical vein newborn',\n 'DNASE:fibroblast of villous mesenchyme',\n 'DNASE:Jurkat clone E61',\n 'DNASE:K562',\n 'DNASE:K562',\n 'DNASE:K562',\n 'DNASE:myocyte originated from LHCN-M2',\n 'DNASE:LHCN-M2',\n 'DNASE:LNCaP clone FGC',\n 'DNASE:M059J',\n 'DNASE:MCF-7',\n 'DNASE:MCF-7 treated with 100 nM estradiol for 1 hour',\n 'DNASE:MCF-7',\n 'DNASE:CD14-positive monocyte female',\n 'DNASE:NB4',\n 'DNASE:astrocyte',\n 'DNASE:bronchial epithelial cell female treated with retinoic acid',\n 'DNASE:fibroblast of dermis female adult',\n 'DNASE:foreskin fibroblast male newborn',\n 'DNASE:keratinocyte female',\n 'DNASE:fibroblast of lung male adult (45 years)',\n 'DNASE:NT2/D1',\n 'DNASE:Panc1',\n 'DNASE:epithelial cell of prostate',\n 'DNASE:RPMI-7951',\n 'DNASE:epithelial cell of proximal tubule',\n 'DNASE:bronchial epithelial cell',\n 'DNASE:SK-N-MC',\n 'DNASE:SK-N-SH treated with 6 uM all-trans-retinoic acid for 48 hours',\n 'DNASE:skeletal muscle cell',\n 'DNASE:T47D',\n 'DNASE:T-helper 1 cell',\n 'DNASE:T-helper 1 cell female adult (26 years)',\n 'DNASE:T-helper 1 cell male adult (33 years)',\n 'DNASE:T-helper 17 cell',\n 'DNASE:T-helper 2 cell',\n 'DNASE:T-helper 2 cell female adult (26 years)',\n 'DNASE:T-helper 2 cell male adult (33 years)',\n 'DNASE:regulatory T cell female adult (35 years)',\n 'DNASE:regulatory T cell male adult (28 years)',\n 'DNASE:WERI-Rb-1',\n 'DNASE:WI38 genetically modified using stable transfection originated from WI38 treated with 20 nM afimoxifene for 72 hours',\n 'DNASE:WI38 genetically modified using stable transfection originated from WI38',\n 'DNASE:HT1080',\n 'DNASE:SK-MEL-5',\n 'DNASE:SJCRH30',\n 'DNASE:NCI-H460',\n 'DNASE:SK-N-DZ treated with dimethyl sulfoxide for 72 hours',\n 'DNASE:GM23338 male adult (53 years) originated from GM23248',\n 'DNASE:lung embryo (112 days)',\n 'DNASE:SK-MEL-5',\n 'DNASE:muscle of back female embryo (113 days)',\n 'DNASE:iPS DF 4.7 male newborn',\n 'DNASE:right renal cortex interstitium male embryo (105 days)',\n 'DNASE:caudate nucleus male adult (78 years)',\n 'DNASE:left renal pelvis male embryo (105 days)',\n 'DNASE:H9 S1 phase genetically modified using stable transfection',\n 'DNASE:right kidney female embryo (87 days)',\n 'DNASE:Karpas-422',\n 'DNASE:CD8-positive, alpha-beta T cell male adult (21 year)',\n 'DNASE:renal cortex interstitium female embryo (96 days)',\n 'DNASE:brain female embryo (85 days)',\n 'DNASE:muscle of leg male embryo (97 days)',\n 'DNASE:muscle of back female embryo (105 days)',\n 'DNASE:placenta female embryo (113 days)',\n 'DNASE:foreskin keratinocyte male newborn',\n 'DNASE:right kidney female embryo (107 days)',\n 'DNASE:RCC 7860',\n 'DNASE:colon epithelial cell line',\n 'DNASE:left renal cortex interstitium male embryo (120 days)',\n 'DNASE:T-cell',\n 'DNASE:large intestine male embryo (113 days)',\n 'DNASE:PC-3',\n 'DNASE:muscle of leg male embryo (96 days)',\n 'DNASE:adrenal gland embryo (96 days)',\n 'DNASE:coronary artery female adult (53 years)',\n 'DNASE:stomach female embryo (105 days)',\n 'DNASE:muscle of arm female embryo (115 days)',\n 'DNASE:heart female embryo (91 day)',\n 'DNASE:kidney embryo (80 days)',\n 'DNASE:heart left ventricle female adult (53 years)',\n 'DNASE:muscle of back female embryo (98 days)',\n 'DNASE:lung male embryo (108 days)',\n 'DNASE:tibial artery female adult (53 years)',\n 'DNASE:adrenal gland male embryo (101 day)',\n 'DNASE:kidney female embryo (121 day)',\n 'DNASE:stomach female embryo (107 days)',\n 'DNASE:small intestine female embryo (110 days)',\n 'DNASE:MG63',\n 'DNASE:skin of body female embryo (82 days)',\n 'DNASE:left renal cortex interstitium male embryo (105 days)',\n 'DNASE:stomach male embryo (58 days) and male embryo (76 days)',\n 'DNASE:left kidney female embryo (59 days) and male embryo (91 day)',\n 'DNASE:hematopoietic multipotent progenitor cell',\n 'DNASE:kidney female embryo (120 days)',\n 'DNASE:muscle of back female embryo (115 days)',\n 'DNASE:hematopoietic multipotent progenitor cell male adult (25 years) treated with erythropoietin for 20 days, hydrocortisone succinate for 20 days, kit ligand for 20 days, interleukin-3 for 20 days',\n 'DNASE:small intestine female embryo (120 days)',\n 'DNASE:brain embryo (112 days)',\n 'DNASE:stomach female embryo (105 days)',\n 'DNASE:left kidney female embryo (98 days)',\n 'DNASE:trophoblast cell embryo (21 week)',\n 'DNASE:common myeloid progenitor, CD34-positive female adult (27 years)',\n 'DNASE:eye female embryo (76 days)',\n 'DNASE:renal cortex interstitium male embryo (108 days)',\n 'DNASE:placenta female embryo (108 days)',\n 'DNASE:stomach female adult (53 years)',\n 'DNASE:small intestine female embryo (107 days)',\n 'DNASE:large intestine female embryo (120 days)',\n 'DNASE:kidney glomerular epithelial cell male adult (43 years) and male adult (62 years)',\n 'DNASE:renal pelvis female embryo (96 days)',\n 'DNASE:lung female embryo (76 days)',\n 'DNASE:muscle of back male embryo (104 days)',\n 'DNASE:lung female embryo (85 days)',\n 'DNASE:spinal cord male embryo (105 days)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 4 days, kit ligand for 4 days, hydrocortisone succinate for 4 days, erythropoietin for 4 days',\n 'DNASE:HepG2',\n 'DNASE:foreskin fibroblast male newborn',\n 'DNASE:omental fat pad female adult (53 years)',\n 'DNASE:large intestine female embryo (110 days)',\n 'DNASE:heart female embryo (105 days)',\n 'DNASE:renal cortex interstitium male embryo (113 days)',\n 'DNASE:brain female embryo (96 days)',\n 'DNASE:thyroid gland male adult (37 years)',\n 'DNASE:liver embryo (59 days) and embryo (80 days)',\n 'DNASE:stomach male adult (54 years)',\n 'DNASE:thymus male embryo (127 days)',\n 'DNASE:upper lobe of left lung male adult (37 years)',\n 'DNASE:endodermal cell',\n 'DNASE:forelimb muscle female embryo (108 days)',\n 'DNASE:CD4-positive, alpha-beta T cell male adult (37 years)',\n 'DNASE:muscle of leg male embryo (101 day)',\n 'DNASE:gastrocnemius medialis male adult (37 years)',\n 'DNASE:gastrocnemius medialis male adult (54 years)',\n 'DNASE:stomach male embryo (91 day)',\n 'DNASE:muscle of back male embryo (101 day)',\n 'DNASE:heart female embryo (117 days)',\n 'DNASE:kidney tubule cell female adult (80 years) and male adult (62 years)',\n 'DNASE:fibroblast of skin of abdomen male embryo (97 days)',\n 'DNASE:pancreas male adult (34 years)',\n 'DNASE:trophoblast cell originated from H1-hESC',\n 'DNASE:left kidney male embryo (96 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:brain female embryo (142 days)',\n 'DNASE:small intestine male embryo (105 days)',\n 'DNASE:heart female embryo (110 days)',\n 'DNASE:common myeloid progenitor, CD34-positive female',\n 'DNASE:adrenal gland male adult (37 years)',\n 'DNASE:muscle of back female embryo (85 days)',\n 'DNASE:muscle of leg female embryo (85 days)',\n \"DNASE:Peyer's patch male adult (54 years)\",\n 'DNASE:amniotic stem cell',\n 'DNASE:stomach female embryo (98 days)',\n 'DNASE:large intestine female embryo (91 day)',\n 'DNASE:lung female embryo (120 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:SW480',\n 'DNASE:GM23248',\n 'DNASE:muscle of trunk female embryo (120 days)',\n 'DNASE:islet precursor cell',\n 'DNASE:medulla oblongata male adult (78 years) and male adult (84 years)',\n 'DNASE:right lung male embryo (115 days)',\n 'DNASE:body of pancreas male adult (54 years)',\n 'DNASE:mammary epithelial cell female adult (18 years)',\n 'DNASE:gastrocnemius medialis female adult (51 year)',\n 'DNASE:uterus female adult (53 years)',\n 'DNASE:ELR',\n 'DNASE:omental fat pad female adult (51 year)',\n 'DNASE:stomach male child (3 years)',\n 'DNASE:B cell male adult (37 years)',\n 'DNASE:foreskin fibroblast male newborn',\n 'DNASE:renal cortex interstitium male embryo (91 day)',\n 'DNASE:ACHN',\n 'DNASE:kidney tubule cell female adult (80 years) treated with 5 uM cisplatin',\n 'DNASE:left renal pelvis male embryo (105 days)',\n 'DNASE:iPS DF 6.9 male newborn',\n 'DNASE:kidney male embryo (87 days)',\n 'DNASE:right lung female embryo (91 day)',\n 'DNASE:NCI-H226',\n 'DNASE:right renal cortex interstitium male embryo (105 days)',\n 'DNASE:G401',\n 'DNASE:muscle of arm male embryo (113 days)',\n 'DNASE:common myeloid progenitor, CD34-positive male adult',\n 'DNASE:muscle of leg female embryo (113 days)',\n 'DNASE:arm bone male embryo (81 day)',\n 'DNASE:H9',\n 'DNASE:testis male embryo',\n 'DNASE:neural stem progenitor cell originated from H1-hESC',\n 'DNASE:right atrium auricular region female adult (51 year)',\n 'DNASE:common myeloid progenitor, CD34-positive male adult (49 years)',\n 'DNASE:stomach female embryo (121 day)',\n 'DNASE:muscle of leg female embryo (105 days)',\n 'DNASE:muscle of leg male embryo (97 days)',\n 'DNASE:left kidney female embryo (87 days)',\n 'DNASE:muscle of back male embryo (97 days)',\n 'DNASE:muscle of leg male embryo (96 days)',\n 'DNASE:right lung female embryo (105 days)',\n 'DNASE:NAMALWA treated with Sendai virus for 2 hours',\n 'DNASE:renal pelvis male embryo (127 days)',\n 'DNASE:muscle of arm male embryo (96 days)',\n 'DNASE:heart male child (3 years)',\n 'DNASE:brain female embryo (117 days)',\n 'DNASE:muscle of arm female embryo (85 days)',\n 'DNASE:heart male embryo (110 days)',\n 'DNASE:L1-S8',\n 'DNASE:CD8-positive, alpha-beta T cell male adult (37 years)',\n 'DNASE:muscle of back male embryo (91 day)',\n 'DNASE:left renal pelvis male embryo (105 days)',\n 'DNASE:middle frontal gyrus male adult (78 years)',\n 'DNASE:lung male embryo (103 days)',\n 'DNASE:heart male embryo (105 days)',\n 'DNASE:left renal pelvis male embryo (120 days)',\n 'DNASE:common myeloid progenitor, CD34-positive female adult (50 years)',\n \"DNASE:Peyer's patch female adult (53 years)\",\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:hematopoietic multipotent progenitor cell',\n 'DNASE:right kidney male embryo (87 days)',\n 'DNASE:tibial artery male adult (37 years)',\n 'DNASE:renal cell carcinoma',\n 'DNASE:thymus female embryo (113 days)',\n 'DNASE:brain female embryo (109 days)',\n 'DNASE:Daoy',\n 'DNASE:A673',\n 'DNASE:muscle of arm male embryo (101 day)',\n 'DNASE:muscle of arm female embryo (120 days)',\n 'DNASE:muscle of back male embryo (105 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:ecto neural progenitor cell originated from H9',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 17 days, kit ligand for 17 days, hydrocortisone succinate for 17 days, erythropoietin for 17 days',\n 'DNASE:hepatocyte originated from H9',\n 'DNASE:renal pelvis male embryo (97 days)',\n 'DNASE:heart embryo (101 day)',\n 'DNASE:large intestine male embryo (115 days)',\n 'DNASE:T-cell male adult (37 years)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:CD1c-positive myeloid dendritic cell',\n 'DNASE:B cell male adult (21 year)',\n 'DNASE:superior temporal gyrus male adult (84 years)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:iPS DF 19.11 male newborn',\n 'DNASE:hindlimb muscle male embryo (120 days)',\n 'DNASE:MCF 10A treated with 1 uM tamoxifen for 6 hours',\n 'DNASE:sigmoid colon male adult (54 years)',\n 'DNASE:heart male embryo (120 days)',\n 'DNASE:tibial nerve female adult (51 year)',\n 'DNASE:adipocyte',\n 'DNASE:muscle of trunk female embryo (121 day)',\n 'DNASE:left cardiac atrium female embryo (101 day)',\n 'DNASE:T-cell male adult (21 year)',\n 'DNASE:right kidney male embryo (108 days)',\n 'DNASE:adrenal gland female embryo (108 days)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 11 day, kit ligand for 11 day, hydrocortisone succinate for 11 day, erythropoietin for 11 day',\n 'DNASE:brain male embryo (105 days)',\n 'DNASE:body of pancreas female adult (53 years)',\n 'DNASE:left kidney female embryo (147 days)',\n 'DNASE:CD4-positive, alpha-beta T cell male adult (37 years)',\n 'DNASE:KBM-7',\n 'DNASE:psoas muscle male child (3 years)',\n 'DNASE:ovary female embryo',\n 'DNASE:RKO',\n 'DNASE:leg bone male embryo (81 day)',\n 'DNASE:glomerular visceral epithelial cell child (3 years)',\n 'DNASE:foreskin melanocyte male newborn',\n 'DNASE:embryonic facial prominence embryo (53 days) and embryo (58 days)',\n 'DNASE:vagina female adult (53 years)',\n 'DNASE:kidney female embryo (85 days)',\n 'DNASE:muscle of back male embryo (96 days)',\n 'DNASE:muscle of trunk female embryo (113 days)',\n 'DNASE:iPS DF 19.7 male newborn',\n 'DNASE:right lung female embryo (110 days)',\n 'DNASE:left lung male embryo (87 days)',\n 'DNASE:large intestine female embryo (105 days)',\n 'DNASE:right lung female embryo (98 days)',\n 'DNASE:leg bone male embryo (81 day)',\n 'DNASE:CD14-positive monocyte male adult (21 year)',\n 'DNASE:muscle of arm male embryo (120 days)',\n \"DNASE:Peyer's patch male adult (37 years)\",\n 'DNASE:common myeloid progenitor, CD34-positive male adult (36 years)',\n 'DNASE:left lung female embryo (108 days)',\n 'DNASE:small intestine female embryo (91 day)',\n 'DNASE:MM.1S',\n 'DNASE:sigmoid colon female adult (51 year)',\n 'DNASE:left lung female embryo (105 days)',\n 'DNASE:common myeloid progenitor, CD34-positive female adult (33 years)',\n 'DNASE:retina embryo (125 days) and male embryo (103 days)',\n 'DNASE:brain male embryo (72 days) and male embryo (76 days)',\n 'DNASE:muscle of back male embryo (108 days)',\n 'DNASE:IMR-90',\n 'DNASE:lung female embryo (108 days)',\n 'DNASE:left lung male embryo (113 days)',\n 'DNASE:OCI-LY7',\n 'DNASE:upper lobe of left lung female adult (51 year)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 18 days, kit ligand for 18 days, hydrocortisone succinate for 18 days, erythropoietin for 18 days',\n 'DNASE:putamen male adult (78 years)',\n 'DNASE:common myeloid progenitor, CD34-positive male adult (42 years)',\n 'DNASE:placenta embryo (53 days)',\n 'DNASE:kidney male embryo (105 days)',\n 'DNASE:heart left ventricle female embryo (136 days)',\n 'DNASE:small intestine female embryo (108 days)',\n 'DNASE:LoVo',\n 'DNASE:cerebellar cortex male adult (78 years) and male adult (84 years)',\n 'DNASE:lung embryo (67 days)',\n 'DNASE:transverse colon female adult (53 years)',\n 'DNASE:brain embryo (80 days)',\n 'DNASE:stomach female embryo (108 days)',\n 'DNASE:umbilical cord embryo (59 days) and male embryo (76 days)',\n 'DNASE:muscle of leg male embryo (105 days)',\n 'DNASE:Caki2',\n 'DNASE:muscle of arm female embryo (105 days)',\n 'DNASE:foreskin melanocyte male newborn',\n 'DNASE:stomach male embryo (108 days)',\n 'DNASE:body of pancreas male adult (37 years)',\n 'DNASE:renal cortex interstitium female embryo (120 days)',\n 'DNASE:body of pancreas female adult (51 year)',\n 'DNASE:large intestine male embryo (105 days)',\n 'DNASE:limb embryo (58 days) and embryo (59 days)',\n 'DNASE:heart female embryo (147 days)',\n 'DNASE:heart male embryo (96 days)',\n 'DNASE:right renal pelvis male embryo (120 days)',\n 'DNASE:left lung female embryo (117 days)',\n 'DNASE:thymus female embryo (98 days)',\n 'DNASE:ovary female adult (53 years)',\n 'DNASE:left kidney male embryo (115 days)',\n 'DNASE:thymus male embryo (113 days)',\n 'DNASE:placenta female embryo (105 days)',\n 'DNASE:EH',\n 'DNASE:renal cortex interstitium male embryo (97 days)',\n 'DNASE:placenta embryo (102 days)',\n 'DNASE:placenta embryo (56 days) and embryo (59 days)',\n 'DNASE:renal pelvis female embryo (103 days)',\n 'DNASE:right lobe of liver female adult (53 years)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:tongue male embryo (72 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:liver female embryo (101 day) and female embryo (113 days)',\n 'DNASE:large intestine female embryo (107 days)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 6 days, kit ligand for 6 days, hydrocortisone succinate for 6 days, erythropoietin for 6 days',\n 'DNASE:common myeloid progenitor, CD34-positive male',\n 'DNASE:small intestine female embryo (98 days)',\n 'DNASE:CD4-positive, alpha-beta T cell male adult (21 year)',\n 'DNASE:brain male embryo (101 day)',\n 'DNASE:placenta female embryo (101 day) and male embryo (105 days)',\n 'DNASE:renal pelvis male embryo (91 day)',\n 'DNASE:lung embryo (80 days) and male embryo (76 days)',\n \"DNASE:Ammon's horn male adult (84 years)\",\n 'DNASE:muscle of back female embryo (105 days)',\n 'DNASE:lung male embryo (82 days)',\n 'DNASE:left renal cortex interstitium male embryo (105 days)',\n 'DNASE:trophoblast cell embryo (17 weeks) and embryo (18 weeks)',\n 'DNASE:RPMI8226',\n 'DNASE:small intestine male embryo (91 day)',\n 'DNASE:brain embryo (56 days) and male embryo (58 days)',\n 'DNASE:pancreas female adult (30 years)',\n 'DNASE:adrenal gland female adult (53 years)',\n 'DNASE:breast epithelium female adult (51 year)',\n 'DNASE:left kidney male embryo (87 days)',\n 'DNASE:renal pelvis female embryo (96 days)',\n 'DNASE:stomach male embryo (127 days)',\n 'DNASE:CD8-positive, alpha-beta T cell female adult (34 years)',\n 'DNASE:spinal cord female embryo (89 days)',\n 'DNASE:muscle of arm male embryo (97 days)',\n 'DNASE:renal pelvis female embryo (105 days)',\n 'DNASE:HAP-1',\n 'DNASE:SJSA1',\n 'DNASE:retina embryo (74 days) and embryo (85 days)',\n 'DNASE:muscle of leg male embryo (127 days)',\n 'DNASE:fibroblast of skin of abdomen male embryo (97 days)',\n 'DNASE:bipolar neuron originated from GM23338 treated with 0.5 ug/mL doxycycline hyclate for 4 days',\n 'DNASE:stomach female embryo (147 days)',\n 'DNASE:lung male embryo (54 days) and male embryo (58 days)',\n 'DNASE:T-cell male adult (36 years)',\n 'DNASE:T-cell male adult (21 year)',\n 'DNASE:HK-2',\n 'DNASE:NCI-H460',\n 'DNASE:left lung male embryo (96 days)',\n 'DNASE:common myeloid progenitor, CD34-positive male adult (23 years)',\n 'DNASE:stomach female adult (51 year)',\n 'DNASE:CD4-positive, alpha-beta T cell female adult (33 years)',\n 'DNASE:kidney female embryo (113 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:placenta female embryo (85 days)',\n 'DNASE:brain male embryo (122 days)',\n 'DNASE:muscle of arm male embryo (97 days)',\n 'DNASE:renal cortex interstitium female embryo (103 days)',\n 'DNASE:thyroid gland female adult (51 year)',\n 'DNASE:NAMALWA',\n 'DNASE:heart embryo (59 days) and female embryo (76 days)',\n 'DNASE:large intestine male embryo (105 days)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:right kidney male embryo (96 days)',\n 'DNASE:CD14-positive monocyte male adult (37 years)',\n 'DNASE:ELF-1',\n 'DNASE:spinal cord female embryo (113 days)',\n 'DNASE:spleen embryo (112 days)',\n 'DNASE:left lung female embryo (107 days)',\n 'DNASE:thymus female embryo',\n 'DNASE:CD4-positive, alpha-beta T cell male adult (21 year)',\n 'DNASE:stomach female embryo (96 days)',\n 'DNASE:EL',\n 'DNASE:CD14-positive monocyte female adult (34 years)',\n 'DNASE:thyroid gland female adult (53 years)',\n 'DNASE:adrenal gland female embryo (113 days)',\n 'DNASE:muscle of back male embryo (96 days)',\n 'DNASE:SJCRH30',\n 'DNASE:natural killer cell male adult (21 year)',\n 'DNASE:heart male embryo (72 days) and male embryo (76 days)',\n 'DNASE:midbrain male adult (78 years) and male adult (84 years)',\n 'DNASE:ovary female adult (30 years)',\n 'DNASE:mesendoderm originated from H1-hESC',\n 'DNASE:natural killer cell male adult (37 years)',\n 'DNASE:natural killer cell female adult (34 years)',\n 'DNASE:foreskin keratinocyte male newborn',\n 'DNASE:stomach female embryo',\n 'DNASE:adrenal gland male embryo (108 days)',\n 'DNASE:testis male embryo',\n 'DNASE:mesenchymal stem cell originated from H1-hESC',\n 'DNASE:vagina female adult (51 year)',\n 'DNASE:common myeloid progenitor, CD34-positive male adult (43 years)',\n 'DNASE:heart right ventricle female embryo (101 day) and female embryo (103 days)',\n 'DNASE:L1-S8R',\n 'DNASE:heart female embryo (116 days) and female embryo (98 days)',\n 'DNASE:MCF 10A treated with 1 uM tamoxifen for 24 hours',\n 'DNASE:right renal pelvis male embryo (105 days)',\n 'DNASE:muscle of arm female embryo (98 days)',\n 'DNASE:H9 G1 phase genetically modified using stable transfection',\n 'DNASE:tibial nerve male adult (37 years)',\n 'DNASE:kidney male embryo (85 days)',\n 'DNASE:tongue female embryo (59 days) and female embryo (76 days)',\n 'DNASE:transverse colon female adult (51 year)',\n 'DNASE:right renal pelvis male embryo (105 days)',\n 'DNASE:large intestine male embryo (91 day)',\n 'DNASE:right kidney female embryo (117 days)',\n 'DNASE:right kidney male embryo (91 day)',\n 'DNASE:skin fibroblast male embryo (97 days)',\n 'DNASE:globus pallidus male adult (78 years) and male adult (84 years)',\n 'DNASE:kidney female embryo (105 days)',\n 'DNASE:right atrium auricular region female adult (53 years)',\n 'DNASE:thymus female embryo (147 days)',\n 'DNASE:stomach male adult (34 years)',\n 'DNASE:eye embryo (56 days) and male embryo (76 days)',\n 'DNASE:esophagus squamous epithelium male adult (37 years)',\n 'DNASE:glomerular visceral epithelial cell child (3 years)',\n 'DNASE:muscle of back male embryo (127 days)',\n 'DNASE:spinal cord male embryo (96 days)',\n 'DNASE:MCF 10A',\n 'DNASE:transverse colon male adult (54 years)',\n 'DNASE:kidney embryo (59 days) and female embryo (59 days)',\n 'DNASE:H1-hESC',\n 'DNASE:large intestine female embryo (98 days)',\n 'DNASE:large intestine female embryo (103 days)',\n 'DNASE:placenta male embryo (85 days)',\n 'DNASE:left lung female embryo (91 day)',\n 'DNASE:heart embryo (80 days)',\n 'DNASE:femur female embryo (98 days)',\n 'DNASE:H4',\n 'DNASE:trophoblast cell embryo (23 weeks)',\n 'DNASE:urinary bladder male embryo (76 days)',\n 'DNASE:HT-29',\n 'DNASE:limb embryo (53 days) and embryo (56 days)',\n 'DNASE:retina female embryo (89 days)',\n 'DNASE:dedifferentiated amniotic fluid mesenchymal stem cell',\n 'DNASE:upper lobe of left lung female adult (53 years)',\n 'DNASE:brain female embryo (105 days)',\n 'DNASE:muscle of arm embryo (101 day)',\n 'DNASE:renal cortex interstitium male embryo (108 days)',\n 'DNASE:pons male adult (78 years)',\n 'DNASE:thymus female embryo (105 days)',\n 'DNASE:CD8-positive, alpha-beta T cell female adult (33 years)',\n 'DNASE:cardiac muscle cell',\n 'DNASE:CD8-positive, alpha-beta T cell male adult (21 year)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 8 days, kit ligand for 8 days, hydrocortisone succinate for 8 days, erythropoietin for 8 days',\n 'DNASE:right lung female embryo (117 days)',\n 'DNASE:right lung male embryo (105 days)',\n 'DNASE:lung female embryo (96 days)',\n 'DNASE:adrenal gland male adult (54 years)',\n 'DNASE:renal cortex interstitium male embryo (127 days)',\n 'DNASE:spleen male adult (54 years)',\n 'DNASE:renal cortex interstitium female embryo (89 days)',\n 'DNASE:ascending aorta female adult (51 year)',\n 'DNASE:ovary female adult (51 year)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 13 days, kit ligand for 13 days, hydrocortisone succinate for 13 days, erythropoietin for 13 days',\n 'DNASE:cardiac fibroblast female embryo (94 days) and female embryo (98 days)',\n 'DNASE:adrenal gland male embryo (85 days)',\n 'DNASE:large intestine male embryo (108 days)',\n 'DNASE:occipital lobe male adult (84 years)',\n 'DNASE:right lung female embryo (107 days)',\n 'DNASE:small intestine female embryo (105 days)',\n 'DNASE:muscle of leg male embryo (104 days)',\n 'DNASE:lower leg skin female adult (53 years)',\n 'DNASE:adrenal gland female adult (51 year)',\n 'DNASE:adrenal gland female embryo (85 days)',\n 'DNASE:muscle of arm male embryo (115 days)',\n 'DNASE:right kidney female embryo (147 days)',\n 'DNASE:kidney female embryo (76 days) and male embryo (76 days)',\n 'DNASE:large intestine female embryo (108 days)',\n 'DNASE:right kidney female embryo (98 days)',\n 'DNASE:right renal cortex interstitium male embryo (120 days)',\n 'DNASE:muscle of arm male embryo (96 days)',\n 'DNASE:thymus male embryo (108 days)',\n 'DNASE:B cell female adult (34 years)',\n 'DNASE:thyroid gland male adult (54 years)',\n 'DNASE:spinal cord female embryo (59 days) and male embryo (72 days)',\n 'DNASE:heart embryo (96 days)',\n 'DNASE:renal pelvis female embryo (89 days)',\n 'DNASE:renal pelvis male embryo (108 days)',\n 'DNASE:heart female embryo (103 days)',\n 'DNASE:H9',\n 'DNASE:K562',\n 'DNASE:left renal cortex interstitium male embryo (105 days)',\n 'DNASE:right lung female embryo (108 days)',\n 'DNASE:stomach female embryo (96 days)',\n 'DNASE:small intestine male adult (34 years)',\n 'DNASE:renal cortex interstitium female embryo (96 days)',\n 'DNASE:A172',\n 'DNASE:left lung male embryo (115 days)',\n 'DNASE:muscle of leg male embryo (115 days)',\n 'DNASE:hematopoietic multipotent progenitor cell treated with interleukin-3 for 15 days, kit ligand for 15 days, hydrocortisone succinate for 15 days, erythropoietin for 15 days',\n 'DNASE:muscle of leg female embryo (115 days)',\n 'DNASE:PC-9',\n 'DNASE:kidney female embryo (108 days)',\n 'DNASE:stomach embryo (101 day)',\n 'DNASE:H9 G2 phase genetically modified using stable transfection',\n 'DNASE:esophagus muscularis mucosa male adult (37 years)',\n 'DNASE:small intestine male embryo (108 days)',\n 'DNASE:heart left ventricle female embryo (101 day) and female embryo (103 days)',\n 'DNASE:SK-N-DZ',\n 'DNASE:brain male embryo (104 days)',\n 'DNASE:right lung male embryo (87 days)',\n 'DNASE:muscle of arm male embryo (105 days)',\n 'DNASE:muscle of arm male embryo (104 days)',\n 'DNASE:kidney female embryo (105 days)',\n 'DNASE:left lung male embryo (105 days)',\n 'DNASE:left kidney female embryo (107 days)',\n \"DNASE:Peyer's patch male adult (37 years)\",\n 'DNASE:renal pelvis male embryo (113 days)',\n 'DNASE:prostate gland male adult (37 years)',\n 'DNASE:HeLa-S3',\n 'DNASE:left lung female embryo (110 days)',\n 'DNASE:thymus male embryo (104 days)',\n 'DNASE:neural progenitor cell originated from H9',\n 'DNASE:trophoblast cell embryo (39 weeks) and embryo (40 weeks)',\n 'DNASE:right lung male embryo (96 days)',\n 'DNASE:H9 G1 phase genetically modified using stable transfection',\n 'DNASE:small intestine male embryo (87 days)',\n 'DNASE:spinal cord female embryo (87 days)',\n 'DNASE:left kidney female embryo (110 days)',\n 'DNASE:arm bone male embryo (81 day)',\n 'DNASE:testis male adult (54 years)',\n 'DNASE:transverse colon male adult (37 years)',\n 'DNASE:right renal pelvis male embryo (105 days)',\n 'DNASE:lung embryo (101 day)',\n 'DNASE:inferior parietal cortex male adult (84 years)',\n 'DNASE:kidney capillary endothelial cell female embryo (113 days)',\n 'DNASE:placenta male embryo (91 day)',\n 'DNASE:right kidney male embryo (115 days)',\n 'DNASE:coronary artery female adult (51 year)',\n 'ATAC:BM0106-Day0-MCP-A / Bone Marrow CD34+ / pDC',\n 'ATAC:BM0106-UNK-ATAC-2 / Bone Marrow CD34+ / UNK',\n 'ATAC:BM0828-MEGA1-A-151109 / Bone Marrow CD34+ / Mega',\n 'ATAC:BM1077-MCP / Bone Marrow CD34+ / pDC',\n 'ATAC:BM1077-UNK / Bone Marrow CD34+ / UNK',\n 'ATAC:BM1137-GMP1-low-ATAC-2 / Bone Marrow CD34+ / GMP-A',\n 'ATAC:BM1137-GMP2-mid-ATAC-1 / Bone Marrow CD34+ / GMP-B',\n 'ATAC:BM1137-GMP3-high-ATAC-2 / Bone Marrow CD34+ / GMP-C',\n 'ATAC:BM1214-Day0-MCP / Bone Marrow CD34+ / pDC',\n 'ATAC:BM1214-Day0-UNK-A / Bone Marrow CD34+ / UNK',\n 'CHIP:CTCF:MCF-7',\n 'CHIP:TAF1:MCF-7',\n 'CHIP:H3K4me3:GM12878',\n 'CHIP:CTCF:GM12878',\n 'CHIP:H3K27ac:GM12878',\n 'CHIP:H3K27me3:GM12878',\n 'CHIP:H3K4me1:GM12878',\n 'CHIP:H3K4me2:GM12878',\n 'CHIP:H3K9ac:GM12878',\n 'CHIP:H4K20me1:GM12878',\n 'CHIP:H3K27me3:endothelial cell of umbilical vein male newborn',\n 'CHIP:H3K4me2:endothelial cell of umbilical vein male newborn',\n 'CHIP:H3K4me3:endothelial cell of umbilical vein male newborn',\n 'CHIP:CTCF:K562',\n 'CHIP:H3K27me3:K562',\n 'CHIP:H3K36me3:K562',\n 'CHIP:H3K4me2:K562',\n 'CHIP:H3K4me3:K562',\n 'CHIP:H3K9ac:K562',\n 'CHIP:H3K9me1:K562',\n 'CHIP:CTCF:endothelial cell of umbilical vein male newborn',\n 'CHIP:H3K27ac:endothelial cell of umbilical vein male newborn',\n 'CHIP:H3K27ac:keratinocyte female',\n 'CHIP:H3K27ac:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K27me3:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K36me3:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K4me2:HepG2',\n 'CHIP:H3K9ac:HepG2',\n 'CHIP:CTCF:H1-hESC',\n 'CHIP:H3K4me1:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K4me2:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K4me3:mammary epithelial cell female adult (50 years)',\n 'CHIP:H4K20me1:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K4me3:HepG2',\n 'CHIP:H4K20me1:HepG2',\n 'CHIP:H3K27ac:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K27me3:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K36me3:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K4me3:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K9ac:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K27ac:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K27me3:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K36me3:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K4me1:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K4me2:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K4me3:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K9ac:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H4K20me1:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K27ac:H1-hESC',\n 'CHIP:H3K79me2:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K9me3:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:CTCF:myotube',\n 'CHIP:H2AFZ:myotube',\n 'CHIP:H3K27ac:myotube',\n 'CHIP:H3K36me3:myotube',\n 'CHIP:H3K4me1:myotube',\n 'CHIP:H3K4me2:myotube',\n 'CHIP:H3K4me3:myotube',\n 'CHIP:CTCF:HeLa-S3',\n 'CHIP:H3K27ac:HeLa-S3',\n 'CHIP:H3K4me2:HeLa-S3',\n 'CHIP:H3K4me3:HeLa-S3',\n 'CHIP:H3K79me2:HeLa-S3',\n 'CHIP:H3K9ac:HeLa-S3',\n 'CHIP:H4K20me1:HeLa-S3',\n 'CHIP:H3K27me3:HepG2',\n 'CHIP:H3K79me2:myotube',\n 'CHIP:CTCF:astrocyte',\n 'CHIP:H3K27ac:astrocyte',\n 'CHIP:H3K4me3:astrocyte',\n 'CHIP:H2AFZ:GM12878',\n 'CHIP:H3K79me2:GM12878',\n 'CHIP:H3K9ac:myotube',\n 'CHIP:H4K20me1:myotube',\n 'CHIP:H2AFZ:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:H3K27me3:HeLa-S3',\n 'CHIP:H2AFZ:K562',\n 'CHIP:H3K79me2:K562',\n 'CHIP:H3K9me3:K562',\n 'CHIP:H2AFZ:osteoblast',\n 'CHIP:H3K27ac:osteoblast',\n 'CHIP:H3K36me3:osteoblast',\n 'CHIP:H3K4me1:osteoblast',\n 'CHIP:H3K4me2:osteoblast',\n 'CHIP:H3K9me3:osteoblast',\n 'CHIP:CTCF:fibroblast of dermis',\n 'CHIP:H3K27ac:fibroblast of dermis',\n 'CHIP:H3K4me3:fibroblast of dermis NONE and female adult',\n 'CHIP:H3K4me1:HepG2',\n 'CHIP:H3K4me1:HeLa-S3',\n 'CHIP:KDM5B:K562',\n 'CHIP:RBBP5:H1-hESC',\n 'CHIP:HDAC1:K562',\n 'CHIP:HDAC2:K562',\n 'CHIP:PHF8:K562',\n 'CHIP:RBBP5:K562',\n 'CHIP:SAP30:K562',\n 'CHIP:CHD1:H1-hESC',\n 'CHIP:H3K9me3:myotube',\n 'CHIP:H2AFZ:HeLa-S3',\n 'CHIP:H3K9me3:HeLa-S3',\n 'CHIP:H3K27me3:osteoblast',\n 'CHIP:H4K20me1:osteoblast',\n 'CHIP:H2AFZ:DND-41',\n 'CHIP:H3K27ac:DND-41',\n 'CHIP:H3K36me3:DND-41',\n 'CHIP:H3K4me1:DND-41',\n 'CHIP:H3K4me3:DND-41',\n 'CHIP:H3K79me2:DND-41',\n 'CHIP:H4K20me1:DND-41',\n 'CHIP:EZH2:GM12878',\n 'CHIP:EZH2:mammary epithelial cell female adult (50 years)',\n 'CHIP:H2AFZ:mammary epithelial cell female adult (50 years)',\n 'CHIP:H3K9me3:mammary epithelial cell female adult (50 years)',\n 'CHIP:EZH2:skeletal muscle myoblast male adult (22 years)',\n 'CHIP:EZH2:HepG2',\n 'CHIP:H2AFZ:keratinocyte female',\n 'CHIP:H3K79me2:keratinocyte female',\n 'CHIP:H3K9me3:keratinocyte female',\n 'CHIP:EZH2:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H2AFZ:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K9me3:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K9ac:astrocyte',\n 'CHIP:H4K20me1:astrocyte',\n 'CHIP:H3K9ac:DND-41',\n 'CHIP:H3K9me3:DND-41',\n 'CHIP:H3K79me2:mammary epithelial cell female adult (50 years)',\n 'CHIP:H2AFZ:endothelial cell of umbilical vein male newborn',\n 'CHIP:H3K79me2:endothelial cell of umbilical vein male newborn',\n 'CHIP:EZH2:fibroblast of dermis',\n 'CHIP:H3K79me2:fibroblast of lung female child (11 year) and male adult (45 years)',\n 'CHIP:H3K79me2:osteoblast',\n 'CHIP:H3K4me3:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K27ac:CD14-positive monocyte female',\n 'CHIP:H3K27me3:CD14-positive monocyte female',\n 'CHIP:H3K36me3:CD14-positive monocyte female',\n 'CHIP:H3K4me1:CD14-positive monocyte female',\n 'CHIP:H3K4me3:CD14-positive monocyte female',\n 'CHIP:H3K79me2:CD14-positive monocyte female',\n 'CHIP:H3K9me3:CD14-positive monocyte female',\n 'CHIP:H4K20me1:CD14-positive monocyte female',\n 'CHIP:H3K4me3:A549 treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:H3K9ac:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K27me3:DND-41',\n 'CHIP:H3K9me3:endothelial cell of umbilical vein male newborn',\n 'CHIP:EZH2:HeLa-S3',\n 'CHIP:H3K9me3:HepG2',\n 'CHIP:H3K9ac:CD14-positive monocyte female',\n 'CHIP:H3K4me3:osteoblast',\n 'CHIP:H3K27me3:myotube',\n 'CHIP:HDAC6:K562',\n 'CHIP:PHF8:H1-hESC',\n 'CHIP:CTCF:CD14-positive monocyte female',\n 'CHIP:H3K79me2:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:HDAC6:H1-hESC',\n 'CHIP:SAP30:H1-hESC',\n 'CHIP:SUZ12:H1-hESC',\n 'CHIP:CREBBP:K562',\n 'CHIP:CBX3:K562',\n 'CHIP:KAT2B:K562',\n 'CHIP:SIRT6:K562',\n 'CHIP:SUZ12:K562',\n 'CHIP:CTCF:A549 treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:H2AFZ:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K27ac:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K27me3:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K4me1:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K9me3:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H4K20me1:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H3K27ac:B cell female adult (27 years)',\n 'CHIP:EP300:H1-hESC',\n 'CHIP:SIRT6:H1-hESC',\n 'CHIP:SETDB1:K562',\n 'CHIP:CTCF:B cell female adult (27 years) and female adult (43 years)',\n 'CHIP:H2AFZ:B cell female adult (27 years) and female adult (43 years)',\n 'CHIP:H3K4me2:B cell female adult (27 years) and female adult (43 years)',\n 'CHIP:CHD7:H1-hESC',\n 'CHIP:HDAC2:H1-hESC',\n 'CHIP:KDM4A:H1-hESC',\n 'CHIP:WHSC1:K562',\n 'CHIP:H3K27ac:A549 treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:H3K4me2:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:H4K20me1:B cell female adult (27 years)',\n 'CHIP:FOXP2:SK-N-MC',\n 'CHIP:POLR2A:GM12878',\n 'CHIP:SRF:GM12878',\n 'CHIP:REST:GM12878',\n 'CHIP:USF1:GM12878',\n 'CHIP:JUND:HepG2',\n 'CHIP:SIN3A:HepG2',\n 'CHIP:USF1:HepG2',\n 'CHIP:POLR2A:HeLa-S3',\n 'CHIP:PBX3:GM12878',\n 'CHIP:TAF1:GM12878',\n 'CHIP:BATF:GM12878',\n 'CHIP:EBF1:GM12878',\n 'CHIP:IRF4:GM12878',\n 'CHIP:TCF12:GM12878',\n 'CHIP:BCL11A:GM12878',\n 'CHIP:EP300:GM12878',\n 'CHIP:ZBTB33:GM12878',\n 'CHIP:PAX5:GM12878',\n 'CHIP:NR3C1:A549 treated with 500 pM dexamethasone for 1 hour',\n 'CHIP:NR3C1:A549 treated with 50 nM dexamethasone for 1 hour',\n 'CHIP:NR3C1:A549 treated with 5 nM dexamethasone for 1 hour',\n 'CHIP:POLR2A:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:POLR2A:A549 treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:PAX5:GM12878',\n 'CHIP:REST:H1-hESC',\n 'CHIP:POLR2A:H1-hESC',\n 'CHIP:TAF1:H1-hESC',\n 'CHIP:FOSL2:HepG2',\n 'CHIP:GABPA:HeLa-S3',\n 'CHIP:TAF1:HeLa-S3',\n 'CHIP:RXRA:HepG2',\n 'CHIP:POLR2A:GM12892',\n 'CHIP:POLR2AphosphoS5:GM12892',\n 'CHIP:TAF1:GM12892',\n 'CHIP:POLR2AphosphoS5:H1-hESC',\n 'CHIP:BHLHE40:HepG2',\n 'CHIP:CTCF:HepG2',\n 'CHIP:POLR2AphosphoS5:GM12878',\n 'CHIP:POU2F2:GM12891',\n 'CHIP:SPI1:GM12891',\n 'CHIP:POLR2A:GM12891',\n 'CHIP:POLR2AphosphoS5:GM12891',\n 'CHIP:TAF1:GM12891',\n 'CHIP:NR3C1:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:BCL11A:H1-hESC',\n 'CHIP:SIX5:H1-hESC',\n 'CHIP:SP1:H1-hESC',\n 'CHIP:SIN3A:H1-hESC',\n 'CHIP:TCF12:H1-hESC',\n 'CHIP:USF1:H1-hESC',\n 'CHIP:SRF:H1-hESC',\n 'CHIP:GABPA:H1-hESC',\n 'CHIP:ESR1:Ishikawa treated with 10 nM estradiol for 1 hour',\n 'CHIP:ESR1:Ishikawa treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'CHIP:EGR1:H1-hESC',\n 'CHIP:NR3C1:Ishikawa treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:RXRA:GM12878',\n 'CHIP:SIX5:GM12878',\n 'CHIP:TCF12:HepG2',\n 'CHIP:PAX5:GM12891',\n 'CHIP:REST:SK-N-SH',\n 'CHIP:GABPA:HepG2',\n 'CHIP:REST:HepG2',\n 'CHIP:POLR2A:HepG2',\n 'CHIP:TAF1:HepG2',\n 'CHIP:REST:Panc1',\n 'CHIP:REST:PFSK-1',\n 'CHIP:NR3C1:A549 treated with 100 nM dexamethasone for 1 hour',\n 'CHIP:ESR1:T47D treated with 100 nM genistein for 1 hour',\n 'CHIP:NR3C1:A549 treated with 0.02% ethanol for 1 hour',\n 'CHIP:RXRA:H1-hESC',\n 'CHIP:SP1:HepG2',\n 'CHIP:BCLAF1:GM12878',\n 'CHIP:ETS1:GM12878',\n 'CHIP:MEF2A:GM12878',\n 'CHIP:ATF3:H1-hESC',\n 'CHIP:YY1:H1-hESC',\n 'CHIP:ATF3:HepG2',\n 'CHIP:BCLAF1:K562',\n 'CHIP:POLR2A:Ishikawa treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'CHIP:YY1:GM12891',\n 'CHIP:EP300:H1-hESC',\n 'CHIP:JUND:H1-hESC',\n 'CHIP:ETS1:K562',\n 'CHIP:POLR2AphosphoS5:K562',\n 'CHIP:FOXA1:T47D treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'CHIP:NR3C1:Ishikawa treated with 0.02% ethanol for 1 hour',\n 'CHIP:RAD21:H1-hESC',\n 'CHIP:FOXA1:HepG2',\n 'CHIP:HNF4A:HepG2',\n 'CHIP:E2F6:K562',\n 'CHIP:ESR1:T47D treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'CHIP:GABPA:K562',\n 'CHIP:MAX:K562',\n 'CHIP:SIN3A:K562',\n 'CHIP:RAD21:HepG2',\n 'CHIP:YY1:GM12892',\n 'CHIP:TAF7:H1-hESC',\n 'CHIP:EP300:HepG2',\n 'CHIP:CTCF:SK-N-SH treated with 6 uM all-trans-retinoic acid for 48 hours',\n 'CHIP:RAD21:SK-N-SH treated with 6 uM all-trans-retinoic acid for 48 hours',\n 'CHIP:YY1:SK-N-SH treated with 6 uM all-trans-retinoic acid for 48 hours',\n 'CHIP:HDAC2:HepG2',\n 'CHIP:ZBTB7A:K562',\n 'CHIP:USF1:SK-N-SH treated with 6 uM all-trans-retinoic acid for 48 hours',\n 'CHIP:YY1:K562',\n 'CHIP:SRF:GM12878',\n 'CHIP:BCL11A:H1-hESC',\n 'CHIP:POLR2AphosphoS5:HCT116',\n 'CHIP:REST:HeLa-S3',\n 'CHIP:FOXA1:HepG2',\n 'CHIP:POLR2A:K562',\n 'CHIP:NANOG:H1-hESC',\n 'CHIP:FOSL1:K562',\n 'CHIP:REST:K562',\n 'CHIP:GATA3:T47D treated with 0.02% dimethyl sulfoxide for 1 hour',\n 'CHIP:RAD21:GM12878',\n 'CHIP:ELF1:HepG2',\n 'CHIP:ZBTB33:HepG2',\n 'CHIP:EGR1:K562',\n 'CHIP:MEF2C:GM12878',\n 'CHIP:CTCF:H1-hESC',\n 'CHIP:FOXA2:HepG2',\n 'CHIP:HNF4G:HepG2',\n 'CHIP:TAF7:K562',\n 'CHIP:THAP1:K562',\n 'CHIP:YY1:GM12878',\n 'CHIP:BCL3:GM12878',\n 'CHIP:HDAC2:H1-hESC',\n 'CHIP:FOSL1:H1-hESC',\n 'CHIP:YY1:HepG2',\n 'CHIP:ATF3:K562',\n ...]\n\n\n\nchrom_bed_downloads = pd.read_csv(\"https://uchicago.box.com/shared/static/du77wf31li38tciv8imivwu57svae03p.csv\")\nchrom_bed_downloads.index = chrom_bed_downloads[\"chroms\"]\n\nchrom_bed_downloads.head(10)\n\n\n\n\n\n\n\n\nchroms\nlink\n\n\nchroms\n\n\n\n\n\n\n1\n1\nhttps://uchicago.box.com/shared/static/9q9n4a0...\n\n\n2\n2\nhttps://uchicago.box.com/shared/static/1tk6a3f...\n\n\n3\n3\nhttps://uchicago.box.com/shared/static/77ldwqq...\n\n\n4\n4\nhttps://uchicago.box.com/shared/static/s0g48al...\n\n\n5\n5\nhttps://uchicago.box.com/shared/static/yafgxb1...\n\n\n6\n6\nhttps://uchicago.box.com/shared/static/9vpxc7z...\n\n\n7\n7\nhttps://uchicago.box.com/shared/static/hkru0gi...\n\n\n8\n8\nhttps://uchicago.box.com/shared/static/ruac33s...\n\n\n9\n9\nhttps://uchicago.box.com/shared/static/dfw6gkj...\n\n\n10\n10\nhttps://uchicago.box.com/shared/static/ek50gvt...\n\n\n\n\n\n\n\n\nchr1_tss = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/tss_by_chr/chr17_tss_by_gene.txt', sep='\\t')\namigo1_variations = pd.read_table('/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr17/chr17_GSDMB.bed', sep='\\t')\ngeuvadis_gene_expression = pd.read_table('https://uchicago.box.com/shared/static/5vwc7pjw9qmtv7298c4rc7bcuicoyemt.gz', sep='\\t',\n                                         dtype={'gene_id': str, 'gene_name':str, 'TargetID':str, 'Chr':str})\ngeuvadis_gene_expression.head(5)\n\n\n\n\n\n\n\n\ngene_id\ngene_name\nTargetID\nChr\nCoord\nHG00096\nHG00097\nHG00099\nHG00100\nHG00101\n...\nNA20810\nNA20811\nNA20812\nNA20813\nNA20814\nNA20815\nNA20816\nNA20819\nNA20826\nNA20828\n\n\n\n\n0\nENSG00000223972.4\nDDX11L1\nENSG00000223972.4\n1\n11869\n0.320818\n0.344202\n0.354225\n0.478064\n-0.102815\n...\n1.008605\n0.384489\n0.581284\n0.513981\n0.667449\n0.350890\n0.186103\n-0.037976\n0.405439\n0.199143\n\n\n1\nENSG00000227232.3\nWASH7P\nENSG00000227232.3\n1\n29806\n33.714457\n20.185174\n18.095407\n24.100871\n29.018719\n...\n30.980194\n34.086207\n39.678442\n29.643513\n27.120420\n29.121624\n31.117198\n32.047074\n22.798959\n23.563874\n\n\n2\nENSG00000243485.1\nMIR1302-11\nENSG00000243485.1\n1\n29554\n0.240408\n0.157456\n0.218806\n0.320878\n0.067833\n...\n0.065940\n0.228784\n0.140642\n0.283905\n0.273821\n0.286311\n0.324060\n0.049574\n0.255288\n0.157440\n\n\n3\nENSG00000238009.2\nRP11-34P13.7\nENSG00000238009.2\n1\n133566\n0.328272\n0.327932\n0.090064\n0.420443\n0.220269\n...\n0.274071\n0.384179\n0.533693\n0.307221\n0.307367\n0.400278\n0.612321\n0.666633\n0.281138\n1.346129\n\n\n4\nENSG00000239945.1\nRP11-34P13.8\nENSG00000239945.1\n1\n91105\n0.332171\n-0.032164\n0.017323\n0.424677\n0.214025\n...\n0.347323\n0.346744\n0.073580\n0.400396\n0.470517\n0.069749\n0.299353\n0.090019\n0.282554\n-0.157170\n\n\n\n\n5 rows × 467 columns\n\n\n\n\nmodel = Enformer(model_path) # here we load the model architecture.\n\nfasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data\n\n\ngene_intervals = collect_intervals(chromosomes=['17'], gene_list=['GSDMB'])\nprint(gene_intervals)\n\n{'GSDMB': ['17', 38060848, 38077313]}"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#run-predictions",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#run-predictions",
    "title": "Import Libraries",
    "section": "Run Predictions",
    "text": "Run Predictions\nWe’ll pick one individual at random.\n\n# rand_individual = np.random.choice(a=geuvadis_gene_expression.columns[6:-1], replace=False) # individuals we are interested in\nrand_individual = 'NA12413'\n\n\ntest = My_class('GSDMB', '17', rand_individual)\n\n\ndiffmats = test.get_diffmats()\nabs, rel, relmax, relmed = diffmats\nrel\n\narray([[2.68207751e-02, 2.14794427e-02, 1.54860010e-02, ...,\n        3.27786431e-03, 4.31587268e-03, 5.99253085e-03],\n       [1.52227283e-02, 9.49528441e-03, 1.39587221e-03, ...,\n        4.25775489e-03, 6.33378932e-03, 3.99001292e-04],\n       [5.20520937e-03, 5.04603982e-03, 1.07796649e-02, ...,\n        2.46862252e-03, 5.82935056e-03, 1.01276860e-03],\n       ...,\n       [1.82648703e-01, 1.20395273e-01, 2.26677638e-02, ...,\n        3.71882971e-03, 2.21709910e-04, 3.99682624e-03],\n       [7.65870988e-01, 4.11944836e-01, 7.03058019e-03, ...,\n        7.04148132e-03, 2.09397208e-02, 2.70997807e-02],\n       [4.41073626e-01, 1.37864158e-01, 3.22264820e-01, ...,\n        1.49025135e-02, 2.87779793e-03, 4.64532932e-04]], dtype=float32)\n\n\n\ntest.get_summary(test.rel_diffmat)\n\n{'mean': 0.21557848,\n 'median': 0.08500237,\n 'std_dev': 0.5238661,\n 'minimum': 0.0,\n 'maximum': 73.63812,\n 'total_sum': 1026250.1,\n 'q1': 0.02724431036040187,\n 'q2': 0.0850023701786995,\n 'q3': 0.21821939945220947,\n 'iqr': 0.1909750890918076}\n\n\n\nabs_table = test.make_table(abs, 1)\nabs_table_sorted = abs_table.sort_values('diff')\nabs_table_sorted\n\n\n\n\n\n\n\n\ntrack\nbin\ndiff\n\n\n\n\n789\nCHIP:H3K4me1:thymus male child (3 years)\n533\n1.000574\n\n\n2468\nCHIP:H3K4me3:esophagus male adult (34 years)\n760\n1.000663\n\n\n2393\nCHIP:HNRNPLL:K562\n760\n1.000681\n\n\n2649\nCHIP:H3K4me1:CD14-positive monocyte male adult...\n867\n1.000864\n\n\n220\nCHIP:CTCF:A549 treated with 100 nM dexamethaso...\n134\n1.001465\n\n\n...\n...\n...\n...\n\n\n1002\nCHIP:CTCF:K562\n540\n7.443279\n\n\n1070\nCHIP:CTCF:K562\n540\n7.470882\n\n\n864\nCHIP:CTCF:K562\n539\n8.511012\n\n\n1674\nCAGE:thymus, adult, pool1\n563\n10.100098\n\n\n1690\nCAGE:thymus, fetal, pool1\n563\n10.273163\n\n\n\n\n2669 rows × 3 columns\n\n\n\n\nfor mat in diffmats:\n    print(test.get_summary(mat))\n\n{'mean': 0.011740582, 'median': 0.002480626, 'std_dev': 0.065571606, 'minimum': 0.0, 'maximum': 10.273163, 'total_sum': 55890.43, 'q1': 0.0005608946084976196, 'q2': 0.002480626106262207, 'q3': 0.007642507553100586, 'iqr': 0.007081612944602966}\n{'mean': 0.21557848, 'median': 0.08500237, 'std_dev': 0.5238661, 'minimum': 0.0, 'maximum': 73.63812, 'total_sum': 1026250.1, 'q1': 0.02724431036040187, 'q2': 0.0850023701786995, 'q3': 0.21821939945220947, 'iqr': 0.1909750890918076}\n{'mean': 0.03527108, 'median': 0.0074218167, 'std_dev': 0.08494974, 'minimum': 0.0, 'maximum': 1.0, 'total_sum': 167906.14, 'q1': 0.0011184182367287576, 'q2': 0.007421816699206829, 'q3': 0.03162767644971609, 'iqr': 0.030509258212987334}\n{'mean': 5.7709837, 'median': 1.0, 'std_dev': 116.90829, 'minimum': 0.0, 'maximum': 36243.305, 'total_sum': 27472468.0, 'q1': 0.38562167435884476, 'q2': 1.0, 'q3': 2.418138027191162, 'iqr': 2.0325163528323174}\n\n\n\nlen(test.get_outliers(rel, 8))\n\n2285\n\n\n\nvalues = np.linspace(1, 80, 10)\nfor v in values:\n    print(len(test.get_outliers()))\n\n\ntest.plot_tol_numouts(rel, 1, 80, 10)\n\n\n\n\n\ntest_abs_out = test.get_outliers(test.abs_mat, 1)\ntest.get_outliers(test.abs_mat, 1), len(test.get_outliers(test.abs_mat, 1))\n\n(array([1.0394936, 1.0977535, 1.0580368, ..., 1.274787 , 1.6978073,\n        1.5110455], dtype=float32),\n 2669)\n\n\n\ntest.make_hist(test_abs_out, 20)\n\n\n\n\n\ntest.get_outlier_inds(test.abs_mat, 1)\ncol_outs = test.get_outlier_inds(test.abs_mat, 1)[2]\n\nto get list of unique inds: set(inds_arr) \nget count of inds: Counter(inds_arr)\nto get list of unique inds: set(inds_arr) \nget count of inds: Counter(inds_arr)\n\n\n\ntest.make_hist(col_outs, 500)\n\n\n\n\n\noutlier_df = test.make_table(test.abs_mat, 1)\noutlier_df\n\n\n\n\n\n\n\n\ntrack\nbin\ndiff\n\n\n\n\n0\nCHIP:H3K27ac:OCI-LY3\n44\n1.039494\n\n\n1\nCHIP:H3K27ac:OCI-LY3\n45\n1.097754\n\n\n2\nCHIP:H3K27ac:OCI-LY3\n46\n1.058037\n\n\n3\nCHIP:H3K27ac:OCI-LY3\n48\n1.166883\n\n\n4\nCHIP:H3K27ac:OCI-LY3\n53\n1.050079\n\n\n...\n...\n...\n...\n\n\n2664\nCHIP:H3K4me1:CD14-positive monocyte male adult...\n893\n1.130640\n\n\n2665\nCHIP:H3K4me1:CD14-positive monocyte female\n894\n1.405522\n\n\n2666\nCHIP:H3K4me1:CD14-positive monocyte male adult...\n894\n1.274787\n\n\n2667\nCHIP:H3K4me1:CD14-positive monocyte female\n895\n1.697807\n\n\n2668\nCHIP:H3K4me1:CD14-positive monocyte male adult...\n895\n1.511045\n\n\n\n\n2669 rows × 3 columns\n\n\n\n\n    # def get_summary(self, arr):\n    # def get_outliers(self, arr, tol):\n    # def make_hist(arr, bin_num):\n    # def get_outlier_inds(self, arr, tol):\n\n\ntest2 = My_class(\"AMIGO1\", \"1\", rand_individual)\n\n\ntest2_abs_diff = test2.get_abs_diff()\ntest2_abs_diff, type(test2_abs_diff)\n\n(array([[5.7518482e-06, 3.5203993e-06, 8.2701445e-07, ..., 6.4517371e-07,\n         6.3516200e-07, 1.2149103e-06],\n        [2.5629997e-06, 1.7061830e-06, 6.2957406e-06, ..., 3.6321580e-08,\n         3.4179538e-06, 1.1073425e-06],\n        [1.4603138e-06, 1.5571713e-06, 1.6354024e-06, ..., 1.9324943e-08,\n         2.0535663e-06, 6.4587221e-07],\n        ...,\n        [5.5428594e-05, 6.6407025e-05, 5.4815784e-05, ..., 1.5444122e-05,\n         2.6834011e-04, 1.5201420e-04],\n        [9.3728304e-05, 1.3028085e-04, 1.2800470e-04, ..., 4.4204295e-05,\n         4.0826201e-04, 2.2485107e-04],\n        [3.8206577e-05, 5.6162477e-05, 9.3773007e-05, ..., 4.2296946e-05,\n         5.4708123e-04, 2.2122264e-04]], dtype=float32),\n numpy.ndarray)\n\n\n\nabs_diff2_sum = test2.get_summary(test2_abs_diff)\nabs_diff2_sum\n\n{'mean': 0.0008395509,\n 'median': 0.00011945516,\n 'std_dev': 0.009009555,\n 'minimum': 0.0,\n 'maximum': 2.1459656,\n 'total_sum': 3996.6384,\n 'q1': 2.8625130653381348e-05,\n 'q2': 0.00011945515871047974,\n 'q3': 0.0003998279571533203,\n 'iqr': 0.00037120282649993896}\n\n\n\ntest2.get_summary(test2.abs_mat)\n\n{'mean': 0.0008395509,\n 'median': 0.00011945516,\n 'std_dev': 0.009009555,\n 'minimum': 0.0,\n 'maximum': 2.1459656,\n 'total_sum': 3996.6384,\n 'q1': 2.8625130653381348e-05,\n 'q2': 0.00011945515871047974,\n 'q3': 0.0003998279571533203,\n 'iqr': 0.00037120282649993896}\n\n\n\nabs_outs2 = test2.get_outliers(test2.abs_mat, 1)\nlen(abs_outs2)\n\n78\n\n\n\ntest2.get_outlier_inds(test2.abs_mat)\n\n\ntest2.make_hist(abs_outs2, 20)\n\n\n\n\n\ngene = 'GSDMB'\ngene_interval = gene_intervals[gene]\ntarget_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n                                        gene_interval[1],\n                                        gene_interval[2])\ntarget_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))\nwindow_coords = target_interval.resize(SEQUENCE_LENGTH)\ncur_gene_vars = pd.read_csv(\"/grand/TFXcan/imlab/users/lvairus/hackenf/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n\n\nhaplo_1, haplo_2 = geno_to_seq(gene, rand_individual)\n\nhaplo_1_enc = one_hot_encode(\"\".join(haplo_1))[np.newaxis]\nhaplo_2_enc = one_hot_encode(\"\".join(haplo_2))[np.newaxis]\naverage_enc = np.add(haplo_1_enc, haplo_2_enc) / 2\n\n\nprediction_1 = model.predict_on_batch(haplo_1_enc)['human'][0]\nprediction_2 = model.predict_on_batch(haplo_2_enc)['human'][0]\n\npost_average = (prediction_1 + prediction_2) / 2\npre_average = model.predict_on_batch(average_enc)['human'][0]"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#comparing-predictions",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#comparing-predictions",
    "title": "Import Libraries",
    "section": "Comparing Predictions",
    "text": "Comparing Predictions\n\npre_average2, post_average2 = run_predictions2(gene, '17', rand_individual)\n\nCurrently on gene GSDMB, and predicting on individual NA12413...\n\n\n\ndiff = pre_average - post_average\n\nabs_diff = np.sqrt(np.square(diff))\n\nrel_diff = (abs_diff) / ((pre_average + post_average) + 10**-16)\n\n\n# Summary Statistics of Absolute Differece\narr = abs_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.011741725\nMedian: 0.0024814606\nStandard Deviation: 0.06555718\nMinimum: 0.0\nMaximum: 10.2612915\nSum: 55895.87\n\n\n\n# Summary Statistics of Relative Difference\narr = rel_diff\n\nprint(\"Mean:\", np.mean(arr))\nprint(\"Median:\", np.median(arr))\nprint(\"Standard Deviation:\", np.std(arr))\nprint(\"Minimum:\", np.min(arr))\nprint(\"Maximum:\", np.max(arr))\nprint(\"Sum:\", np.sum(arr))\n\nMean: 0.00026652514\nMedian: 8.4674466e-05\nStandard Deviation: 0.0011749842\nMinimum: 0.0\nMaximum: 0.24099354\nSum: 1268.779\n\n\n\nbigDiff = abs_diff[abs_diff&gt;1]\nlen(bigDiff)\n\n72\n\n\n\n# Plot the histogram\nplt.hist(bigDiff, bins=20)\n\n# Add labels and title\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Histogram')\n\n# Display the plot\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#in-which-tracks-is-it-not-precise",
    "title": "Import Libraries",
    "section": "In which tracks is it not precise?",
    "text": "In which tracks is it not precise?\n\n# max diff tolerance is 1. If a diff is greater than 1 we will count it as too big\ntolerance = 1\n\nindices = np.where(abs_diff &gt; tolerance)\nindices[0][0], indices[1][0]\n\nind_of_big_diffs = np.array(list(zip(indices[0], indices[1])))\nlen(ind_of_big_diffs), ind_of_big_diffs\n\n(72,\n array([[ 773, 4740],\n        [ 773, 4746],\n        [ 773, 4747],\n        [ 773, 4748],\n        [ 773, 4754],\n        [ 773, 4759],\n        [ 773, 4760],\n        [ 773, 4764],\n        [ 773, 4766],\n        [ 773, 4770],\n        [ 773, 4777],\n        [ 773, 4782],\n        [ 773, 4797],\n        [ 773, 4808],\n        [ 773, 4810],\n        [ 773, 4815],\n        [ 773, 4816],\n        [ 773, 4817],\n        [ 773, 4818],\n        [ 773, 4819],\n        [ 773, 4868],\n        [ 773, 4869],\n        [ 773, 4870],\n        [ 773, 4874],\n        [ 773, 4877],\n        [ 773, 4879],\n        [ 773, 4881],\n        [ 773, 4884],\n        [ 773, 4885],\n        [ 773, 4886],\n        [ 773, 4887],\n        [ 773, 4890],\n        [ 773, 4892],\n        [ 773, 4893],\n        [ 773, 4897],\n        [ 773, 4898],\n        [ 773, 4900],\n        [ 773, 4902],\n        [ 773, 4905],\n        [ 773, 4906],\n        [ 773, 4909],\n        [ 773, 4920],\n        [ 773, 5056],\n        [ 773, 5057],\n        [ 773, 5072],\n        [ 773, 5073],\n        [ 773, 5078],\n        [ 773, 5079],\n        [ 773, 5080],\n        [ 773, 5106],\n        [ 773, 5110],\n        [ 773, 5115],\n        [ 773, 5127],\n        [ 773, 5144],\n        [ 773, 5150],\n        [ 773, 5196],\n        [ 773, 5198],\n        [ 773, 5212],\n        [ 773, 5213],\n        [ 773, 5236],\n        [ 773, 5238],\n        [ 773, 5300],\n        [ 829, 2652],\n        [ 830,  733],\n        [ 830,  746],\n        [ 830,  801],\n        [ 830,  810],\n        [ 830,  812],\n        [ 830,  814],\n        [ 830,  815],\n        [ 830,  822],\n        [ 830, 3647]]))\n\n\n\ncols\n\n# all the indices of the columns where the diff exceeds tolerance\ncol_inds = indices[1]\n\n\ncounts = Counter(col_inds)\n[(key,value) for key,value in counts.items() if value &gt; 8]\n\n[]\n\n\n\nprint(f\"Number of unique col ind: {len(set(col_inds))} \\nTotal col ind: {len(col_inds)}\")\n\nNumber of unique col ind: 72 \nTotal col ind: 72\n\n\n\nplt.hist(col_inds, bins=200)  # Specify the number of bins\nplt.title('Histogram of col indexes')\nplt.show()\n\n\n\n\nAnalysis: the difference exceeds the tolerance in 227 unique columns that are pretty evenly distributed, so enformer doesn’t necessarily do better or worse with averaging before/after in any particular cell line\ni want to get the amount of times it affects each col 227 uniqe cols\n\n\nrows\n\nlen(set(indices[0])), len(indices[0])\n\n(3, 72)\n\n\n\n# Summary Statistics of rows\narr1 = indices[0]\n\nprint(\"Mean:\", np.mean(arr1))\nprint(\"Median:\", np.median(arr1))\nprint(\"Standard Deviation:\", np.std(arr1))\nprint(\"Minimum:\", np.min(arr1))\nprint(\"Maximum:\", np.max(arr1))\nprint(\"Sum:\", np.sum(arr1))\n\nq1 = np.percentile(arr, 25)\nq3 = np.percentile(arr, 75)\niqr = q3 - q1\n\nprint(\"Q1:\", q1)\nprint(\"Q3:\", q3)\nprint(\"Interquartile Range:\", iqr)\n\nMean: 780.9027777777778\nMedian: 773.0\nStandard Deviation: 19.678075590631757\nMinimum: 773\nMaximum: 830\nSum: 56225\n\n\n\nplt.hist(indices[0], bins=30)  # Specify the number of bins\nplt.title('Histogram of row indexes')\nplt.show()\n\n\n\n\nAnalysis: There are only a few specific locations where enformer does worse"
  },
  {
    "objectID": "posts/2023-07-14-compare-avgs/Compare_averages.html#comparing-across-tracks",
    "href": "posts/2023-07-14-compare-avgs/Compare_averages.html#comparing-across-tracks",
    "title": "Import Libraries",
    "section": "Comparing across tracks",
    "text": "Comparing across tracks\n\nres = []\nfor i in range(5313):\n    pre_track = pre_average[:, i]\n    post_track = post_average[:, i]\n    corr = np.corrcoef(pre_track, post_track)[0][1]\n    res.append(corr)\n\nThe results from both methods are nearly identical.\n\nprint(min(res), max(res))\n\n0.9989958894392978 0.9999999912865261"
  },
  {
    "objectID": "posts/2023-06-13-population-structure/index.html",
    "href": "posts/2023-06-13-population-structure/index.html",
    "title": "population structure",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(devtools)\n\nLoading required package: usethis\n\nlibrary(glue)\n\n\nif(!file.exists(glue(\"~/Downloads/analysis_population_structure.tgz\")))\n{\n  system(glue(\"wget -O ~/Downloads/analysis_population_structure.tgz https://uchicago.box.com/shared/static/zv1jyevq01mt130ishx25sgb1agdu8lj.tgz\"))\n  ## tar -xf file_name.tar.gz --directory /target/directory\n}\nsystem(glue(\"tar xvf ~/Downloads/analysis_population_structure.tgz --directory ~/Downloads/\")) \n\nThe following code is loading a function in gist.github.com/38431b74c6c0bf90c12f devtools::source_gist(\"38431b74c6c0bf90c12f\")\n\nwork.dir =\"~/Downloads/analysis_population_structure/\"\n\ndevtools::source_gist(\"38431b74c6c0bf90c12f\")\n\nℹ Sourcing gist \"38431b74c6c0bf90c12f\"\nℹ SHA-1 hash of file is \"cbeca7fd9bf1602dee41c4f1880cc3a5e8992303\"\n\n\n\npopinfo = read_tsv(paste0(work.dir,\"relationships_w_pops_051208.txt\"))\n\nRows: 1301 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (5): FID, IID, dad, mom, population\ndbl (2): sex, pheno\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npopinfo %&gt;% count(population)\n\n# A tibble: 11 × 2\n   population     n\n   &lt;chr&gt;      &lt;int&gt;\n 1 ASW           90\n 2 CEU          180\n 3 CHB           90\n 4 CHD          100\n 5 GIH          100\n 6 JPT           91\n 7 LWK          100\n 8 MEX           90\n 9 MKK          180\n10 TSI          100\n11 YRI          180\n\n\n\nsamdata = read_tsv(paste0(work.dir,\"phase3_corrected.psam\"),guess_max = 2500) \n\nRows: 2504 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (5): #IID, PAT, MAT, SuperPop, Population\ndbl (1): SEX\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nspec(samdata)\n\ncols(\n  `#IID` = col_character(),\n  PAT = col_character(),\n  MAT = col_character(),\n  SEX = col_double(),\n  SuperPop = col_character(),\n  Population = col_character()\n)\n\n\n\nsuperpop = samdata %&gt;% select(SuperPop,Population) %&gt;% unique()\nsuperpop = rbind(superpop, data.frame(SuperPop=c(\"EAS\",\"HIS\",\"AFR\"),Population=c(\"CHD\",\"MEX\",\"MKK\")))\n\n\nif(!file.exists(glue::glue(\"{work.dir}output/allhwe.hwe\")))\nsystem(glue::glue(\"~/bin/plink --bfile {work.dir}hapmapch22 --hardy --out {work.dir}output/allhwe\"))\nallhwe = read.table(glue::glue(\"{work.dir}output/allhwe.hwe\"),header=TRUE,as.is=TRUE)\nhist(allhwe$P)\n\n\n\n\n\nqqunif(allhwe$P,main='HWE HapMap3 All Pop')\n\nWarning in qqunif(allhwe$P, main = \"HWE HapMap3 All Pop\"): thresholding p to\n1e-30\n\n\n\n\n\n\npop = \"CHB\"\npop = \"CEU\"\npop = \"YRI\"\nfor(pop in c(\"CHB\",\"CEU\",\"YRI\"))\n{\n  ## what if we calculate with single population?\n  popinfo %&gt;% filter(population==pop) %&gt;%\n    write_tsv(path=glue::glue(\"{work.dir}{pop}.fam\") )\n  if(!file.exists(glue::glue(\"{work.dir}output/hwe-{pop}.hwe\")))\n  system(glue::glue(\"~/bin/plink --bfile {work.dir}hapmapch22 --hardy --keep {work.dir}{pop}.fam --out {work.dir}output/hwe-{pop}\"))\n  pophwe = read.table(glue::glue(\"{work.dir}output/hwe-{pop}.hwe\"),header=TRUE,as.is=TRUE)\n  hist(pophwe$P,main=glue::glue(\"HWE {pop} and founders only\"))\n  qqunif(pophwe$P,main=glue::glue(\"HWE {pop} and founders only\"))\n}\n\nWarning: The `path` argument of `write_tsv()` is deprecated as of readr 1.4.0.\nℹ Please use the `file` argument instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nigrowth = read_tsv(\"https://raw.githubusercontent.com/hakyimlab/igrowth/master/rawgrowth.txt\")\n\nRows: 3726 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): IID, pop, serum\ndbl (4): sex, experim, meas.by, growth\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nspec(igrowth)\n\ncols(\n  IID = col_character(),\n  sex = col_double(),\n  pop = col_character(),\n  experim = col_double(),\n  meas.by = col_double(),\n  serum = col_character(),\n  growth = col_double()\n)\n\n\n\nigrowth = popinfo %&gt;% select(-pheno) %&gt;% inner_join(igrowth %&gt;% select(IID,growth), by=c(\"IID\"=\"IID\"))\nwrite_tsv(igrowth,path=glue::glue(\"{work.dir}igrowth.pheno\"))\nigrowth %&gt;% ggplot(aes(population,growth)) + geom_violin(aes(fill=population)) + geom_boxplot(width=0.2,col='black',fill='gray',alpha=.8) + theme_bw(base_size = 15)\n\nWarning: Removed 130 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 130 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\nsummary( lm(growth~population,data=igrowth) )\n\n\nCall:\nlm(formula = growth ~ population, data = igrowth)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-58821 -18093  -2242  15896  98760 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    73080.8      938.2  77.894  &lt; 2e-16 ***\npopulationCEU  -2190.1     1175.4  -1.863   0.0625 .  \npopulationCHB   9053.1     2043.9   4.429 9.73e-06 ***\npopulationJPT   3476.8     2034.8   1.709   0.0876 .  \npopulationYRI  -7985.2     1137.2  -7.022 2.61e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 24160 on 3591 degrees of freedom\n  (130 observations deleted due to missingness)\nMultiple R-squared:  0.0345,    Adjusted R-squared:  0.03342 \nF-statistic: 32.08 on 4 and 3591 DF,  p-value: &lt; 2.2e-16\n\n\n\nif(!file.exists(glue::glue(\"{work.dir}output/igrowth.assoc.linear\")))\nsystem(glue::glue(\"~/bin/plink --bfile {work.dir}hapmapch22 --linear --pheno {work.dir}igrowth.pheno --pheno-name growth --maf 0.05 --out {work.dir}output/igrowth\"))\nigrowth.assoc = read.table(glue::glue(\"{work.dir}output/igrowth.assoc.linear\"),header=T,as.is=T)\nhist(igrowth.assoc$P)\n\n\n\n\n\nqqunif(igrowth.assoc$P)\n\n\n\n\n\nlibrary(qqman)\n\n\n\n\nFor example usage please run: vignette('qqman')\n\n\n\n\n\nCitation appreciated but not required:\n\n\nTurner, (2018). qqman: an R package for visualizing GWAS results using Q-Q and manhattan plots. Journal of Open Source Software, 3(25), 731, https://doi.org/10.21105/joss.00731.\n\n\n\n\nmanhattan(igrowth.assoc, chr=\"CHR\", bp=\"BP\", snp=\"SNP\", p=\"P\" )\n\n\n\n\n\n## generate PCs using plink\nif(!file.exists(glue::glue(\"{work.dir}output/pca.eigenvec\")))\nsystem(glue::glue(\"~/bin/plink --bfile {work.dir}hapmapch22 --pca --out {work.dir}output/pca\"))\n## read plink calculated PCs\npcplink = read.table(glue::glue(\"{work.dir}output/pca.eigenvec\"),header=F, as.is=T)\nnames(pcplink) = c(\"FID\",\"IID\",paste0(\"PC\", c(1:(ncol(pcplink)-2))) )\npcplink = popinfo %&gt;% left_join(superpop,by=c(\"population\"=\"Population\")) %&gt;% inner_join(pcplink, by=c(\"FID\"=\"FID\", \"IID\"=\"IID\"))\n## plot PC1 vs PC2\npcplink %&gt;% ggplot(aes(PC1,PC2,col=population,shape=SuperPop)) + geom_point(size=3,alpha=.7) + theme_bw(base_size = 15)\n\n\n\n\n\nif(!file.exists(glue::glue(\"{work.dir}output/igrowth-adjPC.assoc.linear\")))\nsystem(glue::glue(\"~/bin/plink --bfile {work.dir}hapmapch22 --linear --pheno {work.dir}igrowth.pheno --pheno-name growth --covar {work.dir}output/pca.eigenvec --covar-number 1-4 --hide-covar --maf 0.05 --out {work.dir}output/igrowth-adjPC\"))\nigrowth.adjusted.assoc = read.table(glue::glue(\"{work.dir}output/igrowth-adjPC.assoc.linear\"),header=T,as.is=T)\n##indadd = igrowth.adjusted.assoc$TEST==\"ADD\"\ntitulo = \"igrowh association adjusted for PCs\"\nhist(igrowth.adjusted.assoc$P,main=titulo)\n\n\n\n\n\nqqunif(igrowth.adjusted.assoc$P,main=titulo)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laura’s Blog",
    "section": "",
    "text": "Compare Averages (relmax3)\n\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nAdding Slims to Targets df\n\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nCompare averages 2\n\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nCompare averages 1\n\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nPlotting Enformer Usage Notebook Predictions\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nHow to install GPU-enabled tensorflow on a mac M1\n\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nIntro to Parsl\n\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nParsl Cheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nHackathon Enformer\n\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nHackathon Enformer\n\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nDiabetes Practice\n\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nDiabetes Example\n\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nZero to Hero\n\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nUsing Conda\n\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nUsing Polaris\n\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nIris Neural Network Training\n\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nIris Neural Network Training\n\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\npopulation structure\n\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nPython Basics\n\n\n\n\n\n\n\ncode\n\n\ntraining\n\n\ntutorial\n\n\ncheatsheet\n\n\n\n\nBasic information and commands for python\n\n\n\n\n\n\nJun 8, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nLarge Language Models\n\n\n\n\n\nSummary of LLM article by Serafim Batzoglou\n\n\n\n\n\n\nJun 6, 2023\n\n\nLaura Vairus\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]